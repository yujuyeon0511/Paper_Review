---
title: "Hierarchical Adaptive Eviction for KV Cache Management in Multimodal Language Mo"
date: 2026-02-03
arxiv: "2602.02197v1"
category: "cs.LG"
model: "google/gemma-3-27b-it:free"
---

# Hierarchical Adaptive Eviction for KV Cache Management in Multimodal Language Models

## ğŸ“– ë…¼ë¬¸ ì •ë³´

| í•­ëª© | ë‚´ìš© |
|------|------|
| **ì €ì** | Xindian Ma, Yidi Lu, Peng Zhang, Jing Zhang |
| **ë°œí‘œì¼** | 2026-02-02 |
| **arXiv** | [2602.02197v1](https://arxiv.org/pdf/2602.02197v1) |
| **ì¹´í…Œê³ ë¦¬** | cs.LG |

---

## ğŸ“ ì´ˆë¡ (Abstract)

The integration of visual information into Large Language Models (LLMs) has enabled Multimodal LLMs (MLLMs), but the quadratic memory and computational costs of Transformer architectures remain a bottleneck. Existing KV cache eviction strategies fail to address the heterogeneous attention distributions between visual and text tokens, leading to suboptimal efficiency or degraded performance. In this paper, we propose Hierarchical Adaptive Eviction (HAE), a KV cache eviction framework that optimizes text-visual token interaction in MLLMs by implementing Dual-Attention Pruning during pre-filling (leveraging visual token sparsity and attention variance) and a Dynamic Decoding Eviction Strategy (inspired by OS Recycle Bins) during decoding. HAE minimizes KV cache usage across layers, reduces computational overhead via index broadcasting, and theoretically ensures superior information integrity and lower error bounds compared to greedy strategies, enhancing efficiency in both comprehension and generation tasks. Empirically, HAE reduces KV-Cache memory by 41\% with minimal accuracy loss (0.3\% drop) in image understanding tasks and accelerates story generation inference by 1.5x while maintaining output quality on Phi3.5-Vision-Instruct model.

---

## ğŸ” AI ë¶„ì„

## ğŸ“„ ë…¼ë¬¸ ìš”ì•½
ë³¸ ë…¼ë¬¸ì€ Multimodal Large Language Model (MLLM)ì˜ KV ìºì‹œ ê´€ë¦¬ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ê³„ì¸µì  ì ì‘í˜• ì‚­ì œ (Hierarchical Adaptive Eviction, HAE) í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. HAEëŠ” í…ìŠ¤íŠ¸-ë¹„ì „ í† í° ê°„ì˜ ì´ì§ˆì ì¸ ì–´í…ì…˜ ë¶„í¬ë¥¼ ê³ ë ¤í•˜ì—¬ pre-filling ë‹¨ê³„ì—ì„œ Dual-Attention Pruningì„, decoding ë‹¨ê³„ì—ì„œ Dynamic Decoding Eviction Strategyë¥¼ ì ìš©í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ KV ìºì‹œ ì‚¬ìš©ëŸ‰ì„ ì¤„ì´ê³  ê³„ì‚° ì˜¤ë²„í—¤ë“œë¥¼ ê°ì†Œì‹œì¼œ MLLMì˜ íš¨ìœ¨ì„±ì„ í–¥ìƒì‹œí‚¤ë©´ì„œë„ ì„±ëŠ¥ ì €í•˜ë¥¼ ìµœì†Œí™”í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, HAEëŠ” KV ìºì‹œ ë©”ëª¨ë¦¬ë¥¼ 41%ê¹Œì§€ ì¤„ì´ê³  ì¶”ë¡  ì†ë„ë¥¼ ìµœëŒ€ 1.5ë°°ê¹Œì§€ í–¥ìƒì‹œí‚¤ëŠ” ê²ƒì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.

### ğŸ†• ìƒˆë¡œìš´ ì  (Novelty)
ê¸°ì¡´ KV ìºì‹œ ì‚­ì œ ì „ëµë“¤ì´ í…ìŠ¤íŠ¸ì™€ ë¹„ì „ í† í° ê°„ì˜ ì´ì§ˆì ì¸ ì–´í…ì…˜ ë¶„í¬ë¥¼ ê³ ë ¤í•˜ì§€ ëª»í–ˆë˜ ì ì„ ê°œì„ í•˜ì—¬, HAEëŠ” Dual-Attention Pruningê³¼ Dynamic Decoding Eviction Strategyë¥¼ í†µí•´ í…ìŠ¤íŠ¸-ë¹„ì „ í† í° ìƒí˜¸ì‘ìš©ì„ ìµœì í™”í•©ë‹ˆë‹¤. íŠ¹íˆ, OS Recycle Binì—ì„œ ì˜ê°ì„ ì–»ì€ Dynamic Decoding Eviction StrategyëŠ” decoding ê³¼ì •ì—ì„œ ìºì‹œ íš¨ìœ¨ì„±ì„ ë†’ì´ëŠ” ìƒˆë¡œìš´ ì ‘ê·¼ ë°©ì‹ì„ ì œì‹œí•©ë‹ˆë‹¤.

### ğŸ’ª ê°•ì  (Strengths)
1. **íš¨ìœ¨ì„± í–¥ìƒ:** KV ìºì‹œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ í¬ê²Œ ì¤„ì´ê³  ì¶”ë¡  ì†ë„ë¥¼ í–¥ìƒì‹œì¼œ MLLMì˜ ì‹¤ìš©ì„±ì„ ë†’ì…ë‹ˆë‹¤.
2. **ì„±ëŠ¥ ìœ ì§€:** ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ ë†’ì´ë©´ì„œë„ ì´ë¯¸ì§€ ì´í•´ ë° ìŠ¤í† ë¦¬ ìƒì„±ê³¼ ê°™ì€ ë‹¤ì–‘í•œ taskì—ì„œ ì„±ëŠ¥ ì €í•˜ë¥¼ ìµœì†Œí™”í•©ë‹ˆë‹¤.
3. **ì´ë¡ ì  ê·¼ê±°:** ì •ë³´ ë¬´ê²°ì„± ë° ì˜¤ë¥˜ ë²”ìœ„ë¥¼ ì´ë¡ ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ HAEì˜ ìš°ìˆ˜ì„±ì„ ì…ì¦í•©ë‹ˆë‹¤.

### âš ï¸ ì•½ì /í•œê³„ì  (Limitations)
1. **ëª¨ë¸ ì˜ì¡´ì„±:** Phi3.5-Vision-Instruct ëª¨ë¸ì— ëŒ€í•œ ì‹¤í—˜ ê²°ê³¼ë§Œ ì œì‹œë˜ì–´ ìˆì–´, ë‹¤ë¥¸ MLLM ëª¨ë¸ì— ëŒ€í•œ ì¼ë°˜í™” ê°€ëŠ¥ì„±ì´ ë¶ˆí™•ì‹¤í•©ë‹ˆë‹¤. ë‹¤ì–‘í•œ ëª¨ë¸ ì•„í‚¤í…ì²˜ ë° í¬ê¸°ì— ëŒ€í•œ ì‹¤í—˜ì´ í•„ìš”í•©ë‹ˆë‹¤.
2. **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹:** Dual-Attention Pruning ë° Dynamic Decoding Eviction Strategyì— ì‚¬ìš©ë˜ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì— ëŒ€í•œ ìƒì„¸í•œ ì„¤ëª…ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ìµœì ì˜ ì„±ëŠ¥ì„ ì–»ê¸° ìœ„í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • ì „ëµì— ëŒ€í•œ ì—°êµ¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.
3. **ë³µì¡ë„:** HAE í”„ë ˆì„ì›Œí¬ëŠ” ê¸°ì¡´ KV ìºì‹œ ê´€ë¦¬ ì „ëµë³´ë‹¤ ë³µì¡í•˜ë©°, êµ¬í˜„ ë° ìœ ì§€ë³´ìˆ˜ì— ì–´ë ¤ì›€ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ğŸ”— ë‚´ ì—°êµ¬ì™€ì˜ ì—°ê´€ì„±
ë³¸ ë…¼ë¬¸ì€ Vision encoderì™€ Text LLM ê°„ì˜ ì •ë ¬(alignment) ì—°êµ¬ì— ì¤‘ìš”í•œ ì‹œì‚¬ì ì„ ì œê³µí•©ë‹ˆë‹¤. íŠ¹íˆ, í…ìŠ¤íŠ¸ì™€ ë¹„ì „ í† í° ê°„ì˜ ì´ì§ˆì ì¸ ì–´í…ì…˜ ë¶„í¬ë¥¼ ê³ ë ¤í•œ ìºì‹œ ê´€ë¦¬ ì „ëµì€, ë‘ ëª¨ë‹¬ë¦¬í‹° ê°„ì˜ ì •ë³´ íë¦„ì„ ìµœì í™”í•˜ì—¬ MLLMì˜ ì¶”ë¡  ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ë° ê¸°ì—¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, KV ìºì‹œ íš¨ìœ¨ì„±ì„ ë†’ì´ëŠ” ê²ƒì€ Scientific ë„ë©”ì¸ì—ì„œ ëŒ€ê·œëª¨ ì‹œê° ìë£Œë¥¼ í™œìš©í•˜ëŠ” MLLMì˜ í™œìš© ê°€ëŠ¥ì„±ì„ ë†’ì´ëŠ” ë° ì¤‘ìš”í•œ ì—­í• ì„ í•  ê²ƒì…ë‹ˆë‹¤.

### ğŸ’¡ ì—°êµ¬ ì•„ì´ë””ì–´ ì œì•ˆ
1. **ë‹¤ì–‘í•œ ëª¨ë¸ì— ëŒ€í•œ HAE ì ìš©:** ë‹¤ì–‘í•œ MLLM ëª¨ë¸ (ì˜ˆ: LLaVA, Gemini)ì— HAEë¥¼ ì ìš©í•˜ì—¬ ì„±ëŠ¥ ë° íš¨ìœ¨ì„±ì„ ë¹„êµ ë¶„ì„í•©ë‹ˆë‹¤.
2. **Scientific ë„ë©”ì¸ íŠ¹í™” HAE:** Scientific ì´ë¯¸ì§€ (ì˜ˆ: í˜„ë¯¸ê²½ ì´ë¯¸ì§€, ì˜ë£Œ ì˜ìƒ)ì˜ íŠ¹ì§•ì„ ê³ ë ¤í•˜ì—¬ HAE í”„ë ˆì„ì›Œí¬ë¥¼ ê°œì„ í•˜ê³ , Scientific document understanding taskì— ì ìš©í•©ë‹ˆë‹¤.
3. **HAEì™€ Vision Encoder ê°œì„ ì˜ ê²°í•©:** HAEì™€ í•¨ê»˜ Vision Encoderì˜ êµ¬ì¡°ë¥¼ ê°œì„ í•˜ì—¬, ë”ìš± íš¨ìœ¨ì ì¸ ì‹œê° ì •ë³´ ì¶”ì¶œ ë° í‘œí˜„ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, sparse attention ë©”ì»¤ë‹ˆì¦˜ì„ ì ìš©í•˜ì—¬ visual tokenì˜ sparsityë¥¼ ë”ìš± ë†’ì´ëŠ” ì—°êµ¬ë¥¼ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
4. **HAEì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìë™ íŠœë‹:** ê°•í™” í•™ìŠµ ë˜ëŠ” ë² ì´ì§€ì•ˆ ìµœì í™”ì™€ ê°™ì€ ë°©ë²•ì„ ì‚¬ìš©í•˜ì—¬ HAEì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ìë™ìœ¼ë¡œ íŠœë‹í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì„ ê°œë°œí•©ë‹ˆë‹¤.

### ğŸ“š í•µì‹¬ í‚¤ì›Œë“œ
1. Multimodal Large Language Model (MLLM)
2. KV Cache Management
3. Vision-Language Alignment
4. Hierarchical Adaptive Eviction (HAE)
5. Multimodal Reasoning


---

> ğŸ¤– ì´ ê¸€ì€ AI ì—°êµ¬ ì–´ì‹œìŠ¤í„´íŠ¸ì— ì˜í•´ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.
> ë¶„ì„ ëª¨ë¸: google/gemma-3-27b-it:free
