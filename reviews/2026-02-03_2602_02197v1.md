---
title: "Hierarchical Adaptive Eviction for KV Cache Management in Multimodal Language Mo"
date: 2026-02-03
arxiv: "2602.02197v1"
category: "cs.LG"
model: "google/gemma-3-4b-it:free"
---

# Hierarchical Adaptive Eviction for KV Cache Management in Multimodal Language Models

## ğŸ“– ë…¼ë¬¸ ì •ë³´

| í•­ëª© | ë‚´ìš© |
|------|------|
| **ì €ì** | Xindian Ma, Yidi Lu, Peng Zhang, Jing Zhang |
| **ë°œí‘œì¼** | 2026-02-02 |
| **arXiv** | [2602.02197v1](https://arxiv.org/pdf/2602.02197v1) |
| **ì¹´í…Œê³ ë¦¬** | cs.LG |

---

## ğŸ“ ì´ˆë¡ (Abstract)

The integration of visual information into Large Language Models (LLMs) has enabled Multimodal LLMs (MLLMs), but the quadratic memory and computational costs of Transformer architectures remain a bottleneck. Existing KV cache eviction strategies fail to address the heterogeneous attention distributions between visual and text tokens, leading to suboptimal efficiency or degraded performance. In this paper, we propose Hierarchical Adaptive Eviction (HAE), a KV cache eviction framework that optimizes text-visual token interaction in MLLMs by implementing Dual-Attention Pruning during pre-filling (leveraging visual token sparsity and attention variance) and a Dynamic Decoding Eviction Strategy (inspired by OS Recycle Bins) during decoding. HAE minimizes KV cache usage across layers, reduces computational overhead via index broadcasting, and theoretically ensures superior information integrity and lower error bounds compared to greedy strategies, enhancing efficiency in both comprehension and generation tasks. Empirically, HAE reduces KV-Cache memory by 41\% with minimal accuracy loss (0.3\% drop) in image understanding tasks and accelerates story generation inference by 1.5x while maintaining output quality on Phi3.5-Vision-Instruct model.

---

## ğŸ” AI ë¶„ì„

## ë…¼ë¬¸ ë¶„ì„: Hierarchical Adaptive Eviction for KV Cache Management in Multimodal Language Models

### ğŸ“„ ë…¼ë¬¸ ìš”ì•½
ë³¸ ë…¼ë¬¸ì€ ë©€í‹°ëª¨ë‹¬ LLM(MLLM)ì—ì„œ Transformer ê¸°ë°˜ì˜ KV ìºì‹œ ê´€ë¦¬ì˜ ë¹„íš¨ìœ¨ì„±ì„ í•´ê²°í•˜ê¸° ìœ„í•´ â€˜ê³„ì¸µì  ì ì‘í˜• ì¶”ë°©(Hierarchical Adaptive Eviction, HAE)â€™ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. HAEëŠ” ì‹œê°ì  í† í°ì˜ í¬ì†Œì„±ê³¼ ì£¼ì˜ ë¶„ì‚°ì˜ ë³€ë™ì„±ì„ í™œìš©í•œ Dual-Attention Pruningê³¼ OS Recycle Binsì—ì„œ ì˜ê°ì„ ì–»ì€ ë™ì  ë””ì½”ë”© ì¶”ë°© ì „ëµì„ í†µí•´ KV ìºì‹œ ì‚¬ìš©ëŸ‰ì„ ìµœì†Œí™”í•˜ê³  ê³„ì‚° ì˜¤ë²„í—¤ë“œë¥¼ ì¤„ì…ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ì´ë¯¸ì§€ ì´í•´ ì‘ì—…ì—ì„œ KV ìºì‹œ ë©”ëª¨ë¦¬ë¥¼ 41% ê°ì†Œì‹œí‚¤ê³ , Phi3.5-Vision-Instruct ëª¨ë¸ì—ì„œ ìŠ¤í† ë¦¬ ìƒì„± ì¶”ë¡  ì†ë„ë¥¼ 1.5ë°° ê°€ì†í™”í•˜ë©´ì„œë„ ì¶œë ¥ í’ˆì§ˆì„ ìœ ì§€í–ˆìŠµë‹ˆë‹¤.

### ğŸ†• ìƒˆë¡œìš´ ì  (Novelty)
ë³¸ ë…¼ë¬¸ì˜ í•µì‹¬ì ì¸ ìƒˆë¡œìš´ ì ì€ MLLMì˜ KV ìºì‹œ ê´€ë¦¬ì— ìˆì–´ ì‹œê°ì  í† í°ì˜ íŠ¹ì„±ì„ ê³ ë ¤í•œ ê³„ì¸µì  ì¶”ë°© ì „ëµì…ë‹ˆë‹¤. ê¸°ì¡´ì˜ Greedy ì „ëµì€ ì‹œê°ì  í† í°ê³¼ í…ìŠ¤íŠ¸ í† í° ê°„ì˜ ê· ì¼í•œ ì£¼ì˜ ë¶„í¬ë¥¼ ê°€ì •í•˜ì§€ë§Œ, HAEëŠ” ì‹œê°ì  í† í°ì˜ í¬ì†Œì„±ê³¼ ì£¼ì˜ ë¶„ì‚°ì˜ ë³€ë™ì„±ì„ í™œìš©í•˜ì—¬ ë”ìš± íš¨ìœ¨ì ì¸ ìºì‹œ ê´€ë¦¬ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. íŠ¹íˆ, Dual-Attention Pruningê³¼ Dynamic Decoding Eviction Strategyì˜ ì¡°í•©ì€ ê¸°ì¡´ ì—°êµ¬ì—ì„œ ì°¾ì•„ë³´ê¸° í˜ë“  ìƒˆë¡œìš´ ì ‘ê·¼ ë°©ì‹ì…ë‹ˆë‹¤.

### ğŸ’ª ê°•ì  (Strengths)
1. **íš¨ìœ¨ì ì¸ KV ìºì‹œ ê´€ë¦¬:** HAEëŠ” KV ìºì‹œ ì‚¬ìš©ëŸ‰ì„ 41% ê°ì†Œì‹œí‚¤ê³  ì¶”ë¡  ì†ë„ë¥¼ ê°€ì†í™”í•˜ì—¬ MLLMì˜ íš¨ìœ¨ì„±ì„ í¬ê²Œ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
2. **ì‹œê°ì  í† í° íŠ¹ì„± ê³ ë ¤:** ì‹œê°ì  í† í°ì˜ í¬ì†Œì„±ê³¼ ì£¼ì˜ ë¶„ì‚°ì„ ê³ ë ¤í•œ Dual-Attention Pruningì€ ê¸°ì¡´ ì „ëµì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³  ë”ìš± ì •í™•í•œ ì •ë³´ ë³´ì¡´ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.
3. **ì‹¤í—˜ì  ê²€ì¦:** Phi3.5-Vision-Instruct ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìŠ¤í† ë¦¬ ìƒì„± ì‘ì—…ì—ì„œ ì„±ëŠ¥ ìœ ì§€ ë° ì†ë„ í–¥ìƒì„ ì…ì¦í•¨ìœ¼ë¡œì¨ HAEì˜ íš¨ê³¼ë¥¼ ê°ê´€ì ìœ¼ë¡œ ê²€ì¦í–ˆìŠµë‹ˆë‹¤.

### âš ï¸ ì•½ì /í•œê³„ì  (Limitations)
1. **ëª¨ë¸ ì˜ì¡´ì„±:** HAEëŠ” Phi3.5-Vision-Instruct ëª¨ë¸ì—ì„œ íš¨ê³¼ë¥¼ ì…ì¦í–ˆì§€ë§Œ, ë‹¤ë¥¸ MLLM ëª¨ë¸ì—ì„œëŠ” ì„±ëŠ¥ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
2. **ê³„ì¸µì  ì¶”ë°© ì „ëµì˜ ë³µì¡ì„±:** ê³„ì¸µì  ì¶”ë°© ì „ëµì€ êµ¬í˜„ ë° íŠœë‹ì´ ë³µì¡í•  ìˆ˜ ìˆìœ¼ë©°, ì¶”ê°€ì ì¸ ì—°êµ¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.
3. **ì •ëŸ‰ì  ì •ë³´ ë³´ì¡´ ë³´ì¥:** ë…¼ë¬¸ì—ì„œ â€˜ì •ë³´ì˜ ë¬´ê²°ì„±â€™ê³¼ â€˜ì˜¤ë¥˜ ë²”ìœ„â€™ë¥¼ ë‚®ì¶˜ë‹¤ê³  ì–¸ê¸‰í–ˆì§€ë§Œ, ì´ë¥¼ ì •ëŸ‰ì ìœ¼ë¡œ ì¸¡ì •í•˜ê³  ë¶„ì„í•˜ëŠ” ë¶€ë¶„ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.

### ğŸ”— ë‚´ ì—°êµ¬ì™€ì˜ ì—°ê´€ì„±
ë³¸ ë…¼ë¬¸ì˜ KV ìºì‹œ ê´€ë¦¬ ì „ëµì€ ì œê°€ ì§„í–‰ ì¤‘ì¸ Vision Encoderì™€ Text LLM ê°„ì˜ ì •ë ¬ ì—°êµ¬ì— ì¤‘ìš”í•œ ì‹œì‚¬ì ì„ ì œê³µí•©ë‹ˆë‹¤. íŠ¹íˆ, ì‹œê°ì  í† í°ì˜ íŠ¹ì„±ì„ ê³ ë ¤í•œ ì¶”ë°© ì „ëµì€ Vision Encoderì˜ ì¶œë ¥ì„ LLMì— íš¨ê³¼ì ìœ¼ë¡œ ì „ë‹¬í•˜ê¸° ìœ„í•œ í•µì‹¬ì ì¸ ìš”ì†Œê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, MLLMì˜ íš¨ìœ¨ì ì¸ ì¶”ë¡ ì„ ìœ„í•œ KV ìºì‹œ ê´€ë¦¬ ê¸°ë²•ì€ ì œê°€ ì—°êµ¬í•˜ëŠ” Scientific MLLM í™œìš© ì—°êµ¬ì—ë„ ì ìš© ê°€ëŠ¥í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.

### ğŸ’¡ ì—°êµ¬ ì•„ì´ë””ì–´ ì œì•ˆ
1. **ë‹¤ì–‘í•œ MLLM ëª¨ë¸ ì ìš©:** HAE í”„ë ˆì„ì›Œí¬ë¥¼ ë‹¤ì–‘í•œ MLLM ëª¨ë¸ì— ì ìš©í•˜ì—¬ ì¼ë°˜í™” ì„±ëŠ¥ì„ í‰ê°€í•˜ê³ , ëª¨ë¸ë³„ ìµœì ì˜ íŒŒë¼ë¯¸í„°ë¥¼ íƒìƒ‰í•©ë‹ˆë‹¤.
2. **ê³„ì¸µì  ì¶”ë°© ì „ëµì˜ ë³€í˜•:** ê³„ì¸µì  ì¶”ë°© ì „ëµì˜ ê³„ì¸µ êµ¬ì¡°ë¥¼ ë³€ê²½í•˜ê±°ë‚˜, ì¶”ë°© ê¸°ì¤€ì„ ë”ìš± ì •êµí•˜ê²Œ ì¡°ì •í•˜ì—¬ ì„±ëŠ¥ì„ ê°œì„ í•©ë‹ˆë‹¤.
3. **ì •ë³´ì˜ ë¬´ê²°ì„± ì •ëŸ‰ì  ì¸¡ì •:** ì •ë³´ì˜ ë¬´ê²°ì„±ì„ ì •ëŸ‰ì ìœ¼ë¡œ ì¸¡ì •í•˜ëŠ” ì§€í‘œë¥¼ ê°œë°œí•˜ê³ , HAEê°€ ì´ëŸ¬í•œ ì§€í‘œì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•©ë‹ˆë‹¤.
4. **Scientific ë„ë©”ì¸ ì ìš©:** Scientific ë¬¸ì„œ ì´í•´ ë° ìƒì„± ì‘ì—…ì— HAEë¥¼ ì ìš©í•˜ì—¬ Scientific MLLMì˜ ì„±ëŠ¥ í–¥ìƒì„ í‰ê°€í•©ë‹ˆë‹¤.
5. **Attention Variance ê¸°ë°˜ì˜ Adaptive Pruning:** Dual-Attention Pruningì—ì„œ Attention Varianceë¥¼ ë”ìš± ì •êµí•˜ê²Œ í™œìš©í•˜ì—¬, ì‹œê°ì  í† í°ì˜ ì¤‘ìš”ë„ë¥¼ ë”ìš± ì •í™•í•˜ê²Œ íŒë‹¨í•˜ëŠ” ë°©ë²•ì„ ì—°êµ¬í•©ë‹ˆë‹¤.

### ğŸ“š í•µì‹¬ í‚¤ì›Œë“œ
1. Multimodal LLM (MLLM)
2. KV Cache Management
3. Hierarchical Adaptive Eviction (HAE)
4. Dual-Attention Pruning
5. Vision-Language Alignment


---

> ğŸ¤– ì´ ê¸€ì€ AI ì—°êµ¬ ì–´ì‹œìŠ¤í„´íŠ¸ì— ì˜í•´ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.
> ë¶„ì„ ëª¨ë¸: google/gemma-3-4b-it:free
