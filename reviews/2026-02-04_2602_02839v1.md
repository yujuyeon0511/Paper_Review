---
title: "Language Movement Primitives: Grounding Language Models in Robot Motion"
date: 2026-02-04
arxiv: "2602.02839v1"
category: "cs.RO"
model: "google/gemma-3-27b-it:free"
---

# Language Movement Primitives: Grounding Language Models in Robot Motion

## ğŸ“– ë…¼ë¬¸ ì •ë³´

| í•­ëª© | ë‚´ìš© |
|------|------|
| **ì €ì** | Yinlong Dai, Benjamin A. Christie, Daniel J. Evans, Dylan P. Losey, Simon Stepputtis |
| **ë°œí‘œì¼** | 2026-02-02 |
| **arXiv** | [2602.02839v1](https://arxiv.org/pdf/2602.02839v1) |
| **ì¹´í…Œê³ ë¦¬** | cs.RO |

---

## ğŸ“ ì´ˆë¡ (Abstract)

Enabling robots to perform novel manipulation tasks from natural language instructions remains a fundamental challenge in robotics, despite significant progress in generalized problem solving with foundational models. Large vision and language models (VLMs) are capable of processing high-dimensional input data for visual scene and language understanding, as well as decomposing tasks into a sequence of logical steps; however, they struggle to ground those steps in embodied robot motion. On the other hand, robotics foundation models output action commands, but require in-domain fine-tuning or experience before they are able to perform novel tasks successfully. At its core, there still remains the fundamental challenge of connecting abstract task reasoning with low-level motion control. To address this disconnect, we propose Language Movement Primitives (LMPs), a framework that grounds VLM reasoning in Dynamic Movement Primitive (DMP) parameterization. Our key insight is that DMPs provide a small number of interpretable parameters, and VLMs can set these parameters to specify diverse, continuous, and stable trajectories. Put another way: VLMs can reason over free-form natural language task descriptions, and semantically ground their desired motions into DMPs -- bridging the gap between high-level task reasoning and low-level position and velocity control. Building on this combination of VLMs and DMPs, we formulate our LMP pipeline for zero-shot robot manipulation that effectively completes tabletop manipulation problems by generating a sequence of DMP motions. Across 20 real-world manipulation tasks, we show that LMP achieves 80% task success as compared to 31% for the best-performing baseline. See videos at our website: https://collab.me.vt.edu/lmp

---

## ğŸ” AI ë¶„ì„

## ğŸ“„ ë…¼ë¬¸ ìš”ì•½
ë³¸ ë…¼ë¬¸ì€ ìì—°ì–´ ëª…ë ¹ì„ í†µí•´ ë¡œë´‡ì´ ìƒˆë¡œìš´ ì¡°ì‘ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ Language Movement Primitives (LMPs)ë¼ëŠ” í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. LMPsëŠ” VLMì˜ ì¶”ë¡  ëŠ¥ë ¥ì„ Dynamic Movement Primitive (DMP) íŒŒë¼ë¯¸í„°í™”ì— ì—°ê²°í•˜ì—¬, VLMì´ ìì—°ì–´ ì„¤ëª…ì„ ê¸°ë°˜ìœ¼ë¡œ ì›í•˜ëŠ” ë™ì‘ì„ DMPë¡œ ì˜ë¯¸ë¡ ì ìœ¼ë¡œ ë³€í™˜í•˜ë„ë¡ í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ê³ ìˆ˜ì¤€ì˜ ì‘ì—… ì¶”ë¡ ê³¼ ì €ìˆ˜ì¤€ì˜ ë™ì‘ ì œì–´ ì‚¬ì´ì˜ ê²©ì°¨ë¥¼ í•´ì†Œí•˜ê³ , ì œë¡œìƒ· ë¡œë´‡ ì¡°ì‘ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì‹¤ì œ í™˜ê²½ì—ì„œ 20ê°€ì§€ ì¡°ì‘ ì‘ì—…ì— ëŒ€í•´ 80%ì˜ ì„±ê³µë¥ ì„ ë‹¬ì„±í•˜ì—¬ ê¸°ì¡´ baseline ëŒ€ë¹„ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

### ğŸ†• ìƒˆë¡œìš´ ì  (Novelty)
LMPsëŠ” VLMê³¼ DMPë¥¼ ê²°í•©í•˜ì—¬ ë¡œë´‡ ì¡°ì‘ ë¶„ì•¼ì—ì„œ ìƒˆë¡œìš´ ì ‘ê·¼ ë°©ì‹ì„ ì œì‹œí•©ë‹ˆë‹¤. ê¸°ì¡´ ì—°êµ¬ë“¤ì´ VLMì´ë‚˜ ë¡œë´‡ íŒŒìš´ë°ì´ì…˜ ëª¨ë¸ ì¤‘ í•˜ë‚˜ì— ì˜ì¡´í–ˆë˜ ë°˜ë©´, ë³¸ ë…¼ë¬¸ì€ ë‘ ëª¨ë¸ì˜ ì¥ì ì„ í™œìš©í•˜ì—¬ ì¶”ë¡ ê³¼ ë™ì‘ ì œì–´ ì‚¬ì´ì˜ ì—°ê²°ì„ ê°•í™”í•©ë‹ˆë‹¤. íŠ¹íˆ, VLMì´ DMP íŒŒë¼ë¯¸í„°ë¥¼ ì§ì ‘ ì„¤ì •í•˜ì—¬ ë‹¤ì–‘í•œ ì—°ì†ì ì´ê³  ì•ˆì •ì ì¸ ê¶¤ì ì„ ìƒì„±í•œë‹¤ëŠ” ì ì´ í•µì‹¬ì ì¸ noveltyì…ë‹ˆë‹¤.

### ğŸ’ª ê°•ì  (Strengths)
1. **ì œë¡œìƒ· ì„±ëŠ¥:** ë³„ë„ì˜ in-domain fine-tuning ì—†ì´ë„ 80%ì˜ ë†’ì€ ì„±ê³µë¥ ì„ ë³´ì—¬, ìƒˆë¡œìš´ ì‘ì—…ì— ëŒ€í•œ ì ì‘ë ¥ì´ ë›°ì–´ë‚¨ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.
2. **í•´ì„ ê°€ëŠ¥ì„±:** DMP íŒŒë¼ë¯¸í„°ëŠ” í•´ì„ ê°€ëŠ¥í•˜ì—¬, VLMì´ ìƒì„±í•œ ë™ì‘ì„ ì´í•´í•˜ê³  ë””ë²„ê¹…í•˜ëŠ” ë° ìš©ì´í•©ë‹ˆë‹¤.
3. **ì¶”ë¡ ê³¼ ì œì–´ì˜ ì—°ê²°:** VLMì˜ ê³ ìˆ˜ì¤€ ì¶”ë¡  ëŠ¥ë ¥ì„ ë¡œë´‡ì˜ ì €ìˆ˜ì¤€ ë™ì‘ ì œì–´ì™€ íš¨ê³¼ì ìœ¼ë¡œ ì—°ê²°í•˜ì—¬, ë³µì¡í•œ ì¡°ì‘ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.

### âš ï¸ ì•½ì /í•œê³„ì  (Limitations)
1. **DMPì˜ í•œê³„:** DMPëŠ” íŠ¹ì • ìœ í˜•ì˜ ë™ì‘ì— ì í•©í•˜ë©°, ë³µì¡í•˜ê±°ë‚˜ ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥í•œ í™˜ê²½ì—ì„œëŠ” ì„±ëŠ¥ì´ ì €í•˜ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
2. **VLM ì˜ì¡´ì„±:** VLMì˜ ì„±ëŠ¥ì— ë”°ë¼ LMPsì˜ ì„±ëŠ¥ì´ í¬ê²Œ ì¢Œìš°ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. VLMì´ ì˜ëª»ëœ ì¶”ë¡ ì„ í•˜ê±°ë‚˜, DMP íŒŒë¼ë¯¸í„°ë¥¼ ë¶€ì ì ˆí•˜ê²Œ ì„¤ì •í•˜ë©´ ì‘ì—… ì‹¤íŒ¨ë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
3. **í…Œì´ë¸”íƒ‘ í™˜ê²½ ì œí•œ:** ì‹¤í—˜ì´ í…Œì´ë¸”íƒ‘ í™˜ê²½ì—ì„œë§Œ ì§„í–‰ë˜ì–´, ë‹¤ë¥¸ í™˜ê²½ì—ì„œì˜ ì¼ë°˜í™” ì„±ëŠ¥ì€ ê²€ì¦ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.

### ğŸ”— ë‚´ ì—°êµ¬ì™€ì˜ ì—°ê´€ì„±
ë³¸ ë…¼ë¬¸ì€ ì €ì˜ ì—°êµ¬ ë¶„ì•¼ì¸ Scientific MLLM, Reasoning MLLM, Vision-Language Alignmentì™€ ë°€ì ‘í•˜ê²Œ ê´€ë ¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ, VLMì„ í™œìš©í•˜ì—¬ ê³ ìˆ˜ì¤€ì˜ ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ê³  ì´ë¥¼ ë¡œë´‡ ë™ì‘ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ë°©ì‹ì€, Scientific ë„ë©”ì¸ì—ì„œ MLLMì„ í™œìš©í•˜ì—¬ ì‹¤í—˜ ê³¼ì •ì„ ìë™í™”í•˜ê±°ë‚˜, ì‹œë®¬ë ˆì´ì…˜ í™˜ê²½ì—ì„œ ë¡œë´‡ì„ ì œì–´í•˜ëŠ” ë° ì ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, vision encoderì™€ text LLM ê°„ì˜ ì •ë ¬(alignment) ì—°êµ¬ë¥¼ í†µí•´ VLMì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ë©´, LMPsì˜ ì„±ëŠ¥ ë˜í•œ ê°œì„ ë  ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤.

### ğŸ’¡ ì—°êµ¬ ì•„ì´ë””ì–´ ì œì•ˆ
1. **Scientific ë„ë©”ì¸ ì ìš©:** LMPsë¥¼ ê³¼í•™ ì‹¤í—˜ ìë™í™”ì— ì ìš©í•˜ì—¬, MLLMì´ ì‹¤í—˜ ì ˆì°¨ë¥¼ ì´í•´í•˜ê³  ë¡œë´‡ì„ ì œì–´í•˜ì—¬ ì‹¤í—˜ì„ ìˆ˜í–‰í•˜ë„ë¡ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, MLLMì´ í™”í•™ ë°˜ì‘ ê³¼ì •ì„ ì´í•´í•˜ê³  ë¡œë´‡ íŒ”ì„ ì œì–´í•˜ì—¬ ì‹œì•½ì„ í˜¼í•©í•˜ê³  ë°˜ì‘ì„ ê´€ì°°í•˜ëŠ” ì‹¤í—˜ì„ ìë™í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
2. **Vision Encoder ê°œì„ :** ë” ê°•ë ¥í•œ vision encoderë¥¼ ì‚¬ìš©í•˜ì—¬ VLMì˜ ì‹œê°ì  ì´í•´ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ê³ , LMPsì˜ ì„±ëŠ¥ì„ ê°œì„ í•©ë‹ˆë‹¤. íŠ¹íˆ, ê³¼í•™ì  ì´ë¯¸ì§€ë‚˜ ë°ì´í„°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” vision encoderë¥¼ ê°œë°œí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.
3. **Multimodal Reasoning ê°•í™”:** VLMì˜ multimodal reasoning ëŠ¥ë ¥ì„ ê°•í™”í•˜ì—¬, ë³µì¡í•œ ì‘ì—…ì— ëŒ€í•œ ì¶”ë¡  ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, MLLMì´ ì—¬ëŸ¬ ê°œì˜ ì‹œê°ì  ì •ë³´ì™€ í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ í†µí•©í•˜ì—¬ ì‘ì—… ê³„íšì„ ìˆ˜ë¦½í•˜ê³ , LMPsë¥¼ í†µí•´ ë¡œë´‡ ë™ì‘ìœ¼ë¡œ ë³€í™˜í•˜ë„ë¡ í•©ë‹ˆë‹¤.
4. **DMP í™•ì¥:** DMPì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´, ë” ìœ ì—°í•˜ê³  ë‹¤ì–‘í•œ ë™ì‘ì„ í‘œí˜„í•  ìˆ˜ ìˆëŠ” ìƒˆë¡œìš´ ë™ì‘ íŒŒë¼ë¯¸í„°í™” ë°©ë²•ì„ ì—°êµ¬í•©ë‹ˆë‹¤.

### ğŸ“š í•µì‹¬ í‚¤ì›Œë“œ
1. Language Movement Primitives (LMPs)
2. Dynamic Movement Primitive (DMP)
3. Vision-Language Model (VLM)
4. Robot Manipulation
5. Zero-Shot Learning


---

> ğŸ¤– ì´ ê¸€ì€ AI ì—°êµ¬ ì–´ì‹œìŠ¤í„´íŠ¸ì— ì˜í•´ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.
> ë¶„ì„ ëª¨ë¸: google/gemma-3-27b-it:free
