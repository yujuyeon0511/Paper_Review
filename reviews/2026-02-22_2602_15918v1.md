---
title: "EarthSpatialBench: Benchmarking Spatial Reasoning Capabilities of Multimodal LLM"
date: 2026-02-22
arxiv: "2602.15918v1"
category: "cs.CV"
model: "google/gemma-3-4b-it:free"
---

# EarthSpatialBench: Benchmarking Spatial Reasoning Capabilities of Multimodal LLMs on Earth Imagery

## ğŸ“– ë…¼ë¬¸ ì •ë³´

| í•­ëª© | ë‚´ìš© |
|------|------|
| **ì €ì** | Zelin Xu, Yupu Zhang, Saugat Adhikari, Saiful Islam, Tingsong Xiao... |
| **ë°œí‘œì¼** | 2026-02-17 |
| **arXiv** | [2602.15918v1](https://arxiv.org/pdf/2602.15918v1) |
| **ì¹´í…Œê³ ë¦¬** | cs.CV |

---

## ğŸ“ ì´ˆë¡ (Abstract)

Benchmarking spatial reasoning in multimodal large language models (MLLMs) has attracted growing interest in computer vision due to its importance for embodied AI and other agentic systems that require precise interaction with the physical world. However, spatial reasoning on Earth imagery has lagged behind, as it uniquely involves grounding objects in georeferenced images and quantitatively reasoning about distances, directions, and topological relations using both visual cues and vector geometry coordinates (e.g., 2D bounding boxes, polylines, and polygons). Existing benchmarks for Earth imagery primarily focus on 2D spatial grounding, image captioning, and coarse spatial relations (e.g., simple directional or proximity cues). They lack support for quantitative direction and distance reasoning, systematic topological relations, and complex object geometries beyond bounding boxes. To fill this gap, we propose \textbf{EarthSpatialBench}, a comprehensive benchmark for evaluating spatial reasoning in MLLMs on Earth imagery. The benchmark contains over 325K question-answer pairs spanning: (1) qualitative and quantitative reasoning about spatial distance and direction; (2) systematic topological relations; (3) single-object queries, object-pair queries, and compositional aggregate group queries; and (4) object references expressed via textual descriptions, visual overlays, and explicit geometry coordinates, including 2D bounding boxes, polylines, and polygons. We conducted extensive experiments on both open-source and proprietary models to identify limitations in the spatial reasoning of MLLMs.

---

## ğŸ” AI ë¶„ì„

## ë¶„ì„ ê²°ê³¼: EarthSpatialBench ë…¼ë¬¸ ë¶„ì„

### ğŸ“„ ë…¼ë¬¸ ìš”ì•½
ë³¸ ë…¼ë¬¸ì€ MLLMì˜ ê³µê°„ ì¶”ë¡  ëŠ¥ë ¥ í‰ê°€ë¥¼ ìœ„í•œ ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬, EarthSpatialBenchë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ ë²¤ì¹˜ë§ˆí¬ê°€ 2D ê³µê°„ ì§€í–¥ ë° ë‹¨ìˆœí•œ ê³µê°„ ê´€ê³„ì— ì§‘ì¤‘í•˜ëŠ” í•œê³„ì ì„ ê·¹ë³µí•˜ê¸° ìœ„í•´, ê±°ë¦¬, ë°©í–¥, í† í´ë¡œì§€, ë³µì¡í•œ ê°ì²´ ê¸°í•˜í•™ ë“± ë‹¤ì–‘í•œ ê³µê°„ ì¶”ë¡  ëŠ¥ë ¥ì„ í¬ê´„ì ìœ¼ë¡œ í‰ê°€í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. EarthSpatialBenchëŠ” 325,000ê°œ ì´ìƒì˜ ì§ˆë¬¸-ë‹µë³€ ìŒì„ í¬í•¨í•˜ë©°, ê°ì²´ ì„¤ëª…, ì‹œê°ì  ì˜¤ë²„ë ˆì´, ëª…ì‹œì ì¸ ê¸°í•˜ ì¢Œí‘œë¥¼ í™œìš©í•˜ì—¬ ë‹¤ì–‘í•œ ë°©ì‹ìœ¼ë¡œ ê³µê°„ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, í˜„ì¬ MLLMì€ ê³µê°„ ì¶”ë¡  ëŠ¥ë ¥ì—ì„œ ì—¬ì „íˆ í•œê³„ë¥¼ ë³´ì´ê³  ìˆìœ¼ë©°, EarthSpatialBenchëŠ” ì´ëŸ¬í•œ í•œê³„ë¥¼ íŒŒì•…í•˜ê³  ê°œì„ í•˜ëŠ” ë° ê¸°ì—¬í•  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë©ë‹ˆë‹¤.

### ğŸ†• ìƒˆë¡œìš´ ì  (Novelty)
ì´ ë…¼ë¬¸ì˜ ê°€ì¥ í° ìƒˆë¡œìš´ ì ì€ MLLMì˜ ê³µê°„ ì¶”ë¡  ëŠ¥ë ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ **ì§€ë¦¬ì  ì´ë¯¸ì§€ ê¸°ë°˜ì˜ ì¢…í•©ì ì¸ ë²¤ì¹˜ë§ˆí¬, EarthSpatialBench**ë¥¼ ì œì‹œí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ê¸°ì¡´ ë²¤ì¹˜ë§ˆí¬ë“¤ì´ 2D ê³µê°„ ì§€í–¥ ë° ë‹¨ìˆœí•œ ê³µê°„ ê´€ê³„ì—ë§Œ ì§‘ì¤‘í–ˆë‹¤ëŠ” ì ì„ ê³ ë ¤í•  ë•Œ, EarthSpatialBenchëŠ” **ê±°ë¦¬, ë°©í–¥, í† í´ë¡œì§€, ë³µì¡í•œ ê°ì²´ ê¸°í•˜í•™ ë“± ë‹¤ì–‘í•œ ê³µê°„ ì¶”ë¡  ëŠ¥ë ¥ì„ í¬ê´„ì ìœ¼ë¡œ í‰ê°€**í•  ìˆ˜ ìˆëŠ” ìƒˆë¡œìš´ ì ‘ê·¼ ë°©ì‹ì…ë‹ˆë‹¤. ë˜í•œ, **ê°ì²´ ì„¤ëª…, ì‹œê°ì  ì˜¤ë²„ë ˆì´, ê¸°í•˜ ì¢Œí‘œë¥¼ í™œìš©í•œ ë‹¤ì–‘í•œ ê³µê°„ ì •ë³´ ì œê³µ ë°©ì‹**ì€ MLLMì´ ê³µê°„ ì •ë³´ë¥¼ ë” íš¨ê³¼ì ìœ¼ë¡œ ì´í•´í•˜ê³  ì¶”ë¡ í•  ìˆ˜ ìˆë„ë¡ ë•ëŠ”ë‹¤ëŠ” ì ì—ì„œ ì˜ë¯¸ê°€ ìˆìŠµë‹ˆë‹¤.

### ğŸ’ª ê°•ì  (Strengths)
1. **í¬ê´„ì ì¸ í‰ê°€ ë²”ìœ„:** ê±°ë¦¬, ë°©í–¥, í† í´ë¡œì§€, ê°ì²´ ê¸°í•˜í•™ ë“± ë‹¤ì–‘í•œ ê³µê°„ ì¶”ë¡  ëŠ¥ë ¥ì„ í‰ê°€í•˜ì—¬ MLLMì˜ ê³µê°„ ì´í•´ë„ë¥¼ ì‹¬ì¸µì ìœ¼ë¡œ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
2. **ë‹¤ì–‘í•œ ì •ë³´ ì œê³µ ë°©ì‹:** ê°ì²´ ì„¤ëª…, ì‹œê°ì  ì˜¤ë²„ë ˆì´, ê¸°í•˜ ì¢Œí‘œë¥¼ í™œìš©í•˜ì—¬ MLLMì´ ê³µê°„ ì •ë³´ë¥¼ ë‹¤ì–‘í•œ ë°©ì‹ìœ¼ë¡œ ì´í•´í•˜ë„ë¡ ìœ ë„í•©ë‹ˆë‹¤. ì´ëŠ” MLLMì˜ ì¼ë°˜í™” ëŠ¥ë ¥ í–¥ìƒì— ê¸°ì—¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
3. **ì‹¤ìš©ì ì¸ ë²¤ì¹˜ë§ˆí¬:** 325,000ê°œ ì´ìƒì˜ ì§ˆë¬¸-ë‹µë³€ ìŒì„ í¬í•¨í•˜ëŠ” ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì„ ì œê³µí•˜ì—¬ MLLMì˜ ì„±ëŠ¥ì„ ê°ê´€ì ìœ¼ë¡œ í‰ê°€í•˜ê³  ë¹„êµí•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.

### âš ï¸ ì•½ì /í•œê³„ì  (Limitations)
1. **ì§€ë¦¬ì  ì´ë¯¸ì§€ì— íŠ¹í™”:** EarthSpatialBenchëŠ” ì§€ë¦¬ì  ì´ë¯¸ì§€ì— íŠ¹í™”ë˜ì–´ ìˆì–´, ë‹¤ë¥¸ ìœ í˜•ì˜ ì´ë¯¸ì§€ (ì˜ˆ: í’ê²½ ì‚¬ì§„, ì œí’ˆ ì‚¬ì§„)ì— ëŒ€í•œ MLLMì˜ ê³µê°„ ì¶”ë¡  ëŠ¥ë ¥ì„ í‰ê°€í•˜ê¸°ì—ëŠ” ì í•©í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
2. **ëª¨ë¸ ì˜ì¡´ì„±:** ì‹¤í—˜ ê²°ê³¼ëŠ” ì‚¬ìš©ëœ ì˜¤í”ˆì†ŒìŠ¤ ë° í”„ë¡œí¼í‹° ëª¨ë¸ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìœ¼ë©°, íŠ¹ì • ëª¨ë¸ì— í¸í–¥ë  ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.
3. **ë²¤ì¹˜ë§ˆí¬ ìì²´ì˜ í•œê³„:** ë²¤ì¹˜ë§ˆí¬ëŠ” íŠ¹ì • ëŠ¥ë ¥ì„ í‰ê°€í•˜ëŠ” ë° ìœ ìš©í•˜ì§€ë§Œ, MLLMì˜ ì „ë°˜ì ì¸ ì„±ëŠ¥ì„ ë‚˜íƒ€ë‚´ëŠ” ê²ƒì€ ì•„ë‹™ë‹ˆë‹¤.

### ğŸ”— ë‚´ ì—°êµ¬ì™€ì˜ ì—°ê´€ì„±
ë³¸ ë…¼ë¬¸ì˜ EarthSpatialBenchëŠ” ì œê°€ ì§„í–‰í•˜ê³  ìˆëŠ” **Vision-Text Alignment ì—°êµ¬**ì™€ ë°€ì ‘í•˜ê²Œ ê´€ë ¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ, MLLMì´ ì‹œê°ì  ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì´í•´í•˜ê³  ì¶”ë¡ í•˜ëŠ” ëŠ¥ë ¥ì€ Vision-Text Alignmentì˜ í•µì‹¬ ëª©í‘œ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. EarthSpatialBenchë¥¼ í™œìš©í•˜ì—¬ MLLMì˜ ê³µê°„ ì¶”ë¡  ëŠ¥ë ¥ì„ í‰ê°€í•˜ê³  ê°œì„ í•¨ìœ¼ë¡œì¨, Vision-Text Alignment ì—°êµ¬ì˜ ë°©í–¥ì„±ì„ ì„¤ì •í•˜ê³  ìƒˆë¡œìš´ ì—°êµ¬ ì•„ì´ë””ì–´ë¥¼ ë„ì¶œí•˜ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ì œ ì—°êµ¬ì—ì„œ ì‚¬ìš©í•˜ëŠ” **DocVQA, ChartQA**ì™€ ê°™ì€ ë¬¸ì„œ/ì°¨íŠ¸ ê¸°ë°˜ì˜ ì§ˆë¬¸ ì‘ë‹µ ì‹œìŠ¤í…œ ê°œë°œì—ë„ í™œìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ğŸ’¡ ì—°êµ¬ ì•„ì´ë””ì–´ ì œì•ˆ
1. **EarthSpatialBench í™•ì¥:** ë‹¤ì–‘í•œ ìœ í˜•ì˜ ì´ë¯¸ì§€ (ì˜ˆ: í’ê²½ ì‚¬ì§„, ì œí’ˆ ì‚¬ì§„)ë¥¼ í¬í•¨í•˜ì—¬ MLLMì˜ ê³µê°„ ì¶”ë¡  ëŠ¥ë ¥ì„ ë”ìš± í¬ê´„ì ìœ¼ë¡œ í‰ê°€í•  ìˆ˜ ìˆë„ë¡ EarthSpatialBenchë¥¼ í™•ì¥í•©ë‹ˆë‹¤.
2. **ìƒˆë¡œìš´ ê³µê°„ ì¶”ë¡  ëŠ¥ë ¥ í‰ê°€:** EarthSpatialBenchì— ìƒˆë¡œìš´ ê³µê°„ ì¶”ë¡  ëŠ¥ë ¥ì„ ì¶”ê°€í•˜ì—¬ MLLMì˜ ê³µê°„ ì´í•´ë„ë¥¼ ë”ìš± ì‹¬ì¸µì ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤. (ì˜ˆ: 3D ê³µê°„ ì¶”ë¡ , ì‹œê°„ì  ê³µê°„ ì¶”ë¡ )
3. **í•œêµ­ì–´ ì§€ë¦¬ ì •ë³´ ë²¤ì¹˜ë§ˆí¬:** í•œêµ­ì–´ ì§€ë¦¬ ì •ë³´ë¥¼ í™œìš©í•œ MLLMì˜ ê³µê°„ ì¶”ë¡  ëŠ¥ë ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ë²¤ì¹˜ë§ˆí¬ë¥¼ ê°œë°œí•©ë‹ˆë‹¤. ì´ëŠ” í•œêµ­ì–´ MLLM ê°œë°œì— ê¸°ì—¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
4. **ì‹œê°ì  Instruction Tuning í™œìš©:** EarthSpatialBenchë¥¼ í™œìš©í•˜ì—¬ MLLMì„ ì‹œê°ì  Instruction Tuningì„ í†µí•´ ê³µê°„ ì¶”ë¡  ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

### ğŸ“š í•µì‹¬ í‚¤ì›Œë“œ
1. Multimodal Large Language Models (MLLM)
2. Spatial Reasoning
3. Earth Imagery
4. Vision-Language Alignment
5. Benchmarking


---

> ğŸ¤– ì´ ê¸€ì€ AI ì—°êµ¬ ì–´ì‹œìŠ¤í„´íŠ¸ì— ì˜í•´ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.
> ë¶„ì„ ëª¨ë¸: google/gemma-3-4b-it:free
