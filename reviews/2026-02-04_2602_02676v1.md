---
title: "AdaptMMBench: Benchmarking Adaptive Multimodal Reasoning for Mode Selection and "
date: 2026-02-04
arxiv: "2602.02676v1"
category: "cs.CV"
model: "google/gemma-3-27b-it:free"
---

# AdaptMMBench: Benchmarking Adaptive Multimodal Reasoning for Mode Selection and Reasoning Process

## ğŸ“– ë…¼ë¬¸ ì •ë³´

| í•­ëª© | ë‚´ìš© |
|------|------|
| **ì €ì** | Xintong Zhang, Xiaowen Zhang, Jongrong Wu, Zhi Gao, Shilin Yan... |
| **ë°œí‘œì¼** | 2026-02-02 |
| **arXiv** | [2602.02676v1](https://arxiv.org/pdf/2602.02676v1) |
| **ì¹´í…Œê³ ë¦¬** | cs.CV |

---

## ğŸ“ ì´ˆë¡ (Abstract)

Adaptive multimodal reasoning has emerged as a promising frontier in Vision-Language Models (VLMs), aiming to dynamically modulate between tool-augmented visual reasoning and text reasoning to enhance both effectiveness and efficiency. However, existing evaluations rely on static difficulty labels and simplistic metrics, which fail to capture the dynamic nature of difficulty relative to varying model capacities. Consequently, they obscure the distinction between adaptive mode selection and general performance while neglecting fine-grained process analyses. In this paper, we propose AdaptMMBench, a comprehensive benchmark for adaptive multimodal reasoning across five domains: real-world, OCR, GUI, knowledge, and math, encompassing both direct perception and complex reasoning tasks. AdaptMMBench utilizes a Matthews Correlation Coefficient (MCC) metric to evaluate the selection rationality of different reasoning modes, isolating this meta-cognition ability by dynamically identifying task difficulties based on models' capability boundaries. Moreover, AdaptMMBench facilitates multi-dimensional process evaluation across key step coverage, tool effectiveness, and computational efficiency. Our evaluation reveals that while adaptive mode selection scales with model capacity, it notably decouples from final accuracy. Conversely, key step coverage aligns with performance, though tool effectiveness remains highly inconsistent across model architectures.

---

## ğŸ” AI ë¶„ì„

## AdaptMMBench ë…¼ë¬¸ ë¶„ì„

### ğŸ“„ ë…¼ë¬¸ ìš”ì•½
ë³¸ ë…¼ë¬¸ì€ Vision-Language Model (VLM)ì˜ ì ì‘ì  ë©€í‹°ëª¨ë‹¬ ì¶”ë¡  ëŠ¥ë ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ì¸ AdaptMMBenchë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ ë²¤ì¹˜ë§ˆí¬ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´, ëª¨ë¸ì˜ ëŠ¥ë ¥ì— ë”°ë¼ ë™ì ìœ¼ë¡œ ë‚œì´ë„ë¥¼ ì¡°ì ˆí•˜ê³ , ëª¨ë“œ ì„ íƒì˜ í•©ë¦¬ì„±ì„ í‰ê°€í•˜ëŠ” Matthews Correlation Coefficient (MCC)ë¥¼ ë„ì…í–ˆìŠµë‹ˆë‹¤. AdaptMMBenchëŠ” 5ê°€ì§€ ë„ë©”ì¸ì—ì„œ VLMì˜ ì¶”ë¡  ê³¼ì •, ë„êµ¬ í™œìš© íš¨ê³¼, ê³„ì‚° íš¨ìœ¨ì„±ì„ ë‹¤ê°ì ìœ¼ë¡œ ë¶„ì„í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ì ì‘ì  ëª¨ë“œ ì„ íƒì€ ëª¨ë¸ ìš©ëŸ‰ì— ë”°ë¼ í™•ì¥ë˜ì§€ë§Œ ìµœì¢… ì •í™•ë„ì™€ëŠ” ë¶„ë¦¬ë˜ë©°, í•µì‹¬ ë‹¨ê³„ ì»¤ë²„ë¦¬ì§€ê°€ ì„±ëŠ¥ê³¼ ë” ë°€ì ‘í•œ ê´€ë ¨ì´ ìˆìŒì„ ë°í˜”ìŠµë‹ˆë‹¤.

### ğŸ†• ìƒˆë¡œìš´ ì  (Novelty)
AdaptMMBenchëŠ” ê¸°ì¡´ VLM í‰ê°€ ë°©ì‹ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³  ì ì‘ì  ë©€í‹°ëª¨ë‹¬ ì¶”ë¡  ëŠ¥ë ¥ì„ ë³´ë‹¤ ì •í™•í•˜ê²Œ í‰ê°€í•˜ê¸° ìœ„í•œ ë‹¤ìŒê³¼ ê°™ì€ ìƒˆë¡œìš´ ì ì„ ì œì‹œí•©ë‹ˆë‹¤.

* **ë™ì  ë‚œì´ë„ ì¡°ì ˆ:** ëª¨ë¸ì˜ ëŠ¥ë ¥ì— ë”°ë¼ ë‚œì´ë„ë¥¼ ë™ì ìœ¼ë¡œ ì¡°ì ˆí•˜ì—¬, ëª¨ë¸ì˜ ì‹¤ì œ ì ì‘ ëŠ¥ë ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.
* **ëª¨ë“œ ì„ íƒ í•©ë¦¬ì„± í‰ê°€:** MCC metricì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ ëª¨ë“œ ì„ íƒì´ ì–¼ë§ˆë‚˜ í•©ë¦¬ì ì¸ì§€ ì •ëŸ‰ì ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤.
* **ë‹¤ì°¨ì›ì  ê³¼ì • í‰ê°€:** í•µì‹¬ ë‹¨ê³„ ì»¤ë²„ë¦¬ì§€, ë„êµ¬ íš¨ê³¼, ê³„ì‚° íš¨ìœ¨ì„±ì„ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€í•˜ì—¬ ì¶”ë¡  ê³¼ì •ì— ëŒ€í•œ ì‹¬ì¸µì ì¸ ë¶„ì„ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.

### ğŸ’ª ê°•ì  (Strengths)
1. **ì •êµí•œ í‰ê°€ í”„ë ˆì„ì›Œí¬:** AdaptMMBenchëŠ” ë‹¨ìˆœí•œ ì •í™•ë„ ì¸¡ì •ì—ì„œ ë²—ì–´ë‚˜, ëª¨ë¸ì˜ ì ì‘ ëŠ¥ë ¥, ëª¨ë“œ ì„ íƒì˜ í•©ë¦¬ì„±, ì¶”ë¡  ê³¼ì •ì˜ íš¨ìœ¨ì„±ì„ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€í•˜ëŠ” ì •êµí•œ í”„ë ˆì„ì›Œí¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
2. **ë‹¤ì–‘í•œ ë„ë©”ì¸ ì»¤ë²„ë¦¬ì§€:** 5ê°€ì§€ ë„ë©”ì¸(ì‹¤ìƒí™œ, OCR, GUI, ì§€ì‹, ìˆ˜í•™)ì„ í¬í•¨í•˜ì—¬ VLMì˜ ë‹¤ì–‘í•œ í™œìš© ì‹œë‚˜ë¦¬ì˜¤ë¥¼ í¬ê´„ì ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤.
3. **ì‹¤í—˜ì  í†µì°°ë ¥:** ì‹¤í—˜ ê²°ê³¼ë¥¼ í†µí•´ ì ì‘ì  ëª¨ë“œ ì„ íƒê³¼ ìµœì¢… ì •í™•ë„ì˜ ê´€ê³„, í•µì‹¬ ë‹¨ê³„ ì»¤ë²„ë¦¬ì§€ì˜ ì¤‘ìš”ì„±, ë„êµ¬ í™œìš© íš¨ê³¼ì˜ ë¶ˆì¼ì¹˜ ë“± VLM ì—°êµ¬ì— ì¤‘ìš”í•œ í†µì°°ë ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

### âš ï¸ ì•½ì /í•œê³„ì  (Limitations)
1. **MCC metricì˜ í•´ì„:** MCC metricì´ ëª¨ë“œ ì„ íƒì˜ í•©ë¦¬ì„±ì„ í‰ê°€í•˜ëŠ” ë° ìœ ìš©í•˜ì§€ë§Œ, ê·¸ í•´ì„ì´ ì§ê´€ì ì´ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. MCC ì ìˆ˜ê°€ ë‚®ê²Œ ë‚˜ì˜¤ëŠ” ê²½ìš°, ëª¨ë¸ì´ ë‹¨ìˆœíˆ ì˜ëª»ëœ ëª¨ë“œë¥¼ ì„ íƒí•œ ê²ƒì¸ì§€, ì•„ë‹ˆë©´ ë¬¸ì œ ìì²´ì˜ ë‚œì´ë„ê°€ ëª¨ë¸ì˜ ëŠ¥ë ¥ ë²”ìœ„ë¥¼ ë²—ì–´ë‚œ ê²ƒì¸ì§€ êµ¬ë¶„í•˜ê¸° ì–´ë ¤ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
2. **ë„êµ¬ íš¨ê³¼ì˜ ë¶ˆì¼ì¹˜ ì›ì¸ ë¶„ì„ ë¶€ì¡±:** ì‹¤í—˜ ê²°ê³¼, ë„êµ¬ íš¨ê³¼ê°€ ëª¨ë¸ ì•„í‚¤í…ì²˜ì— ë”°ë¼ í¬ê²Œ ë‹¤ë¥´ë‹¤ëŠ” ê²ƒì„ ë°í˜”ì§€ë§Œ, ê·¸ ì›ì¸ì— ëŒ€í•œ ì‹¬ì¸µì ì¸ ë¶„ì„ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.
3. **Scientific ë„ë©”ì¸ ë¶€ì¬:** ì‚¬ìš©ìì˜ ì—°êµ¬ ê´€ì‹¬ì‚¬ì¸ Scientific ë„ë©”ì¸ì´ ë²¤ì¹˜ë§ˆí¬ì— í¬í•¨ë˜ì§€ ì•Šì•„, Scientific MLLMì— ëŒ€í•œ ì§ì ‘ì ì¸ í‰ê°€ê°€ ì–´ë µìŠµë‹ˆë‹¤.

### ğŸ”— ë‚´ ì—°êµ¬ì™€ì˜ ì—°ê´€ì„±
ë³¸ ë…¼ë¬¸ì€ ì‚¬ìš©ìì˜ ì—°êµ¬, íŠ¹íˆ Vision encoderì™€ Text LLM ê°„ì˜ ì •ë ¬(alignment) ì—°êµ¬ì™€ ë°€ì ‘í•˜ê²Œ ê´€ë ¨ë©ë‹ˆë‹¤. AdaptMMBenchëŠ” VLMì˜ ì ì‘ì  ì¶”ë¡  ëŠ¥ë ¥ì„ í‰ê°€í•˜ëŠ” ë° ì‚¬ìš©ë  ìˆ˜ ìˆìœ¼ë©°, ì´ë¥¼ í†µí•´ ë‹¤ì–‘í•œ Vision encoderì™€ LLM ì¡°í•©ì˜ ì„±ëŠ¥ì„ ë¹„êµí•˜ê³ , ì •ë ¬ ì „ëµì˜ íš¨ê³¼ë¥¼ ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, Scientific ë„ë©”ì¸ì—ì„œì˜ MLLM í™œìš© ì—°êµ¬ë¥¼ ìœ„í•´ AdaptMMBenchë¥¼ í™•ì¥í•˜ê±°ë‚˜, ìœ ì‚¬í•œ í”„ë ˆì„ì›Œí¬ë¥¼ êµ¬ì¶•í•˜ëŠ” ë° ì°¸ê³ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ğŸ’¡ ì—°êµ¬ ì•„ì´ë””ì–´ ì œì•ˆ
1. **AdaptMMBenchì˜ Scientific ë„ë©”ì¸ í™•ì¥:** AdaptMMBenchë¥¼ Scientific ë„ë©”ì¸(ì˜ˆ: í™”í•™ êµ¬ì¡°ì‹ ì´í•´, ì˜í•™ ì´ë¯¸ì§€ ë¶„ì„)ìœ¼ë¡œ í™•ì¥í•˜ì—¬, Scientific MLLMì˜ ì ì‘ì  ì¶”ë¡  ëŠ¥ë ¥ì„ í‰ê°€í•˜ëŠ” ë²¤ì¹˜ë§ˆí¬ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤.
2. **Vision Encoder-LLM ì •ë ¬ ì „ëµ í‰ê°€:** AdaptMMBenchë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ì–‘í•œ Vision encoderì™€ LLM ì¡°í•©ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê³ , ì •ë ¬ ì „ëµ(ì˜ˆ: projection layer, adapter)ì´ ì ì‘ì  ì¶”ë¡  ëŠ¥ë ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•©ë‹ˆë‹¤.
3. **ë„êµ¬ íš¨ê³¼ ë¶ˆì¼ì¹˜ ì›ì¸ ë¶„ì„:** AdaptMMBenchì—ì„œ ê´€ì°°ëœ ë„êµ¬ íš¨ê³¼ì˜ ë¶ˆì¼ì¹˜ ì›ì¸ì„ ë¶„ì„í•˜ê³ , ëª¨ë¸ ì•„í‚¤í…ì²˜, ë„êµ¬ì˜ ì¢…ë¥˜, ë¬¸ì œì˜ ë‚œì´ë„ ë“± ë‹¤ì–‘í•œ ìš”ì¸ì´ ë„êµ¬ íš¨ê³¼ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ê·œëª…í•©ë‹ˆë‹¤.
4. **MCC metric ê°œì„ :** MCC metricì˜ í•´ì„ì„ ìš©ì´í•˜ê²Œ í•˜ê³ , ëª¨ë¸ì˜ ëª¨ë“œ ì„ íƒ ì „ëµì— ëŒ€í•œ ë” ê¹Šì€ í†µì°°ë ¥ì„ ì œê³µí•  ìˆ˜ ìˆë„ë¡ MCC metricì„ ê°œì„ í•©ë‹ˆë‹¤.

### ğŸ“š í•µì‹¬ í‚¤ì›Œë“œ
1. Adaptive Multimodal Reasoning
2. Vision-Language Models (VLMs)
3. Benchmarking
4. Mode Selection
5. Multimodal Reasoning Process Evaluation

---

> ğŸ¤– ì´ ê¸€ì€ AI ì—°êµ¬ ì–´ì‹œìŠ¤í„´íŠ¸ì— ì˜í•´ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.
> ë¶„ì„ ëª¨ë¸: google/gemma-3-27b-it:free
