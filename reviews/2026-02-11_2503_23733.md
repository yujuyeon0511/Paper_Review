---
title: "AdaMMS: Model Merging for Heterogeneous Multimodal Large Language Models with Un"
date: 2026-02-11
arxiv: "2503.23733"
category: "Computer Vision and Pattern Recognition"
model: "google/gemma-3-27b-it:free"
---

# AdaMMS: Model Merging for Heterogeneous Multimodal Large Language Models with Unsupervised Coefficient Optimization

## ğŸ“– ë…¼ë¬¸ ì •ë³´

| í•­ëª© | ë‚´ìš© |
|------|------|
| **ì €ì** | Yiyang Du, Xiaochen Wang, Chi Chen, Jiabo Ye, Yiru Wang... |
| **ë°œí‘œì¼** | 2025-03-31 |
| **arXiv** | [2503.23733](https://arxiv.org/pdf/2503.23733) |
| **ì¹´í…Œê³ ë¦¬** | Computer Vision and Pattern Recognition |

---

## ğŸ“ ì´ˆë¡ (Abstract)

Recently, model merging methods have demonstrated powerful strengths in combining abilities on various tasks from multiple Large Language Models (LLMs). While previous model merging methods mainly focus on merging homogeneous models with identical architecture, they meet challenges when dealing with Multimodal Large Language Models (MLLMs) with inherent heterogeneous property, including differences in model architecture and the asymmetry in the parameter space. In this work, we propose AdaMMS 1, a novel model merging method tailored for heterogeneous MLLMs. Our method tackles the challenges in three steps: mapping, merging and searching. Specifically, we first design mapping function between models to apply model merging on MLLMs with different architecture. Then we apply linear interpolation on model weights to actively adapt the asymmetry in the heterogeneous MLLMs. Finally in the hyper-parameter searching step, we propose an unsupervised hyper-parameter selection method for model merging. As the first model merging method capable of merging heterogeneous MLLMs without labeled data, extensive experiments on various model combinations demonstrated that AdaMMS outperforms previous model merging methods on various vision-language benchmarks. 2

---

## ğŸ” AI ë¶„ì„

## ë…¼ë¬¸ ë¶„ì„: AdaMMS: Model Merging for Heterogeneous Multimodal Large Language Models with Unsupervised Coefficient Optimization

### ë…¼ë¬¸ ìš”ì•½
ë³¸ ë…¼ë¬¸ì€ ì´ì§ˆì ì¸ êµ¬ì¡°ë¥¼ ê°€ì§„ Multimodal Large Language Models (MLLMs)ì˜ ëª¨ë¸ ë³‘í•©(model merging) ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ AdaMMSë¼ëŠ” ìƒˆë¡œìš´ ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ ëª¨ë¸ ë³‘í•© ë°©ë²•ë“¤ì´ ë™ì¼í•œ ì•„í‚¤í…ì²˜ë¥¼ ê°€ì§„ ëª¨ë¸ì— ì´ˆì ì„ ë§ì¶˜ ë°˜ë©´, AdaMMSëŠ” ëª¨ë¸ ê°„ ì•„í‚¤í…ì²˜ ì°¨ì´ì™€ íŒŒë¼ë¯¸í„° ê³µê°„ì˜ ë¹„ëŒ€ì¹­ì„±ì„ í•´ê²°í•˜ê¸° ìœ„í•´ ë§¤í•‘, ë³‘í•©, íƒìƒ‰ì˜ ì„¸ ë‹¨ê³„ ì ‘ê·¼ ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. íŠ¹íˆ, ë ˆì´ë¸”ë§ëœ ë°ì´í„° ì—†ì´ë„ ëª¨ë¸ ë³‘í•©ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ë¹„ì§€ë„ í•™ìŠµ ê¸°ë°˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„ íƒ ë°©ë²•ì„ ì œì‹œí•˜ë©°, ë‹¤ì–‘í•œ ë¹„ì „-ì–¸ì–´ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ê¸°ì¡´ ë°©ë²• ëŒ€ë¹„ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.

### ë°©ë²•ë¡  (Methodology)
AdaMMSëŠ” ì´ì§ˆì ì¸ MLLM ë³‘í•©ì„ ìœ„í•œ 3ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ì„ ì œì‹œí•©ë‹ˆë‹¤.

1.  **Mapping:** ì„œë¡œ ë‹¤ë¥¸ ì•„í‚¤í…ì²˜ë¥¼ ê°€ì§„ MLLM ê°„ì˜ ë§¤í•‘ í•¨ìˆ˜ë¥¼ ì„¤ê³„í•˜ì—¬ ëª¨ë¸ ë³‘í•©ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. êµ¬ì²´ì ì¸ ë§¤í•‘ í•¨ìˆ˜ì— ëŒ€í•œ ì„¤ëª…ì€ ì´ˆë¡ì— ëª…ì‹œë˜ì§€ ì•Šì•„ ì›ë¬¸ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.
2.  **Merging:** ëª¨ë¸ ê°€ì¤‘ì¹˜ì— ì„ í˜• ë³´ê°„ë²•(linear interpolation)ì„ ì ìš©í•˜ì—¬ ì´ì§ˆì ì¸ MLLMì˜ ë¹„ëŒ€ì¹­ì„±ì„ ì ê·¹ì ìœ¼ë¡œ ì¡°ì •í•©ë‹ˆë‹¤. ì´ëŠ” ê° ëª¨ë¸ì˜ ê¸°ì—¬ë„ë¥¼ ì¡°ì ˆí•˜ì—¬ ë³‘í•© ì„±ëŠ¥ì„ ìµœì í™”í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.
3.  **Searching:** ëª¨ë¸ ë³‘í•©ì„ ìœ„í•œ ë¹„ì§€ë„ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„ íƒ ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ë ˆì´ë¸”ë§ëœ ë°ì´í„° ì—†ì´ë„ ìµœì ì˜ ë³‘í•© ë¹„ìœ¨ì„ ì°¾ì•„ ì„±ëŠ¥ì„ ê·¹ëŒ€í™”í•©ë‹ˆë‹¤.

ì´ˆë¡ì—ì„œëŠ” ì‚¬ìš©ëœ backbone ëª¨ë¸, vision encoder, LLM ì¢…ë¥˜ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì–¸ê¸‰ì€ ì—†ìŠµë‹ˆë‹¤.

### ì‹¤í—˜ ë° ê²°ê³¼ (Experiments & Results)
-   **ì‚¬ìš©ëœ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹:** ì´ˆë¡ì—ì„œëŠ” êµ¬ì²´ì ì¸ ë°ì´í„°ì…‹ ì´ë¦„ì´ ëª…ì‹œë˜ì§€ ì•Šì•˜ì§€ë§Œ, "various vision-language benchmarks"ë¼ê³  ì–¸ê¸‰ë˜ì–´ ìˆì–´ ë‹¤ì–‘í•œ ë¹„ì „-ì–¸ì–´ ì´í•´ ëŠ¥ë ¥ì„ í‰ê°€í•˜ëŠ” ë°ì´í„°ì…‹ì„ ì‚¬ìš©í–ˆìŒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì˜ˆ: MMBench, SEED-Bench, DocVQA, ChartQA ë“±)
-   **ë¹„êµ ëŒ€ìƒ ëª¨ë¸ (baseline):** ê¸°ì¡´ì˜ ëª¨ë¸ ë³‘í•© ë°©ë²•ë“¤ (previous model merging methods)ê³¼ ë¹„êµí–ˆìŠµë‹ˆë‹¤.
-   **ìˆ˜ì¹˜ ê²°ê³¼:** ì´ˆë¡ì— êµ¬ì²´ì  ìˆ˜ì¹˜ ë¯¸ê¸°ì¬, ì›ë¬¸ í™•ì¸ í•„ìš”.
-   **SOTA ë‹¬ì„± ì—¬ë¶€ ë° ê°œì„  í­:** ì´ˆë¡ì— "AdaMMS outperforms previous model merging methods"ë¼ê³  ì–¸ê¸‰ë˜ì–´ ìˆì–´, ê¸°ì¡´ ëª¨ë¸ ë³‘í•© ë°©ë²• ëŒ€ë¹„ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì˜€ìŒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. êµ¬ì²´ì ì¸ ê°œì„  í­ì€ ì›ë¬¸ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.

### ìƒˆë¡œìš´ ì  (Novelty)
ë³¸ ë…¼ë¬¸ì˜ ê°€ì¥ í° í˜ì‹ ì€ ë ˆì´ë¸”ë§ëœ ë°ì´í„° ì—†ì´ë„ ì´ì§ˆì ì¸ MLLMì„ ë³‘í•©í•  ìˆ˜ ìˆë‹¤ëŠ” ì ì…ë‹ˆë‹¤. ê¸°ì¡´ ëª¨ë¸ ë³‘í•© ë°©ë²•ë“¤ì€ ì£¼ë¡œ ë™ì¼í•œ ì•„í‚¤í…ì²˜ë¥¼ ê°€ì§„ ëª¨ë¸ì— ì ìš©ë˜ì—ˆìœ¼ë©°, ì´ì§ˆì ì¸ ëª¨ë¸ ë³‘í•©ì—ëŠ” ì–´ë ¤ì›€ì„ ê²ªì—ˆìŠµë‹ˆë‹¤. AdaMMSëŠ” ë§¤í•‘ í•¨ìˆ˜ ì„¤ê³„, ì„ í˜• ë³´ê°„ë²• ì ìš©, ë¹„ì§€ë„ í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ì„ í†µí•´ ì´ëŸ¬í•œ í•œê³„ë¥¼ ê·¹ë³µí–ˆìŠµë‹ˆë‹¤.

### ê°•ì  (Strengths)
1.  **ì´ì§ˆì ì¸ MLLM ë³‘í•©:** ê¸°ì¡´ ë°©ë²•ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³  ì´ì§ˆì ì¸ MLLMì„ íš¨ê³¼ì ìœ¼ë¡œ ë³‘í•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
2.  **ë¹„ì§€ë„ í•™ìŠµ:** ë ˆì´ë¸”ë§ëœ ë°ì´í„° ì—†ì´ë„ ëª¨ë¸ ë³‘í•©ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆì–´ ë°ì´í„° ìˆ˜ì§‘ ë° ë ˆì´ë¸”ë§ ë¹„ìš©ì„ ì ˆê°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
3.  **ì„±ëŠ¥ í–¥ìƒ:** ë‹¤ì–‘í•œ ë¹„ì „-ì–¸ì–´ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ê¸°ì¡´ ë°©ë²• ëŒ€ë¹„ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.

### ì•½ì /í•œê³„ì  (Limitations)
1.  **ë§¤í•‘ í•¨ìˆ˜ ì„¤ê³„:** ëª¨ë¸ ê°„ ì•„í‚¤í…ì²˜ ì°¨ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ë§¤í•‘ í•¨ìˆ˜ ì„¤ê³„ê°€ ë³µì¡í•  ìˆ˜ ìˆìœ¼ë©°, ì„±ëŠ¥ì— í° ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
2.  **ì„ í˜• ë³´ê°„ë²•ì˜ í•œê³„:** ì„ í˜• ë³´ê°„ë²•ì´ ëª¨ë“  ê²½ìš°ì— ìµœì ì˜ ë³‘í•© ê²°ê³¼ë¥¼ ë³´ì¥í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
3.  **ì´ˆë¡ì˜ ì •ë³´ ë¶€ì¡±:** ì´ˆë¡ì—ì„œ êµ¬ì²´ì ì¸ ì‹¤í—˜ ì„¤ì •, ë°ì´í„°ì…‹, ìˆ˜ì¹˜ ê²°ê³¼ ë“±ì´ ë¶€ì¡±í•˜ì—¬ ë…¼ë¬¸ì˜ ì „ì²´ì ì¸ ë‚´ìš©ì„ íŒŒì•…í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤.

### ë‚´ ì—°êµ¬ì™€ì˜ ì—°ê´€ì„±
ë³¸ ë…¼ë¬¸ì€ ì œ ì—°êµ¬ ë¶„ì•¼ì¸ MLLM merging, Korean MLLM, vision-text alignment, document/chart/OCR/table VQAì™€ ë§¤ìš° ë°€ì ‘í•˜ê²Œ ê´€ë ¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ, MLLM mergingì„ í†µí•œ ì„±ëŠ¥ í–¥ìƒ ì—°êµ¬ì— ì§ì ‘ì ì¸ ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìœ¼ë©°, í•œêµ­ì–´ MLLM ê°œë°œ ë° í‰ê°€ì—ë„ ì ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤. ë˜í•œ, ë¬¸ì„œ/ì°¨íŠ¸/OCR/í…Œì´ë¸” ì´í•´ íŠ¹í™” MLLM ì—°êµ¬ì— ìˆì–´ ë‹¤ì–‘í•œ ëª¨ë¸ì„ íš¨ê³¼ì ìœ¼ë¡œ ê²°í•©í•˜ëŠ” ë°©ë²•ì„ ì œì‹œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ì—°êµ¬ ì•„ì´ë””ì–´ ì œì•ˆ
1.  **í•œêµ­ì–´ MLLM ë³‘í•©:** AdaMMSë¥¼ í™œìš©í•˜ì—¬ í•œêµ­ì–´ MLLMì„ ë³‘í•©í•˜ê³ , í•œêµ­ì–´ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.
2.  **DocVQA/ChartQA íŠ¹í™” MLLM ë³‘í•©:** ë¬¸ì„œ/ì°¨íŠ¸ ì´í•´ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ DocVQA/ChartQA ë°ì´í„°ì…‹ì— íŠ¹í™”ëœ MLLMì„ AdaMMSë¥¼ í†µí•´ ë³‘í•©í•©ë‹ˆë‹¤.
3.  **ë¹„ì§€ë„ í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ ë°©ë²• ê°œì„ :** AdaMMSì—ì„œ ì œì•ˆëœ ë¹„ì§€ë„ í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ ë°©ë²•ì„ ê°œì„ í•˜ì—¬ ë”ìš± íš¨ìœ¨ì ì¸ ëª¨ë¸ ë³‘í•©ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. (ì˜ˆ: ê°•í™” í•™ìŠµ ê¸°ë°˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰)

### í•µì‹¬ í‚¤ì›Œë“œ
1.  Model Merging
2.  Multimodal Large Language Models (MLLMs)
3.  Vision-Language Alignment
4.  Unsupervised Learning
5.  Heterogeneous Models
6.  Linear Interpolation
7.  Hyperparameter Optimization


---

> ğŸ¤– ì´ ê¸€ì€ AI ì—°êµ¬ ì–´ì‹œìŠ¤í„´íŠ¸ì— ì˜í•´ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.
> ë¶„ì„ ëª¨ë¸: google/gemma-3-27b-it:free
