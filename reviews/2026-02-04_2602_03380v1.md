---
title: "Seeing Through the Chain: Mitigate Hallucination in Multimodal Reasoning Models "
date: 2026-02-04
arxiv: "2602.03380v1"
category: "cs.CV"
model: "google/gemma-3-27b-it:free"
---

# Seeing Through the Chain: Mitigate Hallucination in Multimodal Reasoning Models via CoT Compression and Contrastive Preference Optimization

## ğŸ“– ë…¼ë¬¸ ì •ë³´

| í•­ëª© | ë‚´ìš© |
|------|------|
| **ì €ì** | Hao Fang, Jinyu Li, Jiawei Kong, Tianqu Zhuang, Kuofeng Gao... |
| **ë°œí‘œì¼** | 2026-02-03 |
| **arXiv** | [2602.03380v1](https://arxiv.org/pdf/2602.03380v1) |
| **ì¹´í…Œê³ ë¦¬** | cs.CV |

---

## ğŸ“ ì´ˆë¡ (Abstract)

While multimodal reasoning models (MLRMs) have exhibited impressive capabilities, they remain prone to hallucinations, and effective solutions are still underexplored. In this paper, we experimentally analyze the hallucination cause and propose C3PO, a training-based mitigation framework comprising \textbf{C}hain-of-Thought \textbf{C}ompression and \textbf{C}ontrastive \textbf{P}reference \textbf{O}ptimization. Firstly, we identify that introducing reasoning mechanisms exacerbates models' reliance on language priors while overlooking visual inputs, which can produce CoTs with reduced visual cues but redundant text tokens. To this end, we propose to selectively filter redundant thinking tokens for a more compact and signal-efficient CoT representation that preserves task-relevant information while suppressing noise. In addition, we observe that the quality of the reasoning trace largely determines whether hallucination emerges in subsequent responses. To leverage this insight, we introduce a reasoning-enhanced preference tuning scheme that constructs training pairs using high-quality AI feedback. We further design a multimodal hallucination-inducing mechanism that elicits models' inherent hallucination patterns via carefully crafted inducers, yielding informative negative signals for contrastive correction. We provide theoretical justification for the effectiveness and demonstrate consistent hallucination reduction across diverse MLRMs and benchmarks.

---

## ğŸ” AI ë¶„ì„

## ğŸ“„ ë…¼ë¬¸ ìš”ì•½
ë³¸ ë…¼ë¬¸ì€ Multimodal Large Language Models (MLLM)ì˜ ì¶”ë¡  ê³¼ì •ì—ì„œ ë°œìƒí•˜ëŠ” í™˜ê°(hallucination) í˜„ìƒì„ ì™„í™”í•˜ê¸° ìœ„í•œ C3PO í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. C3POëŠ” Chain-of-Thought (CoT) ì••ì¶•ì„ í†µí•´ ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ í† í°ì„ ì œê±°í•˜ê³ , Contrastive Preference Optimizationì„ í†µí•´ ê³ í’ˆì§ˆì˜ ì¶”ë¡  ê³¼ì •ì„ í•™ìŠµí•˜ë„ë¡ ìœ ë„í•©ë‹ˆë‹¤. íŠ¹íˆ, ì‹œê° ì •ë³´ì— ëŒ€í•œ ì˜ì¡´ë„ë¥¼ ë†’ì´ê³  ì–¸ì–´ì  í¸í–¥ì„ ì¤„ì—¬ í™˜ê° í˜„ìƒì„ íš¨ê³¼ì ìœ¼ë¡œ ê°ì†Œì‹œí‚¤ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ë‹¤ì–‘í•œ MLLMê³¼ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ì¼ê´€ëœ í™˜ê° ê°ì†Œ íš¨ê³¼ë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤.

### ğŸ†• ìƒˆë¡œìš´ ì  (Novelty)
* **CoT ì••ì¶•:** ê¸°ì¡´ CoT ë°©ì‹ì˜ ë¬¸ì œì ì¸ ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ í† í°ìœ¼ë¡œ ì¸í•œ ì‹œê° ì •ë³´ í¬ì„ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, í•µì‹¬ ì •ë³´ë§Œ ë‚¨ê¸°ê³  CoTë¥¼ ì••ì¶•í•˜ëŠ” ìƒˆë¡œìš´ ë°©ì‹ì„ ì œì•ˆí–ˆìŠµë‹ˆë‹¤.
* **Reasoning-enhanced Preference Tuning:** ì¶”ë¡  ê³¼ì •ì˜ í’ˆì§ˆì´ ìµœì¢… ë‹µë³€ì˜ ì •í™•ì„±ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ê³ ë ¤í•˜ì—¬, ê³ í’ˆì§ˆ AI í”¼ë“œë°±ì„ í™œìš©í•œ Contrastive Preference Optimizationì„ í†µí•´ ëª¨ë¸ì´ ë” ë‚˜ì€ ì¶”ë¡  ê³¼ì •ì„ í•™ìŠµí•˜ë„ë¡ ìœ ë„í•©ë‹ˆë‹¤.
* **Multimodal Hallucination-inducing Mechanism:** ëª¨ë¸ì˜ í™˜ê° íŒ¨í„´ì„ ëª…í™•í•˜ê²Œ íŒŒì•…í•˜ê¸° ìœ„í•´, íŠ¹ì • í™˜ê°ì„ ìœ ë„í•˜ëŠ” ë©”ì»¤ë‹ˆì¦˜ì„ ì„¤ê³„í•˜ì—¬ í•™ìŠµì— í™œìš©í•©ë‹ˆë‹¤.

### ğŸ’ª ê°•ì  (Strengths)
1. **í™˜ê° ë¬¸ì œì— ëŒ€í•œ ì‹¬ì¸µì ì¸ ë¶„ì„:** MLLMì˜ í™˜ê° í˜„ìƒ ë°œìƒ ì›ì¸ì„ ì–¸ì–´ì  í¸í–¥ê³¼ ì‹œê° ì •ë³´ ë¶€ì¡±ìœ¼ë¡œ ê·œëª…í•˜ê³ , ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ êµ¬ì²´ì ì¸ ë°©ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤.
2. **ì‹¤í—˜ì  ê²€ì¦:** ë‹¤ì–‘í•œ MLLMê³¼ ë²¤ì¹˜ë§ˆí¬ë¥¼ í†µí•´ C3PO í”„ë ˆì„ì›Œí¬ì˜ íš¨ê³¼ë¥¼ ì…ì¦í•˜ì—¬, ì œì•ˆí•˜ëŠ” ë°©ë²•ë¡ ì˜ ì‹¤ìš©ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
3. **ì´ë¡ ì  ê·¼ê±° ì œì‹œ:** C3POì˜ íš¨ê³¼ì— ëŒ€í•œ ì´ë¡ ì  ê·¼ê±°ë¥¼ ì œì‹œí•˜ì—¬, ë°©ë²•ë¡ ì˜ ì‹ ë¢°ì„±ì„ ë†’ì…ë‹ˆë‹¤.

### âš ï¸ ì•½ì /í•œê³„ì  (Limitations)
* **AI í”¼ë“œë°±ì˜ í’ˆì§ˆ ì˜ì¡´ì„±:** Reasoning-enhanced Preference Tuningì€ ê³ í’ˆì§ˆ AI í”¼ë“œë°±ì— í¬ê²Œ ì˜ì¡´í•©ë‹ˆë‹¤. AI í”¼ë“œë°±ì˜ í’ˆì§ˆì´ ë‚®ì„ ê²½ìš°, ì˜¤íˆë ¤ ì„±ëŠ¥ ì €í•˜ë¥¼ ì•¼ê¸°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
* **Hallucination-inducing Mechanismì˜ ì„¤ê³„ ë‚œì´ë„:** íš¨ê³¼ì ì¸ í™˜ê° ìœ ë„ë¥¼ ìœ„í•œ ì¸ë“€ì„œ ì„¤ê³„ê°€ ì–´ë ¤ìš¸ ìˆ˜ ìˆìœ¼ë©°, ì„¤ê³„ì— ë”°ë¼ ëª¨ë¸ì˜ í•™ìŠµ ë°©í–¥ì´ ì™œê³¡ë  ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.
* **ê³„ì‚° ë¹„ìš©:** CoT ì••ì¶• ë° Contrastive Preference Optimizationì€ ì¶”ê°€ì ì¸ ê³„ì‚° ë¹„ìš©ì„ ë°œìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ğŸ”— ë‚´ ì—°êµ¬ì™€ì˜ ì—°ê´€ì„±
ë³¸ ë…¼ë¬¸ì€ ì œê°€ í˜„ì¬ ì§„í–‰í•˜ê³  ìˆëŠ” Vision encoderì™€ Text LLM ê°„ì˜ ì •ë ¬(alignment) ì—°êµ¬ì™€ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ì´ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ, ì‹œê° ì •ë³´ì— ëŒ€í•œ ì˜ì¡´ë„ë¥¼ ë†’ì´ê³  ì–¸ì–´ì  í¸í–¥ì„ ì¤„ì´ëŠ” C3POì˜ ì ‘ê·¼ ë°©ì‹ì€ Vision encoderì˜ ì„±ëŠ¥ í–¥ìƒ ë° Vision-Language Alignment ê°œì„ ì— ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, Scientific ë„ë©”ì¸ì—ì„œì˜ MLLM í™œìš© ì—°êµ¬ì— ìˆì–´, í™˜ê° í˜„ìƒ ì™„í™”ëŠ” í•„ìˆ˜ì ì¸ ìš”ì†Œì´ë¯€ë¡œ, C3PO í”„ë ˆì„ì›Œí¬ë¥¼ ì ìš©í•˜ì—¬ Scientific MLLMì˜ ì‹ ë¢°ë„ë¥¼ ë†’ì¼ ìˆ˜ ìˆì„ ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë©ë‹ˆë‹¤.

### ğŸ’¡ ì—°êµ¬ ì•„ì´ë””ì–´ ì œì•ˆ
* **Scientific ë„ë©”ì¸ íŠ¹í™” C3PO:** Scientific ë„ë©”ì¸ì˜ íŠ¹ì„±ì„ ë°˜ì˜í•˜ì—¬ C3PO í”„ë ˆì„ì›Œí¬ë¥¼ ê°œì„ í•˜ëŠ” ì—°êµ¬ë¥¼ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, Scientific ë…¼ë¬¸ì˜ êµ¬ì¡°ì  íŠ¹ì§•ì„ í™œìš©í•œ CoT ì••ì¶• ë°©ì‹ì„ ê°œë°œí•˜ê±°ë‚˜, Scientific ì§€ì‹ ê¸°ë°˜ì„ í™œìš©í•œ AI í”¼ë“œë°± ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
* **Vision Encoderì™€ C3POì˜ ê²°í•©:** Vision Encoderì˜ íŠ¹ì§• ì¶”ì¶œ ë°©ì‹ì„ ê°œì„ í•˜ì—¬ C3PO í”„ë ˆì„ì›Œí¬ì™€ ê²°í•©í•˜ëŠ” ì—°êµ¬ë¥¼ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì‹œê° ì •ë³´ì˜ ì¤‘ìš”ë„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” attention ë©”ì»¤ë‹ˆì¦˜ì„ ê°•í™”í•˜ì—¬ C3POì˜ CoT ì••ì¶• íš¨ê³¼ë¥¼ ê·¹ëŒ€í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
* **Hallucination-inducing Mechanismì˜ ìë™í™”:** íš¨ê³¼ì ì¸ í™˜ê° ìœ ë„ë¥¼ ìœ„í•œ ì¸ë“€ì„œë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•˜ëŠ” ë°©ë²•ì„ ì—°êµ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, Generative ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ë‹¤ì–‘í•œ í™˜ê° íŒ¨í„´ì„ ìƒì„±í•˜ê³ , ì´ë¥¼ í•™ìŠµ ë°ì´í„°ë¡œ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ğŸ“š í•µì‹¬ í‚¤ì›Œë“œ
1. Multimodal Reasoning
2. Hallucination Mitigation
3. Chain-of-Thought Compression
4. Contrastive Preference Optimization
5. Vision-Language Alignment


---

> ğŸ¤– ì´ ê¸€ì€ AI ì—°êµ¬ ì–´ì‹œìŠ¤í„´íŠ¸ì— ì˜í•´ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.
> ë¶„ì„ ëª¨ë¸: google/gemma-3-27b-it:free
