---
title: "Large Language Model-Assisted UAV Operations and Communications: A Multifaceted "
date: 2026-02-24
arxiv: "2602.19534v1"
category: "cs.RO"
model: "google/gemma-3-27b-it:free"
---

# Large Language Model-Assisted UAV Operations and Communications: A Multifaceted Survey and Tutorial

## ğŸ“– ë…¼ë¬¸ ì •ë³´

| í•­ëª© | ë‚´ìš© |
|------|------|
| **ì €ì** | Yousef Emami, Hao Zhou, Radha Reddy, Atefeh Hajijamali Arani, Biliang Wang... |
| **ë°œí‘œì¼** | 2026-02-23 |
| **arXiv** | [2602.19534v1](https://arxiv.org/pdf/2602.19534v1) |
| **ì¹´í…Œê³ ë¦¬** | cs.RO |

---

## ğŸ“ ì´ˆë¡ (Abstract)

Uncrewed Aerial Vehicles (UAVs) are widely deployed across diverse applications due to their mobility and agility. Recent advances in Large Language Models (LLMs) offer a transformative opportunity to enhance UAV intelligence beyond conventional optimization-based and learning-based approaches. By integrating LLMs into UAV systems, advanced environmental understanding, swarm coordination, mobility optimization, and high-level task reasoning can be achieved, thereby allowing more adaptive and context-aware aerial operations. This survey systematically explores the intersection of LLMs and UAV technologies and proposes a unified framework that consolidates existing architectures, methodologies, and applications for UAVs. We first present a structured taxonomy of LLM adaptation techniques for UAVs, including pretraining, fine-tuning, Retrieval-Augmented Generation (RAG), and prompt engineering, along with key reasoning capabilities such as Chain-of-Thought (CoT) and In-Context Learning (ICL). We then examine LLM-assisted UAV communications and operations, covering navigation, mission planning, swarm control, safety, autonomy, and network management. After that, the survey further discusses Multimodal LLMs (MLLMs) for human-swarm interaction, perception-driven navigation, and collaborative control. Finally, we address ethical considerations, including bias, transparency, accountability, and Human-in-the-Loop (HITL) strategies, and outline future research directions. Overall, this work positions LLM-assisted UAVs as a foundation for intelligent and adaptive aerial systems.

---

## ğŸ” AI ë¶„ì„

## ë¶„ì„ ê²°ê³¼

### ğŸ“„ ë…¼ë¬¸ ìš”ì•½
ë³¸ ë…¼ë¬¸ì€ ë“œë¡ (UAV) ìš´ì˜ ë° í†µì‹  ë¶„ì•¼ì— ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ ì ‘ëª©í•˜ì—¬ ë“œë¡ ì˜ ì§€ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ë°©ì•ˆì„ ì¢…í•©ì ìœ¼ë¡œ ì¡°ì‚¬í•˜ê³  ì œì‹œí•©ë‹ˆë‹¤. LLMì˜ ì‚¬ì „ í•™ìŠµ, ë¯¸ì„¸ ì¡°ì •, RAG, í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ë“± ë‹¤ì–‘í•œ ì ì‘ ê¸°ë²•ê³¼ CoT, ICLê³¼ ê°™ì€ ì¶”ë¡  ëŠ¥ë ¥ì„ ë“œë¡  ì‹œìŠ¤í…œì— ì ìš©í•˜ëŠ” ë°©ë²•ì„ ì²´ê³„ì ìœ¼ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤. íŠ¹íˆ, ë©€í‹°ëª¨ë‹¬ LLM(MLLM)ì„ í™œìš©í•œ ì¸ê°„-ìŠ¤ì›œ ìƒí˜¸ì‘ìš©, ì¸ì‹ ê¸°ë°˜ ë‚´ë¹„ê²Œì´ì…˜, í˜‘ì—… ì œì–´ ë“± ë‹¤ì–‘í•œ ì‘ìš© ë¶„ì•¼ë¥¼ ë‹¤ë£¨ë©°, ìœ¤ë¦¬ì  ê³ ë ¤ ì‚¬í•­ê³¼ í–¥í›„ ì—°êµ¬ ë°©í–¥ì„ ì œì‹œí•©ë‹ˆë‹¤. ê¶ê·¹ì ìœ¼ë¡œ LLM ê¸°ë°˜ ë“œë¡ ì„ ì§€ëŠ¥ì ì´ê³  ì ì‘ ê°€ëŠ¥í•œ í•­ê³µ ì‹œìŠ¤í…œì˜ ê¸°ë°˜ìœ¼ë¡œ ì œì‹œí•©ë‹ˆë‹¤.

### ğŸ†• ìƒˆë¡œìš´ ì  (Novelty)
ê¸°ì¡´ ì—°êµ¬ë“¤ì´ LLM ë˜ëŠ” ë“œë¡  ê¸°ìˆ  ê°ê°ì— ì§‘ì¤‘í•˜ëŠ” ê²½í–¥ì´ ìˆì—ˆë˜ ë°˜ë©´, ë³¸ ë…¼ë¬¸ì€ LLMê³¼ ë“œë¡  ê¸°ìˆ ì˜ ìœµí•©ì„ **ì¢…í•©ì ì´ê³  ì²´ê³„ì ìœ¼ë¡œ** ë‹¤ë£¨ì—ˆë‹¤ëŠ” ì ì´ ê°€ì¥ í° ì°¨ë³„ì ì…ë‹ˆë‹¤. LLM ì ì‘ ê¸°ë²•, ë“œë¡  ìš´ì˜ ë° í†µì‹ , MLLM í™œìš©, ìœ¤ë¦¬ì  ê³ ë ¤ ì‚¬í•­ê¹Œì§€ ì•„ìš°ë¥´ëŠ” **í†µí•© í”„ë ˆì„ì›Œí¬**ë¥¼ ì œì‹œí•˜ì—¬ í•´ë‹¹ ë¶„ì•¼ ì—°êµ¬ì˜ ë°©í–¥ì„±ì„ ì œì‹œí•©ë‹ˆë‹¤. ë˜í•œ, ë“œë¡  ë¶„ì•¼ì— LLMì„ ì ìš©í•˜ê¸° ìœ„í•œ ë‹¤ì–‘í•œ ê¸°ë²•ë“¤ì„ **ë¶„ë¥˜í•˜ê³  ë¹„êµ ë¶„ì„**í•˜ì—¬ ì‹¤ì§ˆì ì¸ ê°€ì´ë“œë¼ì¸ì„ ì œê³µí•©ë‹ˆë‹¤.

### ğŸ’ª ê°•ì  (Strengths)
1. **í¬ê´„ì ì¸ ì¡°ì‚¬:** LLMê³¼ ë“œë¡  ê¸°ìˆ ì˜ ìœµí•©ì— ëŒ€í•œ ê´‘ë²”ìœ„í•˜ê³  ì‹¬ì¸µì ì¸ ì¡°ì‚¬ë¥¼ ìˆ˜í–‰í•˜ì—¬ í•´ë‹¹ ë¶„ì•¼ì˜ ìµœì‹  ë™í–¥ì„ íŒŒì•…í•˜ê³  ìˆìŠµë‹ˆë‹¤.
2. **ì²´ê³„ì ì¸ ë¶„ë¥˜:** LLM ì ì‘ ê¸°ë²•, ë“œë¡  ìš´ì˜ ë° í†µì‹ , MLLM í™œìš© ë“± ë‹¤ì–‘í•œ ì¸¡ë©´ì„ ì²´ê³„ì ìœ¼ë¡œ ë¶„ë¥˜í•˜ì—¬ ì—°êµ¬ìë“¤ì—ê²Œ ëª…í™•í•œ êµ¬ì¡°ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
3. **ì‹¤ìš©ì ì¸ ê°€ì´ë“œë¼ì¸:** LLMì„ ë“œë¡  ì‹œìŠ¤í…œì— ì ìš©í•˜ê¸° ìœ„í•œ ë‹¤ì–‘í•œ ê¸°ë²•ë“¤ì„ ë¹„êµ ë¶„ì„í•˜ê³ , ìœ¤ë¦¬ì  ê³ ë ¤ ì‚¬í•­ê³¼ í–¥í›„ ì—°êµ¬ ë°©í–¥ì„ ì œì‹œí•˜ì—¬ ì‹¤ì§ˆì ì¸ ê°€ì´ë“œë¼ì¸ì„ ì œê³µí•©ë‹ˆë‹¤.

### âš ï¸ ì•½ì /í•œê³„ì  (Limitations)
1. **êµ¬ì²´ì ì¸ êµ¬í˜„ ë° ì‹¤í—˜ ë¶€ì¡±:** ë…¼ë¬¸ì€ ë‹¤ì–‘í•œ ê¸°ë²•ë“¤ì„ ì†Œê°œí•˜ê³  ìˆì§€ë§Œ, ì‹¤ì œ ë“œë¡  ì‹œìŠ¤í…œì— ì ìš©í•œ êµ¬ì²´ì ì¸ êµ¬í˜„ ë° ì‹¤í—˜ ê²°ê³¼ëŠ” ë¶€ì¡±í•©ë‹ˆë‹¤. ì´ë¡ ì ì¸ ë…¼ì˜ì— ì¹˜ì¤‘ë˜ì–´ ì‹¤ì œ ì ìš© ê°€ëŠ¥ì„±ì— ëŒ€í•œ ê²€ì¦ì´ ë¯¸í¡í•©ë‹ˆë‹¤.
2. **MLLM í™œìš©ì˜ ì œí•œì ì¸ ê¹Šì´:** MLLMì„ ì–¸ê¸‰í•˜ê³  ìˆì§€ë§Œ, íŠ¹íˆ ë¬¸ì„œ/ì°¨íŠ¸/OCR/í…Œì´ë¸” ì´í•´ì™€ ê°™ì€ íŠ¹ì • ë©€í‹°ëª¨ë‹¬ ëŠ¥ë ¥ì— ëŒ€í•œ ì‹¬ì¸µì ì¸ ë¶„ì„ì€ ë¶€ì¡±í•©ë‹ˆë‹¤. ì‚¬ìš©ì ì—°êµ¬ ë¶„ì•¼ì— ë¹„í•´ MLLM í™œìš©ì— ëŒ€í•œ ë…¼ì˜ê°€ í”¼ìƒì ì…ë‹ˆë‹¤.
3. **í•œêµ­ì–´ í™˜ê²½ ê³ ë ¤ ë¶€ì¡±:** í•œêµ­ì–´ ë“œë¡  ìš´ì˜ ë° í†µì‹  í™˜ê²½ì— ëŒ€í•œ ê³ ë ¤ê°€ ì „í˜€ ì—†ìŠµë‹ˆë‹¤. í•œêµ­ì–´ LLM/MLLM ì ìš© ê°€ëŠ¥ì„± ë° ë¬¸ì œì ì— ëŒ€í•œ ë…¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.

### ğŸ”— ë‚´ ì—°êµ¬ì™€ì˜ ì—°ê´€ì„±
ë³¸ ë…¼ë¬¸ì€ MLLMì„ í™œìš©í•œ ë“œë¡  ì‹œìŠ¤í…œ ì—°êµ¬ì— ì¤‘ìš”í•œ ì‹œì‚¬ì ì„ ì œê³µí•©ë‹ˆë‹¤. íŠ¹íˆ, MLLMì„ í™œìš©í•œ ì¸ì‹ ê¸°ë°˜ ë‚´ë¹„ê²Œì´ì…˜, í˜‘ì—… ì œì–´, ì¸ê°„-ìŠ¤ì›œ ìƒí˜¸ì‘ìš© ë“±ì˜ ì‘ìš© ë¶„ì•¼ëŠ” ì‚¬ìš©ì ì—°êµ¬ ì£¼ì œì¸ Vision-Text Alignment, Document/Chart/OCR/Table VQAì™€ ì§ì ‘ì ìœ¼ë¡œ ì—°ê´€ë©ë‹ˆë‹¤. ë“œë¡ ì´ ìˆ˜ì§‘í•˜ëŠ” ì‹œê° ì •ë³´ë¥¼ LLMì„ í†µí•´ ì´í•´í•˜ê³ , ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê³ ë„í™”ëœ ì˜ì‚¬ ê²°ì •ì„ ë‚´ë¦¬ëŠ” ì—°êµ¬ì— í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ëª¨ë¸ ë¨¸ì§•ì„ í†µí•´ ë“œë¡  ìš´ì˜ì— íŠ¹í™”ëœ MLLMì„ ê°œë°œí•˜ëŠ” ì•„ì´ë””ì–´ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ğŸ’¡ ì—°êµ¬ ì•„ì´ë””ì–´ ì œì•ˆ
1. **Document VQA ê¸°ë°˜ ë“œë¡  ë¬¸ì„œ ì´í•´:** ë“œë¡ ì´ ì´¬ì˜í•œ ë¬¸ì„œ ì´ë¯¸ì§€(ì˜ˆ: ê±´ì„¤ í˜„ì¥ ë„ë©´, ì¬ë‚œ í˜„ì¥ ì§€ë„)ë¥¼ MLLMì„ í†µí•´ ì´í•´í•˜ê³ , í•„ìš”í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ ë“œë¡  ìš´ì˜ì— í™œìš©í•˜ëŠ” ì—°êµ¬ë¥¼ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
2. **Chart VQA ê¸°ë°˜ ë“œë¡  ì„ë¬´ ê³„íš:** ë“œë¡ ì´ ìˆ˜ì§‘í•œ ì°¨íŠ¸ ë°ì´í„°ë¥¼ MLLMì„ í†µí•´ ë¶„ì„í•˜ê³ , ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìµœì ì˜ ì„ë¬´ ê³„íšì„ ìˆ˜ë¦½í•˜ëŠ” ì—°êµ¬ë¥¼ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
3. **Korean MLLMì„ í™œìš©í•œ í•œêµ­ì–´ ê¸°ë°˜ ë“œë¡  ì œì–´:** í•œêµ­ì–´ ëª…ë ¹ì–´ë¥¼ ì´í•´í•˜ê³  ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” í•œêµ­ì–´ MLLMì„ ê°œë°œí•˜ê³ , ì´ë¥¼ ë“œë¡  ì œì–´ ì‹œìŠ¤í…œì— ì ìš©í•˜ëŠ” ì—°êµ¬ë¥¼ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
4. **MLLM Mergingì„ í†µí•œ ë“œë¡  íŠ¹í™” ëª¨ë¸ ê°œë°œ:** ë“œë¡  ìš´ì˜ì— í•„ìš”í•œ íŠ¹ì • ëŠ¥ë ¥ì„ ê°•í™”í•˜ê¸° ìœ„í•´ MLLMì„ ë¨¸ì§•í•˜ëŠ” ì—°êµ¬ë¥¼ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì‹œê°ì  ì¶”ë¡  ëŠ¥ë ¥ì„ ê°•í™”í•˜ê¸° ìœ„í•´ Vision Encoderë¥¼, ì–¸ì–´ ì´í•´ ëŠ¥ë ¥ì„ ê°•í™”í•˜ê¸° ìœ„í•´ LLMì„ ë¨¸ì§•í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.

### ğŸ“š í•µì‹¬ í‚¤ì›Œë“œ
1. Unmanned Aerial Vehicles (UAVs)
2. Large Language Models (LLMs)
3. Multimodal Large Language Models (MLLMs)
4. Human-Swarm Interaction
5. Perception-Driven Navigation


---

> ğŸ¤– ì´ ê¸€ì€ AI ì—°êµ¬ ì–´ì‹œìŠ¤í„´íŠ¸ì— ì˜í•´ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.
> ë¶„ì„ ëª¨ë¸: google/gemma-3-27b-it:free
