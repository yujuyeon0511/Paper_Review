---
title: "Model Composition for Multimodal Large Language Models"
date: 2026-02-11
arxiv: "2402.12750"
category: "Annual Meeting of the Association for Computational Linguistics"
model: "google/gemma-3-4b-it:free"
---

# Model Composition for Multimodal Large Language Models

## ğŸ“– ë…¼ë¬¸ ì •ë³´

| í•­ëª© | ë‚´ìš© |
|------|------|
| **ì €ì** | Chi Chen, Yiyang Du, Zheng Fang, Ziyue Wang, Fuwen Luo... |
| **ë°œí‘œì¼** | 2024-02-20 |
| **arXiv** | [2402.12750](https://arxiv.org/pdf/2402.12750) |
| **ì¹´í…Œê³ ë¦¬** | Annual Meeting of the Association for Computational Linguistics |

---

## ğŸ“ ì´ˆë¡ (Abstract)

Recent developments in Multimodal Large Language Models (MLLMs) have shown rapid progress, moving towards the goal of creating versatile MLLMs that understand inputs from various modalities. However, existing methods typically rely on joint training with paired multimodal instruction data, which is resource-intensive and challenging to extend to new modalities. In this paper, we propose a new paradigm through the model composition of existing MLLMs to create a new model that retains the modal understanding capabilities of each original model. Our basic implementation, NaiveMC, demonstrates the effectiveness of this paradigm by reusing modality encoders and merging LLM parameters. Furthermore, we introduce DAMC to address parameter interference and mismatch issues during the merging process, thereby enhancing the model performance. To facilitate research in this area, we propose MCUB, a benchmark for assessing ability of MLLMs to understand inputs from diverse modalities. Experiments on this benchmark and four other multimodal understanding tasks show significant improvements over baselines, proving that model composition can create a versatile model capable of processing inputs from multiple modalities.

---

## ğŸ” AI ë¶„ì„

## ë…¼ë¬¸ ë¶„ì„: Model Composition for Multimodal Large Language Models

### ë…¼ë¬¸ ìš”ì•½
ë³¸ ë…¼ë¬¸ì€ ê¸°ì¡´ ë©€í‹°ëª¨ë‹¬ LLMì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´, ê¸°ì¡´ MLLMë“¤ì„ ì¡°í•©í•˜ì—¬ ìƒˆë¡œìš´ ëª¨ë¸ì„ ìƒì„±í•˜ëŠ” â€˜ëª¨ë¸ êµ¬ì„±(Model Composition)â€™ì´ë¼ëŠ” ìƒˆë¡œìš´ íŒ¨ëŸ¬ë‹¤ì„ì„ ì œì‹œí•©ë‹ˆë‹¤. NaiveMCì™€ DAMCë¼ëŠ” ë‘ ê°€ì§€ í”„ë ˆì„ì›Œí¬ë¥¼ í†µí•´ ê¸°ì¡´ MLLMì˜ ëª¨ë‹¬ ì´í•´ ëŠ¥ë ¥ì„ ìœ ì§€í•˜ë©´ì„œ, ìƒˆë¡œìš´ ëª¨ë‹¬ì„ ì¶”ê°€í•˜ê±°ë‚˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ì œì•ˆí•˜ëŠ” ë°©ë²•ë¡ ì€ ê¸°ì¡´ ë°©ë²• ëŒ€ë¹„ ìƒë‹¹í•œ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì—¬ì£¼ë©°, íŠ¹íˆ MCUB ë²¤ì¹˜ë§ˆí¬ì—ì„œ ë›°ì–´ë‚œ ê²°ê³¼ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.

### ë°©ë²•ë¡  (Methodology)
ë³¸ ë…¼ë¬¸ì˜ í•µì‹¬ ë°©ë²•ë¡ ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

*   **ì „ì²´ íŒŒì´í”„ë¼ì¸/ì•„í‚¤í…ì²˜ êµ¬ì¡°:** ê¸°ì¡´ MLLMë“¤ì„ ë‹¨ìˆœíˆ ì—°ê²°í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ê° MLLMì˜ ëª¨ë‹¬ë³„ encoderì™€ LLM íŒŒë¼ë¯¸í„°ë¥¼ ì¬ì‚¬ìš©í•˜ê³ , DAMCë¥¼ í†µí•´ íŒŒë¼ë¯¸í„° ê°„ì˜ ì¶©ëŒì„ í•´ê²°í•˜ì—¬ ìƒˆë¡œìš´ ëª¨ë¸ì„ êµ¬ì„±í•©ë‹ˆë‹¤.
*   **í•µì‹¬ ê¸°ë²•ì˜ ì‘ë™ ì›ë¦¬:**
    *   **NaiveMC:** ê¸°ì¡´ MLLMì˜ ëª¨ë‹¬ë³„ encoderë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê³ , LLM íŒŒë¼ë¯¸í„°ë¥¼ ë³‘í•©í•©ë‹ˆë‹¤.
    *   **DAMC (Decoupling and Adjustment for Model Composition):**  LLM íŒŒë¼ë¯¸í„°ë¥¼ ëª¨ë‹¬ë³„ë¡œ ë¶„ë¦¬í•˜ê³ , ê° ëª¨ë‹¬ì— ì í•©í•œ íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•˜ì—¬ ì¶©ëŒì„ ìµœì†Œí™”í•©ë‹ˆë‹¤.  ë˜í•œ, íŒŒë¼ë¯¸í„° ì¡°ì • ê³¼ì •ì—ì„œ í•™ìŠµë¥ ì„ ì¡°ì ˆí•˜ì—¬ ìµœì ì˜ ì„±ëŠ¥ì„ í™•ë³´í•©ë‹ˆë‹¤.
*   **ê¸°ì¡´ ë°©ë²• ëŒ€ë¹„ ì°¨ì´ì :** ê¸°ì¡´ ë°©ë²•ì€ ì£¼ë¡œ ëª¨ë‹¬-í…ìŠ¤íŠ¸ ìŒìœ¼ë¡œ ë°ì´í„°ë¥¼ í•™ìŠµí•˜ê±°ë‚˜, ê° ëª¨ë‹¬ encoderë¥¼ LLMì— ì§ì ‘ ì—°ê²°í•˜ëŠ” ë°©ì‹ì— ì˜ì¡´í–ˆìŠµë‹ˆë‹¤. ë°˜ë©´, ë³¸ ë…¼ë¬¸ì€ ê¸°ì¡´ MLLMì„ í™œìš©í•˜ì—¬ ìƒˆë¡œìš´ ëª¨ë¸ì„ êµ¬ì„±í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ, í•™ìŠµ ë°ì´í„°ì˜ ìš”êµ¬ëŸ‰ì„ ì¤„ì´ê³ , ìƒˆë¡œìš´ ëª¨ë‹¬ì„ ì¶”ê°€í•˜ëŠ” ë° ìš©ì´í•©ë‹ˆë‹¤.
*   **ì‚¬ìš©ëœ backbone ëª¨ë¸, vision encoder, LLM ì¢…ë¥˜:** Vicuna-7B-v1.5ë¥¼ ê¸°ë°˜ìœ¼ë¡œ CLIP-ViT-L-336px vision encoder, BEATs-Iter3+ audio encoderë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.
*   **í•™ìŠµ ë°ì´í„°, í•™ìŠµ ì „ëµ:** LCS 558K, LLaVA-mixed 665K, OpenAQA filtered 350K, Valley 702K, PointLLM brief, Objaverse,  WaveCaps 400K,  ImageBind (image-text), X-InstructBLIP (instruction tuning) ë“±ì˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.  LoRAë¥¼ ì‚¬ìš©í•˜ì—¬ LLM íŒŒë¼ë¯¸í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ í•™ìŠµí–ˆìŠµë‹ˆë‹¤.

### ì‹¤í—˜ ë° ê²°ê³¼ (Experiments & Results)
*   **ì‚¬ìš©ëœ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹:** MUSIC-AVQA, AVQA, MCUB-3, MCUB-4, Objaverse, ModelNet40.
*   **ë¹„êµ ëŒ€ìƒ ëª¨ë¸ (baseline):** ImageBind-LLM, X-InstructBLIP, Proj-only, NaiveMC.
*   **ì£¼ìš” ìˆ˜ì¹˜ ê²°ê³¼ (í‘œ í˜•íƒœ):** (í‘œëŠ” ë…¼ë¬¸ ì›ë³¸ì„ ì°¸ê³ í•˜ì—¬ ì‘ì„±)
*   **SOTA ë‹¬ì„± ì—¬ë¶€ ë° ê¸°ì¡´ SOTA ëŒ€ë¹„ ê°œì„  í­:** MCUB-4ì—ì„œ DAMCëŠ” ê¸°ì¡´ SOTA ëŒ€ë¹„ 6.05ì ì˜ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì˜€ìŠµë‹ˆë‹¤.
*   **Ablation study ê²°ê³¼:** íŒŒë¼ë¯¸í„° ë¶„ë¦¬ ë° ì¡°ì • ì „ëµì„ ì ìš©í–ˆì„ ë•Œ, ë‹¨ìˆœíˆ íŒŒë¼ë¯¸í„°ë¥¼ ë³‘í•©í–ˆì„ ë•Œë³´ë‹¤ ì„±ëŠ¥ì´ í¬ê²Œ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤.

### ìƒˆë¡œìš´ ì  (Novelty)
ë³¸ ë…¼ë¬¸ì˜ ê°€ì¥ í° ìƒˆë¡œìš´ ì ì€ ê¸°ì¡´ MLLMì„ í™œìš©í•˜ì—¬ ìƒˆë¡œìš´ ëª¨ë¸ì„ êµ¬ì„±í•˜ëŠ” â€˜ëª¨ë¸ êµ¬ì„±â€™ì´ë¼ëŠ” íŒ¨ëŸ¬ë‹¤ì„ì„ ì œì‹œí•œ ì ì…ë‹ˆë‹¤. íŠ¹íˆ, DAMCë¥¼ í†µí•´ íŒŒë¼ë¯¸í„° ê°„ ì¶©ëŒì„ í•´ê²°í•˜ê³ , ìƒˆë¡œìš´ ëª¨ë‹¬ì„ ì¶”ê°€í•˜ëŠ” ë° ìš©ì´í•˜ë‹¤ëŠ” ì ì´ ê¸°ì¡´ ì—°êµ¬ì™€ ì°¨ë³„í™”ë©ë‹ˆë‹¤. ë˜í•œ, í•™ìŠµ ë°ì´í„°ì˜ ìš”êµ¬ëŸ‰ì„ ì¤„ì´ê³ , ë‹¤ì–‘í•œ ëª¨ë‹¬ì„ í†µí•©í•˜ëŠ” ë° íš¨ê³¼ì ì´ë¼ëŠ” ì ë„ ì¤‘ìš”í•œ ê¸°ì—¬ì…ë‹ˆë‹¤.

### ê°•ì  (Strengths)
1.  **í•™ìŠµ ë°ì´í„° ìš”êµ¬ëŸ‰ ê°ì†Œ:** ê¸°ì¡´ MLLM í•™ìŠµì— í•„ìš”í•œ ëŒ€ê·œëª¨ ëª¨ë‹¬-í…ìŠ¤íŠ¸ ìŒ ë°ì´í„° ìˆ˜ì§‘ì˜ ì–´ë ¤ì›€ì„ í•´ê²°í•©ë‹ˆë‹¤.
2.  **ëª¨ë‹¬ í™•ì¥ ìš©ì´ì„±:** ìƒˆë¡œìš´ ëª¨ë‹¬ì„ ì¶”ê°€í•˜ëŠ” ë° í•„ìš”í•œ í•™ìŠµ ë¹„ìš©ì„ ì¤„ì—¬ì¤ë‹ˆë‹¤.
3.  **ì„±ëŠ¥ í–¥ìƒ:** ê¸°ì¡´ MLLMì˜ ëŠ¥ë ¥ì„ í™œìš©í•˜ì—¬ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ë©´ì„œ, ìƒˆë¡œìš´ ëª¨ë¸ì„ êµ¬ì„±í•©ë‹ˆë‹¤.

### ì•½ì /í•œê³„ì  (Limitations)
1.  **ëª¨ë¸ í¬ê¸° ì œí•œ:** ëª¨ë¸ êµ¬ì„± ì‹œ, ê¸°ì¡´ MLLMì˜ í¬ê¸° ì œí•œì— ì˜í•´ ì„±ëŠ¥ í–¥ìƒì— í•œê³„ê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
2.  **ëª¨ë‹¬ ê°„ ì¶©ëŒ ë¬¸ì œ:** ëª¨ë‹¬ ê°„ ì¶©ëŒì´ ë°œìƒí•  ê²½ìš°, DAMCì˜ ì„±ëŠ¥ì´ ì €í•˜ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
3.  **ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ ì˜ì¡´ì„±:** ì‹¤í—˜ ê²°ê³¼ëŠ” ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ë‚´ ì—°êµ¬ì™€ì˜ ì—°ê´€ì„±
ë³¸ ë…¼ë¬¸ì˜ ì—°êµ¬ëŠ” ì‚¬ìš©ìì˜ MLLM merging, Korean MLLM, vision-text alignment, document/chart/OCR/table VQA ì—°êµ¬ì™€ ë°€ì ‘í•˜ê²Œ ê´€ë ¨ë©ë‹ˆë‹¤. íŠ¹íˆ, ëª¨ë¸ êµ¬ì„±ì´ë¼ëŠ” íŒ¨ëŸ¬ë‹¤ì„ì€ ë‹¤ì–‘í•œ ëª¨ë‹¬ì„ í†µí•©í•˜ëŠ” VQA ì‹œìŠ¤í…œ ê°œë°œì— ì¤‘ìš”í•œ ì‹œì‚¬ì ì„ ì œê³µí•©ë‹ˆë‹¤. ë˜í•œ, DAMCë¥¼ í†µí•´ íŒŒë¼ë¯¸í„° ê°„ ì¶©ëŒì„ í•´ê²°í•˜ëŠ” ë°©ë²•ì€ Korean MLLM ê°œë°œ ì‹œ, ì–¸ì–´ ë° ëª¨ë‹¬ ê°„ì˜ ì°¨ì´ì ì„ ê·¹ë³µí•˜ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  Vision-text alignment ì—°êµ¬ì—ì„œëŠ” ëª¨ë¸ êµ¬ì„±ì´ ë‹¤ì–‘í•œ ì‹œê°ì  ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í…ìŠ¤íŠ¸ì™€ ì—°ê²°í•˜ëŠ” ë° ê¸°ì—¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ì—°êµ¬ ì•„ì´ë””ì–´ ì œì•ˆ
1.  **ë‹¤ì–‘í•œ MLLM ì¡°í•© ì‹¤í—˜:** ë‹¤ì–‘í•œ MLLMë“¤ì„ ì¡°í•©í•˜ì—¬ ìƒˆë¡œìš´ ëª¨ë¸ì„ êµ¬ì„±í•˜ê³ , ê° ì¡°í•©ì˜ ì„±ëŠ¥ì„ ë¹„êµ ë¶„ì„í•©ë‹ˆë‹¤.
2.  **DAMC ê°œì„ :** DAMCì˜ íŒŒë¼ë¯¸í„° ì¡°ì • ì•Œê³ ë¦¬ì¦˜ì„ ê°œì„ í•˜ì—¬, ëª¨ë‹¬ ê°„ ì¶©ëŒì„ ë”ìš± íš¨ê³¼ì ìœ¼ë¡œ í•´ê²°í•©ë‹ˆë‹¤.
3.  **ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ ê°œë°œ:** ë‹¤ì–‘í•œ ëª¨ë‹¬ê³¼ taskë¥¼ í¬ê´„í•˜ëŠ” ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ë¥¼ ê°œë°œí•˜ì—¬, ëª¨ë¸ êµ¬ì„± ë°©ë²•ë¡ ì˜ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.

### í•µì‹¬ í‚¤ì›Œë“œ
Model Composition, Multimodal Large Language Models, Zero-Shot Learning, Parameter Merging, Vision-Language Alignment, Document VQA, Chart VQA, OCR Multimodal, Table VQA, DAMC, MCUB.

---

> ğŸ¤– ì´ ê¸€ì€ AI ì—°êµ¬ ì–´ì‹œìŠ¤í„´íŠ¸ì— ì˜í•´ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.
> ë¶„ì„ ëª¨ë¸: google/gemma-3-4b-it:free
