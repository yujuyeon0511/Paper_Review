---
title: "Model Composition for Multimodal Large Language Models"
date: 2026-02-11
arxiv: "2402.12750"
category: "Annual Meeting of the Association for Computational Linguistics"
model: "google/gemma-3-27b-it:free"
---

# Model Composition for Multimodal Large Language Models

## ğŸ“– ë…¼ë¬¸ ì •ë³´

| í•­ëª© | ë‚´ìš© |
|------|------|
| **ì €ì** | Chi Chen, Yiyang Du, Zheng Fang, Ziyue Wang, Fuwen Luo... |
| **ë°œí‘œì¼** | 2024-02-20 |
| **arXiv** | [2402.12750](https://arxiv.org/pdf/2402.12750) |
| **ì¹´í…Œê³ ë¦¬** | Annual Meeting of the Association for Computational Linguistics |

---

## ğŸ“ ì´ˆë¡ (Abstract)

Recent developments in Multimodal Large Language Models (MLLMs) have shown rapid progress, moving towards the goal of creating versatile MLLMs that understand inputs from various modalities. However, existing methods typically rely on joint training with paired multimodal instruction data, which is resource-intensive and challenging to extend to new modalities. In this paper, we propose a new paradigm through the model composition of existing MLLMs to create a new model that retains the modal understanding capabilities of each original model. Our basic implementation, NaiveMC, demonstrates the effectiveness of this paradigm by reusing modality encoders and merging LLM parameters. Furthermore, we introduce DAMC to address parameter interference and mismatch issues during the merging process, thereby enhancing the model performance. To facilitate research in this area, we propose MCUB, a benchmark for assessing ability of MLLMs to understand inputs from diverse modalities. Experiments on this benchmark and four other multimodal understanding tasks show significant improvements over baselines, proving that model composition can create a versatile model capable of processing inputs from multiple modalities.

---

## ğŸ” AI ë¶„ì„

## ë…¼ë¬¸ ë¶„ì„: Model Composition for Multimodal Large Language Models

### ë…¼ë¬¸ ìš”ì•½
ë³¸ ë…¼ë¬¸ì€ ê¸°ì¡´ MLLM í•™ìŠµ ë°©ì‹ì˜ í•œê³„ì ì¸ ê³ ë¹„ìš©ì˜ paired multimodal instruction ë°ì´í„° ìš”êµ¬ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ê¸°ì¡´ MLLMë“¤ì„ ì¡°í•©(composition)í•˜ì—¬ ìƒˆë¡œìš´ ëª¨ë¸ì„ êµ¬ì¶•í•˜ëŠ” íŒ¨ëŸ¬ë‹¤ì„ì„ ì œì‹œí•©ë‹ˆë‹¤. NaiveMCë¥¼ í†µí•´ modality encoder ì¬ì‚¬ìš© ë° LLM íŒŒë¼ë¯¸í„° ë³‘í•©ì˜ íš¨ê³¼ë¥¼ ì…ì¦í•˜ê³ , DAMCë¥¼ í†µí•´ íŒŒë¼ë¯¸í„° ê°„ì„­ ë¬¸ì œë¥¼ ì™„í™”í•˜ì—¬ ì„±ëŠ¥ì„ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤. ë˜í•œ, MLLMì˜ ë‹¤ì–‘í•œ ëª¨ë‹¬ë¦¬í‹° ì´í•´ ëŠ¥ë ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ MCUBë¥¼ ì œì•ˆí•˜ë©°, ë‹¤ì–‘í•œ multimodal understanding taskì—ì„œ ê¸°ì¡´ ëª¨ë¸ ëŒ€ë¹„ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

### ë°©ë²•ë¡  (Methodology)
- **ì „ì²´ íŒŒì´í”„ë¼ì¸/ì•„í‚¤í…ì²˜ êµ¬ì¡°:** ê¸°ì¡´ MLLMë“¤ì„ ì¡°í•©í•˜ì—¬ ìƒˆë¡œìš´ MLLMì„ ë§Œë“œëŠ” ë°©ì‹ìœ¼ë¡œ, í¬ê²Œ NaiveMCì™€ DAMC ë‘ ë‹¨ê³„ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. NaiveMCëŠ” modality encoderë¥¼ ì¬ì‚¬ìš©í•˜ê³  LLM íŒŒë¼ë¯¸í„°ë¥¼ ë³‘í•©í•˜ëŠ” ê°„ë‹¨í•œ ë°©ì‹ì´ë©°, DAMCëŠ” íŒŒë¼ë¯¸í„° ê°„ì„­ ë° ë¶ˆì¼ì¹˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì¶”ê°€ì ì¸ ê¸°ë²•ì„ ì ìš©í•©ë‹ˆë‹¤.
- **í•µì‹¬ ê¸°ë²•ì˜ ì‘ë™ ì›ë¦¬:** DAMCëŠ” íŒŒë¼ë¯¸í„° ê°„ì„­ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ êµ¬ì²´ì ì¸ ê¸°ë²•ì´ ì´ˆë¡ì— ëª…ì‹œë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ì›ë¬¸ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.
- **ê¸°ì¡´ ë°©ë²• ëŒ€ë¹„ êµ¬ì²´ì ìœ¼ë¡œ ë¬´ì—‡ì´ ë‹¤ë¥¸ì§€:** ê¸°ì¡´ ë°©ë²•ì€ paired multimodal instruction ë°ì´í„°ë¡œ joint trainingì„ ì§„í–‰í•˜ëŠ” ë°˜ë©´, ë³¸ ë…¼ë¬¸ì€ ê¸°ì¡´ MLLMì„ ì¡°í•©í•˜ì—¬ í•™ìŠµ ë¹„ìš©ì„ ì ˆê°í•˜ê³  ìƒˆë¡œìš´ ëª¨ë‹¬ë¦¬í‹°ì— ëŒ€í•œ í™•ì¥ì„±ì„ ë†’ì…ë‹ˆë‹¤.
- **ì‚¬ìš©í•œ backbone ëª¨ë¸, vision encoder, LLM ì¢…ë¥˜:** ì´ˆë¡ì— êµ¬ì²´ì ì¸ ëª¨ë¸ ì¢…ë¥˜ëŠ” ì–¸ê¸‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ë§Œ, modality encoderì™€ LLMì„ ì¬ì‚¬ìš©í•œë‹¤ëŠ” ì ì—ì„œ ë‹¤ì–‘í•œ ëª¨ë¸ì— ì ìš© ê°€ëŠ¥í•¨ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.

### ì‹¤í—˜ ë° ê²°ê³¼ (Experiments & Results)
- **ì‚¬ìš©ëœ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ ì´ë¦„:** MCUB (Model Composition Understanding Benchmark) ë° 4ê°œì˜ ë‹¤ë¥¸ multimodal understanding task (êµ¬ì²´ì ì¸ task ì´ë¦„ì€ ì´ˆë¡ì— ë¯¸ê¸°ì¬).
- **ë¹„êµ ëŒ€ìƒ ëª¨ë¸ (baseline):** ì´ˆë¡ì— êµ¬ì²´ì ì¸ baseline ëª¨ë¸ì€ ì–¸ê¸‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.
- **ìˆ˜ì¹˜ ê²°ê³¼:** ì´ˆë¡ì— êµ¬ì²´ì  ìˆ˜ì¹˜ ë¯¸ê¸°ì¬, ì›ë¬¸ í™•ì¸ í•„ìš”.
- **SOTA ë‹¬ì„± ì—¬ë¶€ ë° ê°œì„  í­:** ì´ˆë¡ì— SOTA ë‹¬ì„± ì—¬ë¶€ëŠ” ëª…ì‹œë˜ì§€ ì•Šì•˜ìœ¼ë‚˜, baseline ëŒ€ë¹„ significant improvementsë¥¼ ë³´ì˜€ë‹¤ê³  ì–¸ê¸‰ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
- **ì´ˆë¡ì— ìˆ˜ì¹˜ê°€ ì—†ìœ¼ë©´ "ì´ˆë¡ì— êµ¬ì²´ì  ìˆ˜ì¹˜ ë¯¸ê¸°ì¬, ì›ë¬¸ í™•ì¸ í•„ìš”"ë¼ê³  ëª…ì‹œ:** ì´ˆë¡ì— êµ¬ì²´ì  ìˆ˜ì¹˜ ë¯¸ê¸°ì¬, ì›ë¬¸ í™•ì¸ í•„ìš”.

### ìƒˆë¡œìš´ ì  (Novelty)
ë³¸ ë…¼ë¬¸ì˜ ê°€ì¥ í° í˜ì‹ ì€ paired multimodal instruction ë°ì´í„° ì—†ì´ ê¸°ì¡´ MLLMì„ ì¡°í•©í•˜ì—¬ ìƒˆë¡œìš´ MLLMì„ êµ¬ì¶•í•˜ëŠ” ìƒˆë¡œìš´ íŒ¨ëŸ¬ë‹¤ì„ì„ ì œì‹œí–ˆë‹¤ëŠ” ì ì…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ í•™ìŠµ ë¹„ìš©ì„ ì ˆê°í•˜ê³  ìƒˆë¡œìš´ ëª¨ë‹¬ë¦¬í‹°ì— ëŒ€í•œ í™•ì¥ì„±ì„ ë†’ì¼ ìˆ˜ ìˆìœ¼ë©°, MCUBë¼ëŠ” ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ë¥¼ í†µí•´ MLLMì˜ ë‹¤ì–‘í•œ ëª¨ë‹¬ë¦¬í‹° ì´í•´ ëŠ¥ë ¥ì„ í‰ê°€í•  ìˆ˜ ìˆëŠ” ê¸°ë°˜ì„ ë§ˆë ¨í–ˆìŠµë‹ˆë‹¤.

### ê°•ì  (Strengths)
1. **í•™ìŠµ ë¹„ìš© ì ˆê°:** paired multimodal instruction ë°ì´í„° ì—†ì´ ê¸°ì¡´ ëª¨ë¸ì„ í™œìš©í•˜ì—¬ í•™ìŠµ ë¹„ìš©ì„ í¬ê²Œ ì ˆê°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
2. **í™•ì¥ì„±:** ìƒˆë¡œìš´ ëª¨ë‹¬ë¦¬í‹°ì— ëŒ€í•œ í™•ì¥ì„±ì´ ìš©ì´í•©ë‹ˆë‹¤. ê¸°ì¡´ MLLMì„ ì¡°í•©í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ìƒˆë¡œìš´ ëª¨ë‹¬ë¦¬í‹°ë¥¼ ì‰½ê²Œ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
3. **ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬:** MLLMì˜ ë‹¤ì–‘í•œ ëª¨ë‹¬ë¦¬í‹° ì´í•´ ëŠ¥ë ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ MCUBë¥¼ ì œì•ˆí•˜ì—¬ ì—°êµ¬ ë°œì „ì— ê¸°ì—¬í•©ë‹ˆë‹¤.

### ì•½ì /í•œê³„ì  (Limitations)
1. **íŒŒë¼ë¯¸í„° ê°„ì„­ ë¬¸ì œ:** ëª¨ë¸ ì¡°í•© ê³¼ì •ì—ì„œ íŒŒë¼ë¯¸í„° ê°„ì„­ ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆìœ¼ë©°, DAMCë¥¼ í†µí•´ ì™„í™”í•˜ì§€ë§Œ ê·¼ë³¸ì ì¸ í•´ê²°ì±…ì€ ì•„ë‹ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
2. **ëª¨ë¸ ì„ íƒ ì˜ì¡´ì„±:** ì¡°í•©í•˜ëŠ” ê¸°ì¡´ MLLMì˜ ì„±ëŠ¥ì— ë”°ë¼ ìµœì¢… ëª¨ë¸ì˜ ì„±ëŠ¥ì´ í¬ê²Œ ì¢Œìš°ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
3. **ì´ˆë¡ì˜ ì •ë³´ ë¶€ì¡±:** ì´ˆë¡ì— êµ¬ì²´ì ì¸ ì‹¤í—˜ ê²°ê³¼, ì‚¬ìš©ëœ ëª¨ë¸ ì¢…ë¥˜, DAMCì˜ ì‘ë™ ì›ë¦¬ ë“± ì¤‘ìš”í•œ ì •ë³´ê°€ ë¶€ì¡±í•˜ì—¬ ë…¼ë¬¸ì˜ ì „ì²´ì ì¸ ë‚´ìš©ì„ íŒŒì•…í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤.

### ë‚´ ì—°êµ¬ì™€ì˜ ì—°ê´€ì„±
ë³¸ ë…¼ë¬¸ì€ ì œ ì—°êµ¬ ë¶„ì•¼ì¸ MLLM merging, Korean MLLM, vision-text alignment, document/chart/OCR/table VQAì™€ ë°€ì ‘í•˜ê²Œ ê´€ë ¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ, MLLM mergingì„ í†µí•´ ì„±ëŠ¥ í–¥ìƒì„ ë„ëª¨í•˜ëŠ” ì œ ì—°êµ¬ì™€ ì§ì ‘ì ì¸ ì—°ê´€ì„±ì„ ê°€ì§€ë©°, DAMCë¥¼ í†µí•´ íŒŒë¼ë¯¸í„° ê°„ì„­ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë°©ì‹ì€ ì œ ì—°êµ¬ì— ì ìš©í•˜ì—¬ í•œêµ­ì–´ MLLMì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, MCUB ë²¤ì¹˜ë§ˆí¬ëŠ” ë¬¸ì„œ/ì°¨íŠ¸/OCR/í…Œì´ë¸” ì´í•´ íŠ¹í™” MLLMì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” ë° í™œìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ì—°êµ¬ ì•„ì´ë””ì–´ ì œì•ˆ
1. **DAMCì˜ ì‘ë™ ì›ë¦¬ ë¶„ì„ ë° ê°œì„ :** DAMCì˜ êµ¬ì²´ì ì¸ ì‘ë™ ì›ë¦¬ë¥¼ ë¶„ì„í•˜ê³ , íŒŒë¼ë¯¸í„° ê°„ì„­ ë¬¸ì œë¥¼ ë”ìš± íš¨ê³¼ì ìœ¼ë¡œ í•´ê²°í•  ìˆ˜ ìˆëŠ” ìƒˆë¡œìš´ ê¸°ë²•ì„ ê°œë°œí•©ë‹ˆë‹¤.
2. **í•œêµ­ì–´ MLLM Merging ì—°êµ¬:** ë³¸ ë…¼ë¬¸ì˜ ë°©ë²•ì„ í™œìš©í•˜ì—¬ í•œêµ­ì–´ MLLMì„ mergingí•˜ê³ , í•œêµ­ì–´ ë°ì´í„°ì…‹ì„ í™œìš©í•˜ì—¬ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤. íŠ¹íˆ, í•œêµ­ì–´ ë¬¸ì„œ/ì°¨íŠ¸/OCR/í…Œì´ë¸” ì´í•´ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ë° ì´ˆì ì„ ë§ì¶¥ë‹ˆë‹¤.
3. **MCUB ë²¤ì¹˜ë§ˆí¬ í™•ì¥:** MCUB ë²¤ì¹˜ë§ˆí¬ì— í•œêµ­ì–´ ë¬¸ì„œ/ì°¨íŠ¸/OCR/í…Œì´ë¸” ì´í•´ ëŠ¥ë ¥ì„ í‰ê°€í•  ìˆ˜ ìˆëŠ” ë°ì´í„°ì…‹ì„ ì¶”ê°€í•˜ì—¬ ë²¤ì¹˜ë§ˆí¬ì˜ í™œìš©ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.

### í•µì‹¬ í‚¤ì›Œë“œ
- Multimodal Large Language Models (MLLM)
- Model Composition
- Model Merging
- Vision-Language Alignment
- Benchmark (MCUB)
- Parameter Interference
- Multimodal Understanding


---

> ğŸ¤– ì´ ê¸€ì€ AI ì—°êµ¬ ì–´ì‹œìŠ¤í„´íŠ¸ì— ì˜í•´ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.
> ë¶„ì„ ëª¨ë¸: google/gemma-3-27b-it:free
