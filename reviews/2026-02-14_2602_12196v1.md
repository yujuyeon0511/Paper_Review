---
title: "Visual Reasoning Benchmark: Evaluating Multimodal LLMs on Classroom-Authentic Vi"
date: 2026-02-14
arxiv: "2602.12196v1"
category: "cs.CL"
model: "google/gemma-3-27b-it:free"
---

# Visual Reasoning Benchmark: Evaluating Multimodal LLMs on Classroom-Authentic Visual Problems from Primary Education

## ğŸ“– ë…¼ë¬¸ ì •ë³´

| í•­ëª© | ë‚´ìš© |
|------|------|
| **ì €ì** | Mohamed Huti, Alasdair Mackintosh, Amy Waldock, Dominic Andrews, Maxime LeliÃ¨vre... |
| **ë°œí‘œì¼** | 2026-02-12 |
| **arXiv** | [2602.12196v1](https://arxiv.org/pdf/2602.12196v1) |
| **ì¹´í…Œê³ ë¦¬** | cs.CL |

---

## ğŸ“ ì´ˆë¡ (Abstract)

AI models have achieved state-of-the-art results in textual reasoning; however, their ability to reason over spatial and relational structures remains a critical bottleneck -- particularly in early-grade maths, which relies heavily on visuals. This paper introduces the visual reasoning benchmark (VRB), a novel dataset designed to evaluate Multimodal Large Language Models (MLLMs) on their ability to solve authentic visual problems from classrooms. This benchmark is built on a set of 701 questions sourced from primary school examinations in Zambia and India, which cover a range of tasks such as reasoning by analogy, pattern completion, and spatial matching. We outline the methodology and development of the benchmark which intentionally uses unedited, minimal-text images to test if models can meet realistic needs of primary education. Our findings reveal a ``jagged frontier'' of capability where models demonstrate better proficiency in static skills such as counting and scaling, but reach a distinct ``spatial ceiling'' when faced with dynamic operations like folding, reflection, and rotation. These weaknesses pose a risk for classroom use on visual reasoning problems, with the potential for incorrect marking, false scaffolding, and reinforcing student misconceptions. Consequently, education-focused benchmarks like the VRB are essential for determining the functional boundaries of multimodal tools used in classrooms.

---

## ğŸ” AI ë¶„ì„

## ë¶„ì„ ê²°ê³¼

### ğŸ“„ ë…¼ë¬¸ ìš”ì•½
ë³¸ ë…¼ë¬¸ì€ ì´ˆë“± êµìœ¡ í™˜ê²½ì—ì„œ ì‹¤ì œ ì‚¬ìš©ë˜ëŠ” ì‹œê°ì  ë¬¸ì œë¥¼ í†µí•´ Multimodal Large Language Models (MLLM)ì˜ ì‹œê°ì  ì¶”ë¡  ëŠ¥ë ¥ì„ í‰ê°€í•˜ëŠ” ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ì¸ Visual Reasoning Benchmark (VRB)ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. VRBëŠ” ì ë¹„ì•„ì™€ ì¸ë„ì˜ ì´ˆë“±í•™êµ ì‹œí—˜ ë¬¸ì œ 701ê°œë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, ìœ ì¶”, íŒ¨í„´ ì™„ì„±, ê³µê°„ ë§¤ì¹­ ë“±ì˜ ê³¼ì œë¥¼ í¬í•¨í•©ë‹ˆë‹¤. ì—°êµ¬ ê²°ê³¼, MLLMì€ ì •ì ì¸ ê¸°ìˆ (ê³„ì‚°, í¬ê¸° ì¡°ì ˆ)ì—ëŠ” ëŠ¥ìˆ™í•˜ì§€ë§Œ, ì ‘ê¸°, ë°˜ì‚¬, íšŒì „ê³¼ ê°™ì€ ë™ì ì¸ ì—°ì‚°ì—ëŠ” ì–´ë ¤ì›€ì„ ê²ªëŠ” 'ê³µê°„ì  í•œê³„'ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤. ì´ëŠ” ì‹¤ì œ êµìœ¡ í™˜ê²½ì—ì„œ MLLMì˜ í™œìš©ì— ì ì¬ì ì¸ ìœ„í—˜ì„ ì•¼ê¸°í•˜ë©°, êµìœ¡ ì¤‘ì‹¬ì˜ ë²¤ì¹˜ë§ˆí¬ì˜ ì¤‘ìš”ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤.

### ğŸ†• ìƒˆë¡œìš´ ì  (Novelty)
* **ì´ˆë“± êµìœ¡ í™˜ê²½ì— íŠ¹í™”ëœ ì‹œê°ì  ì¶”ë¡  ë²¤ì¹˜ë§ˆí¬:** ê¸°ì¡´ VQA ë²¤ì¹˜ë§ˆí¬ë“¤ì´ ì¼ë°˜ì ì¸ ì´ë¯¸ì§€ ì´í•´ì— ì´ˆì ì„ ë§ì¶˜ ë°˜ë©´, VRBëŠ” ì‹¤ì œ ì´ˆë“± êµìœ¡ì—ì„œ ì‚¬ìš©ë˜ëŠ” ë¬¸ì œ ìœ í˜•ì„ ë°˜ì˜í•˜ì—¬ MLLMì˜ êµìœ¡ì  í™œìš© ê°€ëŠ¥ì„±ì„ í‰ê°€í•©ë‹ˆë‹¤.
* **unedited, minimal-text ì´ë¯¸ì§€ ì‚¬ìš©:** ì¸ìœ„ì ìœ¼ë¡œ ê°€ê³µëœ ì´ë¯¸ì§€ê°€ ì•„ë‹Œ ì‹¤ì œ ì‹œí—˜ ë¬¸ì œì˜ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ í˜„ì‹¤ì ì¸ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì„ ì¸¡ì •í•©ë‹ˆë‹¤.
* **'ê³µê°„ì  í•œê³„' ê°œë… ì œì‹œ:** MLLMì´ ì •ì ì¸ ê¸°ìˆ ì—ëŠ” ëŠ¥ìˆ™í•˜ì§€ë§Œ, ë™ì ì¸ ê³µê°„ ì¶”ë¡ ì—ëŠ” ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤ëŠ” ìƒˆë¡œìš´ ê´€ì ì„ ì œì‹œí•©ë‹ˆë‹¤.

### ğŸ’ª ê°•ì  (Strengths)
1. **í˜„ì‹¤ì ì¸ í‰ê°€ í™˜ê²½:** ì‹¤ì œ êµìœ¡ í™˜ê²½ì˜ ë¬¸ì œë¥¼ ì‚¬ìš©í•˜ì—¬ MLLMì˜ ì‹¤ì§ˆì ì¸ í™œìš© ê°€ëŠ¥ì„±ì„ í‰ê°€í•œë‹¤ëŠ” ì ì—ì„œ ì˜ë¯¸ê°€ ìˆìŠµë‹ˆë‹¤.
2. **ëª…í™•í•œ ë¬¸ì œì  ì§€ì :** MLLMì˜ 'ê³µê°„ì  í•œê³„'ë¥¼ ëª…í™•í•˜ê²Œ ì œì‹œí•˜ê³ , êµìœ¡ í™˜ê²½ì—ì„œì˜ ì ì¬ì ì¸ ìœ„í—˜ì„ ê°•ì¡°í•˜ì—¬ í–¥í›„ ì—°êµ¬ ë°©í–¥ì„ ì œì‹œí•©ë‹ˆë‹¤.
3. **ë°ì´í„°ì…‹ ê³µê°œ:** VRB ë°ì´í„°ì…‹ì„ ê³µê°œí•˜ì—¬ ë‹¤ë¥¸ ì—°êµ¬ìë“¤ì´ MLLMì˜ ì‹œê°ì  ì¶”ë¡  ëŠ¥ë ¥ì„ í‰ê°€í•˜ê³  ê°œì„ í•˜ëŠ” ë° ê¸°ì—¬í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.

### âš ï¸ ì•½ì /í•œê³„ì  (Limitations)
1. **êµ­ê°€ ë° ë¬¸í™”ì  í¸í–¥:** ë°ì´í„°ì…‹ì´ ì ë¹„ì•„ì™€ ì¸ë„ì˜ ì´ˆë“±í•™êµ ì‹œí—˜ ë¬¸ì œë¡œ êµ¬ì„±ë˜ì–´ ìˆì–´ ë‹¤ë¥¸ êµ­ê°€ ë˜ëŠ” ë¬¸í™”ê¶Œì˜ ë¬¸ì œì— ëŒ€í•œ ì¼ë°˜í™” ê°€ëŠ¥ì„±ì´ ë‚®ìŠµë‹ˆë‹¤.
2. **ë¬¸ì œ ìœ í˜•ì˜ ì œí•œ:** ìœ ì¶”, íŒ¨í„´ ì™„ì„±, ê³µê°„ ë§¤ì¹­ ë“± íŠ¹ì • ìœ í˜•ì˜ ë¬¸ì œì— ì§‘ì¤‘ë˜ì–´ ìˆì–´ MLLMì˜ ì‹œê°ì  ì¶”ë¡  ëŠ¥ë ¥ì˜ ì „ì²´ì ì¸ ì¸¡ë©´ì„ í‰ê°€í•˜ê¸°ì—ëŠ” ë¶€ì¡±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
3. **ëª¨ë¸ ì„±ëŠ¥ ë¶„ì„ì˜ ê¹Šì´ ë¶€ì¡±:** ì–´ë–¤ ìœ í˜•ì˜ ì‹œê°ì  ì¶”ë¡ ì— íŠ¹íˆ ì–´ë ¤ì›€ì„ ê²ªëŠ”ì§€, ê·¸ ì›ì¸ì´ ë¬´ì—‡ì¸ì§€ì— ëŒ€í•œ ì‹¬ì¸µì ì¸ ë¶„ì„ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.

### ğŸ”— ë‚´ ì—°êµ¬ì™€ì˜ ì—°ê´€ì„±
ë³¸ ë…¼ë¬¸ì€ ì œ ì—°êµ¬ ë¶„ì•¼ì¸ Vision-Text Alignment, Document/Chart/OCR/Table VQAì™€ ë°€ì ‘í•˜ê²Œ ê´€ë ¨ë©ë‹ˆë‹¤. íŠ¹íˆ, MLLMì˜ ì‹œê°ì  ì¶”ë¡  ëŠ¥ë ¥ì˜ í•œê³„ë¥¼ ì§€ì í•˜ëŠ” ë¶€ë¶„ì€ Vision encoderì™€ Text LLM ê°„ì˜ ì •ë ¬(alignment) ë¬¸ì œì™€ ì§ì ‘ì ìœ¼ë¡œ ì—°ê²°ë©ë‹ˆë‹¤. VRB ë²¤ì¹˜ë§ˆí¬ëŠ” í•œêµ­ì–´ MLLM ê°œë°œ ë° í‰ê°€ì— í™œìš©ë  ìˆ˜ ìˆìœ¼ë©°, í•œêµ­ êµìœ¡ í™˜ê²½ì— ë§ëŠ” ì‹œê°ì  ì¶”ë¡  ë¬¸ì œ ë°ì´í„°ì…‹ êµ¬ì¶•ì˜ ì°¸ê³  ìë£Œê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ë¬¸ì„œ/ì°¨íŠ¸/í…Œì´ë¸” ì´í•´ íŠ¹í™” MLLM ì—°êµ¬ì— ìˆì–´, ê³µê°„ì  ì¶”ë¡  ëŠ¥ë ¥ì´ ì¤‘ìš”í•œ ìš”ì†Œì„ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.

### ğŸ’¡ ì—°êµ¬ ì•„ì´ë””ì–´ ì œì•ˆ
1. **í•œêµ­ì–´ VRB ë°ì´í„°ì…‹ êµ¬ì¶•:** í•œêµ­ ì´ˆë“±í•™êµ ì‹œí—˜ ë¬¸ì œë¥¼ ê¸°ë°˜ìœ¼ë¡œ VRBì™€ ìœ ì‚¬í•œ ë°ì´í„°ì…‹ì„ êµ¬ì¶•í•˜ì—¬ í•œêµ­ì–´ MLLMì˜ ì‹œê°ì  ì¶”ë¡  ëŠ¥ë ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.
2. **Vision-Text Alignment ê°œì„  ì—°êµ¬:** VRB ë°ì´í„°ì…‹ì„ í™œìš©í•˜ì—¬ MLLMì˜ 'ê³µê°„ì  í•œê³„'ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•œ Vision encoderì™€ Text LLM ê°„ì˜ ì •ë ¬(alignment) ê¸°ë²•ì„ ì—°êµ¬í•©ë‹ˆë‹¤. íŠ¹íˆ, ë™ì ì¸ ê³µê°„ ì—°ì‚°ì— ëŒ€í•œ ì´í•´ë„ë¥¼ ë†’ì´ëŠ” ë° ì´ˆì ì„ ë§ì¶¥ë‹ˆë‹¤.
3. **DocVQA/ChartQA ëª¨ë¸ì˜ ê³µê°„ ì¶”ë¡  ëŠ¥ë ¥ ê°•í™”:** ë¬¸ì„œ/ì°¨íŠ¸ ë‚´ì˜ ê³µê°„ì  ê´€ê³„ë¥¼ ì´í•´í•˜ê³  ì¶”ë¡ í•˜ëŠ” ëŠ¥ë ¥ì„ ê°•í™”í•˜ëŠ” DocVQA/ChartQA ëª¨ë¸ì„ ê°œë°œí•©ë‹ˆë‹¤. VRBì˜ ë¬¸ì œ ìœ í˜•ì„ ì°¨ìš©í•˜ì—¬ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
4. **MLLM Mergingì„ í†µí•œ ì„±ëŠ¥ í–¥ìƒ ì—°êµ¬:** VRB ë°ì´í„°ì…‹ì— ëŒ€í•œ ì„±ëŠ¥ì´ ì¢‹ì€ ëª¨ë¸ë“¤ì„ Mergingí•˜ì—¬, ì‹œê°ì  ì¶”ë¡  ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ì—°êµ¬ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.

### ğŸ“š í•µì‹¬ í‚¤ì›Œë“œ
1. Visual Reasoning
2. Multimodal LLM (MLLM)
3. Vision-Language Alignment
4. Educational Benchmark
5. Spatial Reasoning


---

> ğŸ¤– ì´ ê¸€ì€ AI ì—°êµ¬ ì–´ì‹œìŠ¤í„´íŠ¸ì— ì˜í•´ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.
> ë¶„ì„ ëª¨ë¸: google/gemma-3-27b-it:free
