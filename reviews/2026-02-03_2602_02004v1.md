---
title: "ClueTracer: Question-to-Vision Clue Tracing for Training-Free Hallucination Supp"
date: 2026-02-03
arxiv: "2602.02004v1"
category: "cs.CV"
model: "google/gemma-3-27b-it:free"
---

# ClueTracer: Question-to-Vision Clue Tracing for Training-Free Hallucination Suppression in Multimodal Reasoning

## ğŸ“– ë…¼ë¬¸ ì •ë³´

| í•­ëª© | ë‚´ìš© |
|------|------|
| **ì €ì** | Gongli Xi, Kun Wang, Zeming Gao, Huahui Yi, Haolang Lu... |
| **ë°œí‘œì¼** | 2026-02-02 |
| **arXiv** | [2602.02004v1](https://arxiv.org/pdf/2602.02004v1) |
| **ì¹´í…Œê³ ë¦¬** | cs.CV |

---

## ğŸ“ ì´ˆë¡ (Abstract)

Large multimodal reasoning models solve challenging visual problems via explicit long-chain inference: they gather visual clues from images and decode clues into textual tokens. Yet this capability also increases hallucinations, where the model generates content that is not supported by the input image or the question. To understand this failure mode, we identify \emph{reasoning drift}: during clue gathering, the model over-focuses on question-irrelevant entities, diluting focus on task-relevant cues and gradually decoupling the reasoning trace from visual grounding. As a consequence, many inference-time localization or intervention methods developed for non-reasoning models fail to pinpoint the true clues in reasoning settings. Motivated by these insights, we introduce ClueRecall, a metric for assessing visual clue retrieval, and present ClueTracer, a training-free, parameter-free, and architecture-agnostic plugin for hallucination suppression. ClueTracer starts from the question and traces how key clues propagate along the model's reasoning pathway (question $\rightarrow$ outputs $\rightarrow$ visual tokens), thereby localizing task-relevant patches while suppressing spurious attention to irrelevant regions. Remarkably, \textbf{without any additional training}, ClueTracer improves all \textbf{reasoning} architectures (including \texttt{R1-OneVision}, \texttt{Ocean-R1}, \texttt{MM-Eureka}, \emph{etc}.) by $\mathbf{1.21\times}$ on reasoning benchmarks. When transferred to \textbf{non-reasoning} settings, it yields a $\mathbf{1.14\times}$ gain.

---

## ğŸ” AI ë¶„ì„

## ClueTracer ë…¼ë¬¸ ë¶„ì„

### ğŸ“„ ë…¼ë¬¸ ìš”ì•½
ë³¸ ë…¼ë¬¸ì€ Multimodal Large Language Model (MLLM)ì˜ ì¶”ë¡  ê³¼ì •ì—ì„œ ë°œìƒí•˜ëŠ” í™˜ê°(hallucination) í˜„ìƒì˜ ê·¼ë³¸ì ì¸ ì›ì¸ì„ 'ì¶”ë¡  ë“œë¦¬í”„íŠ¸(reasoning drift)'ë¡œ ê·œëª…í•˜ê³ , ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ í•™ìŠµ ì—†ì´ ì ìš© ê°€ëŠ¥í•œ í”ŒëŸ¬ê·¸ì¸ ClueTracerë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ClueTracerëŠ” ì§ˆë¬¸ì—ì„œ ì‹œì‘í•˜ì—¬ ëª¨ë¸ì˜ ì¶”ë¡  ê²½ë¡œë¥¼ ë”°ë¼ í•µì‹¬ì ì¸ ì‹œê°ì  ë‹¨ì„œë¥¼ ì¶”ì í•˜ê³ , ê´€ë ¨ ì—†ëŠ” ì˜ì—­ì— ëŒ€í•œ ì£¼ì˜ë¥¼ ì–µì œí•˜ì—¬ í™˜ê°ì„ íš¨ê³¼ì ìœ¼ë¡œ ì–µì œí•©ë‹ˆë‹¤. íŠ¹íˆ, ì¶”ê°€ì ì¸ í•™ìŠµ ì—†ì´ ë‹¤ì–‘í•œ ì¶”ë¡  ê¸°ë°˜ MLLM ì•„í‚¤í…ì²˜ì—ì„œ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì´ë©°, ë¹„-ì¶”ë¡  ê¸°ë°˜ ëª¨ë¸ì—ì„œë„ íš¨ê³¼ì ì¸ ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.

### ğŸ†• ìƒˆë¡œìš´ ì  (Novelty)
* **ì¶”ë¡  ë“œë¦¬í”„íŠ¸(Reasoning Drift) ê°œë… ì œì‹œ:** MLLMì˜ í™˜ê° í˜„ìƒì„ ê¸°ì¡´ì˜ ì‹œê°ì  ê·¼ê±° ë¶€ì¡±ìœ¼ë¡œë§Œ ë³´ê¸°ë³´ë‹¤, ì¶”ë¡  ê³¼ì •ì—ì„œ ì§ˆë¬¸ê³¼ ê´€ë ¨ ì—†ëŠ” ê°ì²´ì— ê³¼ë„í•˜ê²Œ ì§‘ì¤‘í•˜ì—¬ í•µì‹¬ ë‹¨ì„œê°€ í¬ì„ë˜ëŠ” 'ì¶”ë¡  ë“œë¦¬í”„íŠ¸'ë¼ëŠ” ìƒˆë¡œìš´ ê´€ì ì„ ì œì‹œí–ˆìŠµë‹ˆë‹¤.
* **ClueRecall metric:** ì‹œê°ì  ë‹¨ì„œ ê²€ìƒ‰ ëŠ¥ë ¥ì„ í‰ê°€í•˜ëŠ” ìƒˆë¡œìš´ ì§€í‘œ ClueRecallì„ ë„ì…í•˜ì—¬, ì¶”ë¡  ê³¼ì •ì—ì„œì˜ ì‹œê°ì  ë‹¨ì„œ í™œìš© ì •ë„ë¥¼ ì •ëŸ‰ì ìœ¼ë¡œ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.
* **Training-Free Hallucination Suppression:** ì¶”ê°€ì ì¸ í•™ìŠµ ì—†ì´ë„ MLLMì˜ í™˜ê°ì„ ì–µì œí•  ìˆ˜ ìˆëŠ” í”ŒëŸ¬ê·¸ì¸ ClueTracerë¥¼ ê°œë°œí•˜ì—¬, ì‹¤ìš©ì ì¸ í™œìš© ê°€ëŠ¥ì„±ì„ ë†’ì˜€ìŠµë‹ˆë‹¤.

### ğŸ’ª ê°•ì  (Strengths)
1. **ë¬¸ì œ ì •ì˜ì˜ ëª…í™•ì„±:** MLLMì˜ í™˜ê° ë¬¸ì œë¥¼ 'ì¶”ë¡  ë“œë¦¬í”„íŠ¸'ë¼ëŠ” ëª…í™•í•œ ê°œë…ìœ¼ë¡œ ì •ì˜í•˜ê³ , ê·¸ ì›ì¸ì„ ì‹¬ì¸µì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ë¬¸ì œ í•´ê²°ì— ì§‘ì¤‘í•  ìˆ˜ ìˆë„ë¡ í–ˆìŠµë‹ˆë‹¤.
2. **ì¼ë°˜í™” ê°€ëŠ¥ì„±:** ClueTracerëŠ” í•™ìŠµ ì—†ì´ ë‹¤ì–‘í•œ MLLM ì•„í‚¤í…ì²˜ì— ì ìš© ê°€ëŠ¥í•˜ë©°, ì¶”ë¡  ë° ë¹„-ì¶”ë¡  ê¸°ë°˜ ëª¨ë¸ ëª¨ë‘ì—ì„œ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì—¬ ì¼ë°˜í™” ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.
3. **ì‹¤ìš©ì ì¸ ì ‘ê·¼ ë°©ì‹:** ì¶”ê°€ì ì¸ í•™ìŠµ ì—†ì´ ì ìš© ê°€ëŠ¥í•œ í”ŒëŸ¬ê·¸ì¸ í˜•íƒœë¡œ ì œê³µë˜ì–´, ì‹¤ì œ MLLM í™œìš© í™˜ê²½ì—ì„œ ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•˜ë©°, ê°œë°œ ë° ë°°í¬ ë¹„ìš©ì„ ì ˆê°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### âš ï¸ ì•½ì /í•œê³„ì  (Limitations)
* **ì¶”ë¡  ê²½ë¡œ ì¶”ì ì˜ í•œê³„:** ClueTracerëŠ” ëª¨ë¸ì˜ ì¶”ë¡  ê²½ë¡œë¥¼ ë”°ë¼ ë‹¨ì„œë¥¼ ì¶”ì í•˜ì§€ë§Œ, ë³µì¡í•œ ì¶”ë¡  ê³¼ì •ì—ì„œ ëª¨ë“  í•µì‹¬ ë‹¨ì„œë¥¼ ì •í™•í•˜ê²Œ ì‹ë³„í•˜ê³  ì¶”ì í•˜ëŠ” ë° ì–´ë ¤ì›€ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
* **ì‹œê°ì  ë‹¨ì„œì˜ ì •ì˜:** 'ì‹œê°ì  ë‹¨ì„œ'ì˜ ì •ì˜ê°€ ë‹¤ì†Œ ì£¼ê´€ì ì¼ ìˆ˜ ìˆìœ¼ë©°, íŠ¹ì • ì‘ì—…ì´ë‚˜ ë°ì´í„°ì…‹ì— ë”°ë¼ ì ì ˆí•œ ë‹¨ì„œê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
* **ì„±ëŠ¥ í–¥ìƒì˜ ê·¼ë³¸ì ì¸ ì›ë¦¬:** ClueTracerê°€ ì„±ëŠ¥ í–¥ìƒì„ ê°€ì ¸ì˜¤ëŠ” ì •í™•í•œ ë©”ì»¤ë‹ˆì¦˜ì— ëŒ€í•œ ì‹¬ì¸µì ì¸ ë¶„ì„ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ë‹¨ìˆœíˆ ì£¼ì˜ë¥¼ ì–µì œí•˜ëŠ” ê²ƒ ì™¸ì— ë‹¤ë¥¸ ìš”ì¸ì´ ì‘ìš©í•  ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.

### ğŸ”— ë‚´ ì—°êµ¬ì™€ì˜ ì—°ê´€ì„±
ë³¸ ë…¼ë¬¸ì€ ì œê°€ í˜„ì¬ ì§„í–‰í•˜ê³  ìˆëŠ” Vision encoderì™€ Text LLM ê°„ì˜ ì •ë ¬(alignment) ì—°êµ¬ì— ë§¤ìš° ì¤‘ìš”í•œ ì‹œì‚¬ì ì„ ì œê³µí•©ë‹ˆë‹¤. íŠ¹íˆ, 'ì¶”ë¡  ë“œë¦¬í”„íŠ¸' ê°œë…ì€ ì‹œê°ì  ì •ë³´ê°€ LLMì˜ ì¶”ë¡  ê³¼ì •ì—ì„œ ì–´ë–»ê²Œ ì™œê³¡ë  ìˆ˜ ìˆëŠ”ì§€ ì´í•´í•˜ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤. ClueTracerì˜ ì•„ì´ë””ì–´ëŠ” Vision encoderì—ì„œ ì¶”ì¶œëœ ì‹œê°ì  íŠ¹ì§•ì´ LLMì˜ ì¶”ë¡  ê³¼ì •ì— ì ì ˆí•˜ê²Œ í™œìš©ë  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ì •ë ¬ ë©”ì»¤ë‹ˆì¦˜ì„ ê°œë°œí•˜ëŠ” ë° ì˜ê°ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ClueRecall metricì€ ì œê°€ ê°œë°œí•˜ê³  ìˆëŠ” alignment metricì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” ë° í™œìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ğŸ’¡ ì—°êµ¬ ì•„ì´ë””ì–´ ì œì•ˆ
* **ClueTracerì™€ Vision Encoder ê°œì„  ì—°ê³„:** ClueTracerë¥¼ í™œìš©í•˜ì—¬ ì¶”ë¡  ë“œë¦¬í”„íŠ¸ê°€ ë°œìƒí•˜ëŠ” Vision encoderì˜ íŠ¹ì • ë¶€ë¶„ì„ ì‹ë³„í•˜ê³ , í•´ë‹¹ ë¶€ë¶„ì„ ê°œì„ í•˜ëŠ” ì—°êµ¬ë¥¼ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, attention ë©”ì»¤ë‹ˆì¦˜ì„ ìˆ˜ì •í•˜ê±°ë‚˜, ìƒˆë¡œìš´ íŠ¹ì§• ì¶”ì¶œ ë°©ì‹ì„ ë„ì…í•˜ì—¬ ì¶”ë¡  ë“œë¦¬í”„íŠ¸ë¥¼ ì™„í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
* **ClueRecall metric í™•ì¥:** ClueRecall metricì„ ë‹¤ì–‘í•œ ì‹œê°ì  ì¶”ë¡  ì‘ì—…ì— ì ìš©í•˜ê³ , metricì˜ ì‹ ë¢°ë„ì™€ ìœ ìš©ì„±ì„ ê²€ì¦í•˜ëŠ” ì—°êµ¬ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, metricì„ ê°œì„ í•˜ì—¬ ë”ìš± ì •í™•í•˜ê²Œ ì‹œê°ì  ë‹¨ì„œ ê²€ìƒ‰ ëŠ¥ë ¥ì„ í‰ê°€í•  ìˆ˜ ìˆë„ë¡ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
* **ì¶”ë¡  ê²½ë¡œ ì‹œê°í™” ë° ë¶„ì„:** MLLMì˜ ì¶”ë¡  ê²½ë¡œë¥¼ ì‹œê°í™”í•˜ê³ , ClueTracerê°€ ì¶”ë¡  ê²½ë¡œì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•˜ì—¬, í™˜ê° ì–µì œ ë©”ì»¤ë‹ˆì¦˜ì„ ë”ìš± ì‹¬ì¸µì ìœ¼ë¡œ ì´í•´í•˜ëŠ” ì—°êµ¬ë¥¼ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ğŸ“š í•µì‹¬ í‚¤ì›Œë“œ
1. Multimodal Reasoning
2. Hallucination Suppression
3. Vision-Language Alignment
4. Reasoning Drift
5. Training-Free Method


---

> ğŸ¤– ì´ ê¸€ì€ AI ì—°êµ¬ ì–´ì‹œìŠ¤í„´íŠ¸ì— ì˜í•´ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.
> ë¶„ì„ ëª¨ë¸: google/gemma-3-27b-it:free
