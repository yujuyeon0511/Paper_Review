---
title: "FewMMBench: A Benchmark for Multimodal Few-Shot Learning"
date: 2026-02-27
arxiv: "2602.21854v1"
category: "cs.CL"
model: "google/gemma-3-4b-it:free"
---

# FewMMBench: A Benchmark for Multimodal Few-Shot Learning

## ğŸ“– ë…¼ë¬¸ ì •ë³´

| í•­ëª© | ë‚´ìš© |
|------|------|
| **ì €ì** | Mustafa Dogan, Ilker Kesen, Iacer Calixto, Aykut Erdem, Erkut Erdem |
| **ë°œí‘œì¼** | 2026-02-25 |
| **arXiv** | [2602.21854v1](https://arxiv.org/pdf/2602.21854v1) |
| **ì¹´í…Œê³ ë¦¬** | cs.CL |

---

## ğŸ“ ì´ˆë¡ (Abstract)

As multimodal large language models (MLLMs) advance in handling interleaved image-text data, assessing their few-shot learning capabilities remains an open challenge. In this paper, we introduce FewMMBench, a comprehensive benchmark designed to evaluate MLLMs under few-shot conditions, with a focus on In-Context Learning (ICL) and Chain-of-Thought (CoT) prompting. Covering a diverse suite of multimodal understanding tasks, from attribute recognition to temporal reasoning, FewMMBench enables systematic analysis across task types, model families, and prompting strategies. We evaluate 26 open-weight MLLMs from six model families across zero-shot, few-shot, and CoT-augmented few-shot settings. Our findings reveal that instruction-tuned models exhibit strong zero-shot performance but benefit minimally, or even regress, with additional demonstrations or CoT reasoning. Retrieval-based demonstrations and increased context size also yield limited gains. These results highlight FewMMBench as a rigorous testbed for diagnosing and advancing few-shot capabilities in multimodal LLMs. The data is available at: https://huggingface.co/datasets/mustafaa/FewMMBench

---

## ğŸ” AI ë¶„ì„

## ë¶„ì„ ê²°ê³¼: FewMMBench ë…¼ë¬¸ ë¶„ì„

### ğŸ“„ ë…¼ë¬¸ ìš”ì•½
FewMMBench ë…¼ë¬¸ì€ ë©€í‹°ëª¨ë‹¬ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(MLLM)ì˜ Few-Shot í•™ìŠµ ëŠ¥ë ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. ê¸°ì¡´ ì—°êµ¬ë“¤ì´ MLLMì˜ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ëŠ” ë° ì§‘ì¤‘í•œ ë°˜ë©´, ì´ ë…¼ë¬¸ì€ íŠ¹íˆ In-Context Learning (ICL) ë° Chain-of-Thought (CoT) í”„ë¡¬í”„íŒ…ì„ í™œìš©í•˜ì—¬ Few-Shot í™˜ê²½ì—ì„œì˜ MLLM ì„±ëŠ¥ì„ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•˜ëŠ” ë° ì´ˆì ì„ ë§ì¶”ê³  ìˆìŠµë‹ˆë‹¤. 26ê°œì˜ ì˜¤í”ˆ ì›¨ì´íŠ¸ MLLMì„ ëŒ€ìƒìœ¼ë¡œ Zero-Shot, Few-Shot, CoT-augmented Few-Shot ì„¸ ê°€ì§€ ì„¤ì •ì—ì„œ í‰ê°€í–ˆìœ¼ë©°, ê²°ê³¼ì ìœ¼ë¡œ instruction-tuned ëª¨ë¸ì€ Zero-Shot ì„±ëŠ¥ì´ ë›°ì–´ë‚˜ì§€ë§Œ, ì¶”ê°€ì ì¸ ë°ëª¨ë‚˜ CoT ì¶”ë¡ ì„ ì‚¬ìš©í•˜ë©´ ì˜¤íˆë ¤ ì„±ëŠ¥ì´ ì €í•˜ë˜ëŠ” ê²½í–¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ë˜í•œ, Retrieval-based ë°ëª¨ì™€ ì»¨í…ìŠ¤íŠ¸ í¬ê¸° ì¦ê°€ë„ ì œí•œì ì¸ íš¨ê³¼ë§Œ ë³´ì˜€ìŠµë‹ˆë‹¤.

### ğŸ†• ìƒˆë¡œìš´ ì  (Novelty)
*   **Few-Shot í•™ìŠµ í‰ê°€ ë²¤ì¹˜ë§ˆí¬:** MLLMì˜ Few-Shot í•™ìŠµ ëŠ¥ë ¥ì„ ì²´ê³„ì ìœ¼ë¡œ í‰ê°€í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ì¸ FewMMBenchë¥¼ ì œì‹œí–ˆìŠµë‹ˆë‹¤. ê¸°ì¡´ ë²¤ì¹˜ë§ˆí¬ë“¤ì´ ì£¼ë¡œ Zero-Shot ë˜ëŠ” íŠ¹ì • Taskì— ì§‘ì¤‘í–ˆë˜ ë°˜ë©´, ë‹¤ì–‘í•œ Task ìœ í˜•, ëª¨ë¸ ê°€ì¡±, í”„ë¡¬í”„íŠ¸ ì „ëµì„ í¬ê´„í•˜ì—¬ Few-Shot í™˜ê²½ì—ì„œì˜ MLLM ì„±ëŠ¥ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•  ìˆ˜ ìˆë„ë¡ í–ˆìŠµë‹ˆë‹¤.
*   **Instruction-tuned ëª¨ë¸ì˜ í•œê³„ ë°œê²¬:** Instruction-tuned ëª¨ë¸ì´ Few-Shot í™˜ê²½ì—ì„œ ì¶”ê°€ì ì¸ ë°ëª¨ë‚˜ CoT ì¶”ë¡ ì„ ì‚¬ìš©í•˜ë©´ ì˜¤íˆë ¤ ì„±ëŠ¥ì´ ì €í•˜ë˜ëŠ” í˜„ìƒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” MLLMì˜ Few-Shot í•™ìŠµ ì „ëµì— ëŒ€í•œ ìƒˆë¡œìš´ ì‹œê°ì„ ì œê³µí•©ë‹ˆë‹¤.
*   **Retrieval-based ë°ëª¨ì˜ í•œê³„:** Retrieval-based ë°ëª¨ì™€ ì»¨í…ìŠ¤íŠ¸ í¬ê¸° ì¦ê°€ê°€ Few-Shot ì„±ëŠ¥ í–¥ìƒì— í° ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ì ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.

### ğŸ’ª ê°•ì  (Strengths)
1.  **í¬ê´„ì ì¸ í‰ê°€:** ë‹¤ì–‘í•œ Task ìœ í˜•, ëª¨ë¸ ê°€ì¡±, í”„ë¡¬í”„íŠ¸ ì „ëµì„ í¬í•¨í•˜ì—¬ MLLMì˜ Few-Shot í•™ìŠµ ëŠ¥ë ¥ì„ ë‹¤ê°ë„ë¡œ í‰ê°€í–ˆìŠµë‹ˆë‹¤.
2.  **ì‹¤í—˜ì  ê²°ê³¼ì˜ ëª…í™•ì„±:** 26ê°œì˜ MLLMì„ ëŒ€ìƒìœ¼ë¡œ Zero-Shot, Few-Shot, CoT-augmented Few-Shot ì„¸ ê°€ì§€ ì„¤ì •ì—ì„œ ì‹¤í—˜ì„ ì§„í–‰í•˜ì—¬ ê²°ê³¼ì˜ ì‹ ë¢°ì„±ì„ ë†’ì˜€ìŠµë‹ˆë‹¤.
3.  **ì‹¤ìš©ì ì¸ ì‹œì‚¬ì :** Instruction-tuned ëª¨ë¸ì˜ í•œê³„ì™€ Retrieval-based ë°ëª¨ì˜ í•œê³„ë¥¼ ëª…í™•íˆ ì œì‹œí•˜ì—¬ MLLM ê°œë°œ ë° í™œìš©ì— ëŒ€í•œ ì‹¤ìš©ì ì¸ ì‹œì‚¬ì ì„ ì œê³µí•©ë‹ˆë‹¤.

### âš ï¸ ì•½ì /í•œê³„ì  (Limitations)
*   **Task ìœ í˜•ì˜ ì œí•œ:** FewMMBenchëŠ” attribute recognition, temporal reasoning ë“± íŠ¹ì • Task ìœ í˜•ì— ì§‘ì¤‘ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë” ë‹¤ì–‘í•œ Task ìœ í˜•ì„ í¬í•¨í•˜ë©´ ë²¤ì¹˜ë§ˆí¬ì˜ í™œìš©ë„ê°€ ë†’ì•„ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
*   **ëª¨ë¸ ê°€ì¡±ì˜ ì œí•œ:** 6ê°œì˜ ëª¨ë¸ ê°€ì¡±ë§Œì„ ëŒ€ìƒìœ¼ë¡œ í‰ê°€í–ˆìŠµë‹ˆë‹¤. ë” ë‹¤ì–‘í•œ ëª¨ë¸ ê°€ì¡±ì„ í¬í•¨í•˜ë©´ MLLMì˜ Few-Shot í•™ìŠµ ëŠ¥ë ¥ì— ëŒ€í•œ ë” ë„“ì€ ì‹œê°ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
*   **í”„ë¡¬í”„íŠ¸ ì „ëµì˜ ì œí•œ:** ICL ë° CoT í”„ë¡¬í”„íŒ… ì™¸ì— ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸ ì „ëµì„ ê³ ë ¤í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì–‘í•œ í”„ë¡¬í”„íŠ¸ ì „ëµì„ íƒìƒ‰í•˜ë©´ MLLMì˜ Few-Shot í•™ìŠµ ëŠ¥ë ¥ì„ ë”ìš± íš¨ê³¼ì ìœ¼ë¡œ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ğŸ”— ë‚´ ì—°êµ¬ì™€ì˜ ì—°ê´€ì„±
ë³¸ ì—°êµ¬ëŠ” MLLMì˜ Few-Shot í•™ìŠµ ëŠ¥ë ¥ì— ëŒ€í•œ ì´í•´ë¥¼ ë†’ì´ëŠ” ë° ì¤‘ìš”í•œ ê¸°ì—¬ë¥¼ í•©ë‹ˆë‹¤. íŠ¹íˆ, ì €ì˜ ì—°êµ¬ê°€ Vision encoderì™€ Text LLM ê°„ì˜ ì •ë ¬(alignment)ì— ì´ˆì ì„ ë§ì¶”ê³  ìˆëŠ” ì ì„ ê³ ë ¤í•  ë•Œ, FewMMBenchëŠ” MLLMì˜ ë‹¤ì–‘í•œ í”„ë¡¬í”„íŠ¸ ì „ëµê³¼ ì»¨í…ìŠ¤íŠ¸ í™œìš© ë°©ì‹ì´ Vision-Text Alignmentì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•˜ëŠ” ë° ìœ ìš©í•œ ë„êµ¬ê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, instruction-tuned ëª¨ë¸ì˜ í•œê³„ë¥¼ í™•ì¸í•œ ê²°ê³¼ëŠ” ì €ì˜ ì—°êµ¬ê°€ MLLMì˜ íš¨ê³¼ì ì¸ í•™ìŠµ ì „ëµì„ ê°œë°œí•˜ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ğŸ’¡ ì—°êµ¬ ì•„ì´ë””ì–´ ì œì•ˆ
1.  **FewMMBench í™•ì¥:** ì œì•ˆëœ ë²¤ì¹˜ë§ˆí¬ì— ë¬¸ì„œ/ì°¨íŠ¸/OCR/í…Œì´ë¸” VQAì™€ ê°™ì€ ì €ì˜ ì—°êµ¬ ë¶„ì•¼ì™€ ê´€ë ¨ëœ Task ìœ í˜•ì„ ì¶”ê°€í•˜ì—¬ MLLMì˜ ë¬¸ì„œ ì´í•´ ëŠ¥ë ¥ì„ í‰ê°€í•˜ëŠ” ë²¤ì¹˜ë§ˆí¬ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤.
2.  **Vision-Text Alignment íš¨ê³¼ ë¶„ì„:** FewMMBenchë¥¼ í™œìš©í•˜ì—¬ ë‹¤ì–‘í•œ í”„ë¡¬í”„íŠ¸ ì „ëµê³¼ ì»¨í…ìŠ¤íŠ¸ í¬ê¸°ê°€ Vision-Text Alignmentì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•©ë‹ˆë‹¤. íŠ¹íˆ, Instruction-tuned ëª¨ë¸ì˜ ê²½ìš°, Alignment ì „ëµì´ ì„±ëŠ¥ í–¥ìƒì— ì–¼ë§ˆë‚˜ íš¨ê³¼ì ì¸ì§€ ì§‘ì¤‘ì ìœ¼ë¡œ ì—°êµ¬í•©ë‹ˆë‹¤.
3.  **CoT í”„ë¡¬í”„íŒ… ê°œì„ :** FewMMBenchì—ì„œ CoT í”„ë¡¬í”„íŒ…ì´ ì„±ëŠ¥ í–¥ìƒì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•˜ê³ , CoT í”„ë¡¬í”„íŒ…ì˜ íš¨ìœ¨ì„±ì„ ë†’ì´ê¸° ìœ„í•œ ìƒˆë¡œìš´ ì „ëµì„ ê°œë°œí•©ë‹ˆë‹¤.

### ğŸ“š í•µì‹¬ í‚¤ì›Œë“œ
1.  Multimodal Large Language Models (MLLM)
2.  Few-Shot Learning
3.  In-Context Learning (ICL)
4.  Chain-of-Thought (CoT)
5.  Vision-Language Alignment

---

> ğŸ¤– ì´ ê¸€ì€ AI ì—°êµ¬ ì–´ì‹œìŠ¤í„´íŠ¸ì— ì˜í•´ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.
> ë¶„ì„ ëª¨ë¸: google/gemma-3-4b-it:free
