---
title: "NÃ¼wa: Mending the Spatial Integrity Torn by VLM Token Pruning"
date: 2026-02-04
arxiv: "2602.02951v1"
category: "cs.CV"
model: "google/gemma-3-27b-it:free"
---

# NÃ¼wa: Mending the Spatial Integrity Torn by VLM Token Pruning

## ğŸ“– ë…¼ë¬¸ ì •ë³´

| í•­ëª© | ë‚´ìš© |
|------|------|
| **ì €ì** | Yihong Huang, Fei Ma, Yihua Shao, Jingcai Guo, Zitong Yu... |
| **ë°œí‘œì¼** | 2026-02-03 |
| **arXiv** | [2602.02951v1](https://arxiv.org/pdf/2602.02951v1) |
| **ì¹´í…Œê³ ë¦¬** | cs.CV |

---

## ğŸ“ ì´ˆë¡ (Abstract)

Vision token pruning has proven to be an effective acceleration technique for the efficient Vision Language Model (VLM). However, existing pruning methods demonstrate excellent performance preservation in visual question answering (VQA) and suffer substantial degradation on visual grounding (VG) tasks. Our analysis of the VLM's processing pipeline reveals that strategies utilizing global semantic similarity and attention scores lose the global spatial reference frame, which is derived from the interactions of tokens' positional information. Motivated by these findings, we propose $\text{NÃ¼wa}$, a two-stage token pruning framework that enables efficient feature aggregation while maintaining spatial integrity. In the first stage, after the vision encoder, we apply three operations, namely separation, alignment, and aggregation, which are inspired by swarm intelligence algorithms to retain information-rich global spatial anchors. In the second stage, within the LLM, we perform text-guided pruning to retain task-relevant visual tokens. Extensive experiments demonstrate that $\text{NÃ¼wa}$ achieves SOTA performance on multiple VQA benchmarks (from 94% to 95%) and yields substantial improvements on visual grounding tasks (from 7% to 47%).

---

## ğŸ” AI ë¶„ì„

## NÃ¼wa: Mending the Spatial Integrity Torn by VLM Token Pruning ë…¼ë¬¸ ë¶„ì„

### ğŸ“„ ë…¼ë¬¸ ìš”ì•½
ë³¸ ë…¼ë¬¸ì€ VLM(Vision Language Model)ì˜ íš¨ìœ¨ì„±ì„ ë†’ì´ê¸° ìœ„í•œ Vision Token Pruning ê¸°ë²•ì˜ í•œê³„ë¥¼ ì§€ì í•˜ê³ , íŠ¹íˆ Visual Grounding(VG) taskì—ì„œ ì„±ëŠ¥ ì €í•˜ê°€ ë°œìƒí•˜ëŠ” ì›ì¸ì„ ë¶„ì„í–ˆìŠµë‹ˆë‹¤. ê¸°ì¡´ pruning ë°©ë²•ë“¤ì´ global semantic similarityì™€ attention scoreì— ì§‘ì¤‘í•˜ì—¬ positional information ê¸°ë°˜ì˜ global spatial reference frameì„ ìƒì–´ë²„ë¦°ë‹¤ëŠ” ì ì„ ë°í˜€ëƒˆìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ swarm intelligence ì•Œê³ ë¦¬ì¦˜ì—ì„œ ì˜ê°ì„ ë°›ì€ ë‘ ë‹¨ê³„ì˜ pruning frameworkì¸ NÃ¼waë¥¼ ì œì•ˆí•˜ë©°, VQAì™€ VG task ëª¨ë‘ì—ì„œ SOTA ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.

### ğŸ†• ìƒˆë¡œìš´ ì  (Novelty)
ê¸°ì¡´ Vision Token Pruning ë°©ë²•ë“¤ì´ ê°„ê³¼í–ˆë˜ **spatial integrityì˜ ì¤‘ìš”ì„±**ì„ ê°•ì¡°í•˜ê³ , ì´ë¥¼ ë³µì›í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì‹œí•œ ì ì´ ê°€ì¥ í° noveltyì…ë‹ˆë‹¤. íŠ¹íˆ, swarm intelligence ì•Œê³ ë¦¬ì¦˜ì„ í™œìš©í•˜ì—¬ ì •ë³´ê°€ í’ë¶€í•œ global spatial anchorsë¥¼ ìœ ì§€í•˜ëŠ” ë°©ì‹ì€ ê¸°ì¡´ ì—°êµ¬ì™€ ì°¨ë³„í™”ë©ë‹ˆë‹¤. ë˜í•œ, vision encoderì™€ LLM ëª¨ë‘ì—ì„œ pruningì„ ìˆ˜í–‰í•˜ì—¬ ì „ì²´ì ì¸ íš¨ìœ¨ì„±ì„ ë†’ì˜€ë‹¤ëŠ” ì ë„ ìƒˆë¡œìš´ ì‹œë„ì…ë‹ˆë‹¤.

### ğŸ’ª ê°•ì  (Strengths)
1. **ë¬¸ì œ ì •ì˜ì˜ ëª…í™•ì„±:** VLM pruningì˜ ê¸°ì¡´ ë°©ë²•ë“¤ì´ VG taskì—ì„œ ì„±ëŠ¥ ì €í•˜ë¥¼ ë³´ì´ëŠ” ì´ìœ ë¥¼ spatial integrity ì†ì‹¤ì´ë¼ëŠ” ê´€ì ì—ì„œ ëª…í™•í•˜ê²Œ ì •ì˜í•˜ê³  ë¶„ì„í–ˆìŠµë‹ˆë‹¤.
2. **íš¨ê³¼ì ì¸ í”„ë ˆì„ì›Œí¬:** NÃ¼waëŠ” VQAì™€ VG task ëª¨ë‘ì—ì„œ SOTA ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ë©°, ì œì•ˆí•˜ëŠ” ë°©ë²•ì˜ íš¨ê³¼ì„±ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤. íŠ¹íˆ VG taskì—ì„œì˜ ì„±ëŠ¥ í–¥ìƒ í­ì´ í½ë‹ˆë‹¤.
3. **ìƒˆë¡œìš´ ì ‘ê·¼ ë°©ì‹:** Swarm intelligence ì•Œê³ ë¦¬ì¦˜ì„ í™œìš©í•˜ì—¬ spatial anchorsë¥¼ ìœ ì§€í•˜ëŠ” ë°©ì‹ì€ ê¸°ì¡´ ì—°êµ¬ì—ì„œ ì‹œë„ë˜ì§€ ì•Šì•˜ë˜ ì°¸ì‹ í•œ ì ‘ê·¼ ë°©ì‹ì…ë‹ˆë‹¤.

### âš ï¸ ì•½ì /í•œê³„ì  (Limitations)
1. **Swarm Intelligence ì•Œê³ ë¦¬ì¦˜ì˜ ë³µì¡ì„±:** Swarm intelligence ì•Œê³ ë¦¬ì¦˜ì€ ê³„ì‚° ë³µì¡ë„ê°€ ë†’ì„ ìˆ˜ ìˆìœ¼ë©°, ì‹¤ì œ ì ìš© ì‹œ íš¨ìœ¨ì„± ì¸¡ë©´ì—ì„œ ì¶”ê°€ì ì¸ ê³ ë ¤ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
2. **íŠ¹ì • taskì— ëŒ€í•œ ìµœì í™”:** NÃ¼waëŠ” VQAì™€ VG taskì— ëŒ€í•œ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì—¬ì£¼ì§€ë§Œ, ë‹¤ë¥¸ multimodal taskì— ëŒ€í•œ ì¼ë°˜í™” ì„±ëŠ¥ì€ ê²€ì¦ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.
3. **Vision Encoderì— ëŒ€í•œ ì˜ì¡´ì„±:** NÃ¼waëŠ” íŠ¹ì • vision encoder êµ¬ì¡°ì— ìµœì í™”ë˜ì–´ ìˆì„ ê°€ëŠ¥ì„±ì´ ìˆìœ¼ë©°, ë‹¤ë¥¸ vision encoderì— ì ìš© ì‹œ ì„±ëŠ¥ ì €í•˜ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ğŸ”— ë‚´ ì—°êµ¬ì™€ì˜ ì—°ê´€ì„±
ë³¸ ë…¼ë¬¸ì€ ì œê°€ í˜„ì¬ ì§„í–‰í•˜ê³  ìˆëŠ” Vision encoderì™€ Text LLM ê°„ì˜ ì •ë ¬(alignment) ì—°êµ¬ì— ë§¤ìš° ë°€ì ‘í•˜ê²Œ ê´€ë ¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ, spatial integrityë¥¼ ìœ ì§€í•˜ëŠ” ê²ƒì´ VLMì˜ ì„±ëŠ¥ì— ì¤‘ìš”í•˜ë‹¤ëŠ” ì ì€ vision encoderì—ì„œ ì¶”ì¶œëœ featureê°€ LLMì— íš¨ê³¼ì ìœ¼ë¡œ ì „ë‹¬ë˜ê¸° ìœ„í•œ alignment ì „ëµ ìˆ˜ë¦½ì— ì¤‘ìš”í•œ ì‹œì‚¬ì ì„ ì œê³µí•©ë‹ˆë‹¤. ë˜í•œ, NÃ¼waì—ì„œ ì œì•ˆí•˜ëŠ” separation, alignment, aggregation ê³¼ì •ì€ vision encoder featureë¥¼ LLMì— ì í•©í•˜ê²Œ ë³€í™˜í•˜ëŠ” ê³¼ì •ìœ¼ë¡œ í•´ì„ë  ìˆ˜ ìˆìœ¼ë©°, ì œ ì—°êµ¬ì—ì„œ í™œìš©í•  ìˆ˜ ìˆëŠ” ì•„ì´ë””ì–´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

### ğŸ’¡ ì—°êµ¬ ì•„ì´ë””ì–´ ì œì•ˆ
1. **NÃ¼waì˜ spatial integrity ìœ ì§€ ê¸°ë²•ì„ ë‹¤ì–‘í•œ vision encoder êµ¬ì¡°ì— ì ìš©:** NÃ¼waì˜ í•µì‹¬ ì•„ì´ë””ì–´ë¥¼ ë‹¤ì–‘í•œ vision encoder (ì˜ˆ: Swin Transformer, CLIP)ì— ì ìš©í•˜ì—¬ ì„±ëŠ¥ ë³€í™”ë¥¼ ë¹„êµ ë¶„ì„í•˜ê³ , ìµœì ì˜ alignment ì „ëµì„ íƒìƒ‰í•©ë‹ˆë‹¤.
2. **Scientific ë„ë©”ì¸ì—ì„œì˜ NÃ¼wa ì ìš©:** Scientific document understanding task (ì˜ˆ: scientific figure captioning, scientific image retrieval)ì— NÃ¼waë¥¼ ì ìš©í•˜ì—¬ ì„±ëŠ¥ í–¥ìƒì„ í™•ì¸í•˜ê³ , scientific ë„ë©”ì¸ íŠ¹ì„±ì— ë§ëŠ” pruning ì „ëµì„ ê°œë°œí•©ë‹ˆë‹¤.
3. **NÃ¼waì˜ pruning ê³¼ì •ì„ LLMì˜ í•™ìŠµ ê³¼ì •ê³¼ í†µí•©:** NÃ¼waì˜ pruning ê³¼ì •ì„ LLMì˜ í•™ìŠµ ê³¼ì •ê³¼ í†µí•©í•˜ì—¬, LLMì´ ë”ìš± íš¨ìœ¨ì ìœ¼ë¡œ visual informationì„ í•™ìŠµí•˜ê³  í™œìš©í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. (ì˜ˆ: pruningëœ tokenì— ëŒ€í•œ attention weight ê°ì†Œ)

### ğŸ“š í•µì‹¬ í‚¤ì›Œë“œ
1. Vision Token Pruning
2. Visual Grounding
3. Spatial Integrity
4. Swarm Intelligence
5. Multimodal Reasoning


---

> ğŸ¤– ì´ ê¸€ì€ AI ì—°êµ¬ ì–´ì‹œìŠ¤í„´íŠ¸ì— ì˜í•´ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.
> ë¶„ì„ ëª¨ë¸: google/gemma-3-27b-it:free
