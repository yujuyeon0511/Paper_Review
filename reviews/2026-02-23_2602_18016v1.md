---
title: "Towards LLM-centric Affective Visual Customization via Efficient and Precise Emo"
date: 2026-02-23
arxiv: "2602.18016v1"
category: "cs.CV"
model: "google/gemma-3-27b-it:free"
---

# Towards LLM-centric Affective Visual Customization via Efficient and Precise Emotion Manipulating

## ğŸ“– ë…¼ë¬¸ ì •ë³´

| í•­ëª© | ë‚´ìš© |
|------|------|
| **ì €ì** | Jiamin Luo, Xuqian Gu, Jingjing Wang, Jiahong Lu |
| **ë°œí‘œì¼** | 2026-02-20 |
| **arXiv** | [2602.18016v1](https://arxiv.org/pdf/2602.18016v1) |
| **ì¹´í…Œê³ ë¦¬** | cs.CV |

---

## ğŸ“ ì´ˆë¡ (Abstract)

Previous studies on visual customization primarily rely on the objective alignment between various control signals (e.g., language, layout and canny) and the edited images, which largely ignore the subjective emotional contents, and more importantly lack general-purpose foundation models for affective visual customization. With this in mind, this paper proposes an LLM-centric Affective Visual Customization (L-AVC) task, which focuses on generating images within modifying their subjective emotions via Multimodal LLM. Further, this paper contends that how to make the model efficiently align emotion conversion in semantics (named inter-emotion semantic conversion) and how to precisely retain emotion-agnostic contents (named exter-emotion semantic retaining) are rather important and challenging in this L-AVC task. To this end, this paper proposes an Efficient and Precise Emotion Manipulating approach for editing subjective emotions in images. Specifically, an Efficient Inter-emotion Converting (EIC) module is tailored to make the LLM efficiently align emotion conversion in semantics before and after editing, followed by a Precise Exter-emotion Retaining (PER) module to precisely retain the emotion-agnostic contents. Comprehensive experimental evaluations on our constructed L-AVC dataset demonstrate the great advantage of the proposed EPEM approach to the L-AVC task over several state-of-the-art baselines. This justifies the importance of emotion information for L-AVC and the effectiveness of EPEM in efficiently and precisely manipulating such information.

---

## ğŸ” AI ë¶„ì„

## ğŸ“„ ë…¼ë¬¸ ìš”ì•½
ë³¸ ë…¼ë¬¸ì€ ê¸°ì¡´ì˜ ì‹œê°ì  ì»¤ìŠ¤í„°ë§ˆì´ì œì´ì…˜ ì—°êµ¬ê°€ ê°ê´€ì ì¸ ì‹ í˜¸ ì •ë ¬ì— ì§‘ì¤‘í•˜ë©° ì£¼ê´€ì ì¸ ê°ì • ë‚´ìš©ê³¼ ë²”ìš©ì ì¸ ê¸°ë°˜ ëª¨ë¸ ë¶€ì¡± ë¬¸ì œë¥¼ ì§€ì í•˜ê³ , Multimodal LLMì„ í™œìš©í•˜ì—¬ ì´ë¯¸ì§€ì˜ ê°ì •ì„ ìˆ˜ì •í•˜ëŠ” LLM-centric Affective Visual Customization (L-AVC) taskë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. íš¨ìœ¨ì ì¸ ê°ì • ë³€í™˜(inter-emotion semantic conversion)ê³¼ ê°ì • ë¬´ê´€ ë‚´ìš© ìœ ì§€(exter-emotion semantic retaining)ì˜ ì¤‘ìš”ì„±ì„ ê°•ì¡°í•˜ë©°, ì´ë¥¼ ìœ„í•œ Efficient and Precise Emotion Manipulating (EPEM) ì ‘ê·¼ ë°©ì‹ì„ ì œì‹œí•©ë‹ˆë‹¤. ì œì•ˆëœ EPEMì€ L-AVC ë°ì´í„°ì…‹ ìƒì—ì„œ ê¸°ì¡´ SOTA ëª¨ë¸ ëŒ€ë¹„ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì´ë©°, ê°ì • ì •ë³´ì˜ ì¤‘ìš”ì„±ê³¼ EPEMì˜ íš¨ê³¼ì„±ì„ ì…ì¦í•©ë‹ˆë‹¤.

### ğŸ†• ìƒˆë¡œìš´ ì  (Novelty)
* **LLM-centric Affective Visual Customization (L-AVC) task ì •ì˜:** ê¸°ì¡´ ì—°êµ¬ê°€ ë‹¤ë£¨ì§€ ì•Šì•˜ë˜ ì´ë¯¸ì§€ì˜ ì£¼ê´€ì ì¸ ê°ì • ìˆ˜ì •ì´ë¼ëŠ” ìƒˆë¡œìš´ taskë¥¼ ì •ì˜í•˜ê³ , ì´ë¥¼ Multimodal LLM ê¸°ë°˜ìœ¼ë¡œ ì ‘ê·¼í•©ë‹ˆë‹¤.
* **Inter-emotion Semantic Conversion & Exter-emotion Semantic Retaining ê°œë… ì œì‹œ:** ê°ì • ìˆ˜ì • taskì—ì„œ ì¤‘ìš”í•œ ë‘ ê°€ì§€ ìš”ì†Œì¸ ê°ì • ë³€í™˜ì˜ ì˜ë¯¸ë¡ ì  ì •ë ¬ê³¼ ê°ì • ë¬´ê´€ ë‚´ìš© ìœ ì§€ë¥¼ ëª…í™•íˆ ì •ì˜í•˜ê³ , ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ëª¨ë“ˆì„ ì œì•ˆí•©ë‹ˆë‹¤.
* **EPEM (Efficient and Precise Emotion Manipulating) ì ‘ê·¼ ë°©ì‹:** íš¨ìœ¨ì ì¸ ê°ì • ë³€í™˜ ëª¨ë“ˆ(EIC)ê³¼ ì •ë°€í•œ ê°ì • ë¬´ê´€ ë‚´ìš© ìœ ì§€ ëª¨ë“ˆ(PER)ì„ ê²°í•©í•˜ì—¬ ê°ì • ìˆ˜ì • ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ìƒˆë¡œìš´ ì ‘ê·¼ ë°©ì‹ì„ ì œì‹œí•©ë‹ˆë‹¤.

### ğŸ’ª ê°•ì  (Strengths)
1. **ìƒˆë¡œìš´ ì—°êµ¬ ë°©í–¥ ì œì‹œ:** ì´ë¯¸ì§€ ìƒì„± ë¶„ì•¼ì—ì„œ ê°ì •ì´ë¼ëŠ” ì£¼ê´€ì ì¸ ìš”ì†Œë¥¼ ë‹¤ë£¨ëŠ” ìƒˆë¡œìš´ ì—°êµ¬ ë°©í–¥ì„ ì œì‹œí•˜ì—¬, ê¸°ì¡´ ì—°êµ¬ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³ ì ì‹œë„í•©ë‹ˆë‹¤.
2. **ëª…í™•í•œ ë¬¸ì œ ì •ì˜ ë° í•´ê²°:** L-AVC taskë¥¼ ì •ì˜í•˜ê³ , ê°ì • ë³€í™˜ê³¼ ë‚´ìš© ìœ ì§€ë¼ëŠ” í•µì‹¬ ë¬¸ì œë¥¼ ëª…í™•í•˜ê²Œ ì œì‹œí•˜ë©°, ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ êµ¬ì²´ì ì¸ ëª¨ë“ˆì„ ì„¤ê³„í•©ë‹ˆë‹¤.
3. **ì‹¤í—˜ì  ê²€ì¦:** L-AVC ë°ì´í„°ì…‹ì„ êµ¬ì¶•í•˜ê³ , EPEMì˜ ì„±ëŠ¥ì„ ê¸°ì¡´ SOTA ëª¨ë¸ê³¼ ë¹„êµí•˜ì—¬ ì‹¤í—˜ì ìœ¼ë¡œ ê²€ì¦í•¨ìœ¼ë¡œì¨ ì œì•ˆ ë°©ì‹ì˜ íš¨ê³¼ì„±ì„ ì…ì¦í•©ë‹ˆë‹¤.

### âš ï¸ ì•½ì /í•œê³„ì  (Limitations)
1. **ë°ì´í„°ì…‹ êµ¬ì¶•ì˜ ì–´ë ¤ì›€:** ê°ì • ë ˆì´ë¸”ë§ì€ ì£¼ê´€ì ì´ê³  ì–´ë ¤ìš¸ ìˆ˜ ìˆìœ¼ë©°, L-AVC ë°ì´í„°ì…‹ì˜ í’ˆì§ˆê³¼ ë‹¤ì–‘ì„±ì´ ê²°ê³¼ì— í° ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë°ì´í„°ì…‹ êµ¬ì¶• ê³¼ì •ì— ëŒ€í•œ ìƒì„¸í•œ ì„¤ëª…ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.
2. **ê°ì • í‘œí˜„ì˜ í•œê³„:** ë…¼ë¬¸ì—ì„œ ë‹¤ë£¨ëŠ” ê°ì •ì˜ ì¢…ë¥˜ê°€ ì œí•œì ì¼ ìˆ˜ ìˆìœ¼ë©°, ë³µì¡í•˜ê³  ë¯¸ë¬˜í•œ ê°ì •ì„ í‘œí˜„í•˜ëŠ” ë° ì–´ë ¤ì›€ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
3. **LLM ì˜ì¡´ì„±:** EPEMì€ LLMì— í¬ê²Œ ì˜ì¡´í•˜ë©°, LLMì˜ ì„±ëŠ¥ì— ë”°ë¼ ê²°ê³¼ê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ í•œêµ­ì–´ LLMì— ëŒ€í•œ ì ìš© ê°€ëŠ¥ì„±ì€ ê²€ì¦ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.

### ğŸ”— ë‚´ ì—°êµ¬ì™€ì˜ ì—°ê´€ì„±
ë³¸ ë…¼ë¬¸ì€ ì €ì˜ ì—°êµ¬ ë¶„ì•¼ì¸ Vision-Text Alignment, MLLM Merging, Korean MLLMê³¼ ì—°ê´€ì„±ì´ ë†’ìŠµë‹ˆë‹¤. íŠ¹íˆ, ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ê°„ì˜ ì •ë ¬ ì—°êµ¬ì—ì„œ ê°ì •ì´ë¼ëŠ” ì£¼ê´€ì ì¸ ì •ë³´ë¥¼ ê³ ë ¤í•˜ëŠ” ê²ƒì€ ìƒˆë¡œìš´ ì‹œê°ì„ ì œê³µí•©ë‹ˆë‹¤. ë˜í•œ, MLLM Mergingì„ í†µí•´ ë‹¤ì–‘í•œ ê°ì • í‘œí˜„ ëŠ¥ë ¥ì„ ê°€ì§„ ëª¨ë¸ë“¤ì„ ê²°í•©í•˜ì—¬ ë”ìš± í’ë¶€í•œ ê°ì • í‘œí˜„ì´ ê°€ëŠ¥í•œ MLLMì„ ê°œë°œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•œêµ­ì–´ MLLMì— ì ìš©í•œë‹¤ë©´, í•œêµ­ì–´ ê°ì • í‘œí˜„ì— íŠ¹í™”ëœ ëª¨ë¸ì„ ê°œë°œí•˜ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ğŸ’¡ ì—°êµ¬ ì•„ì´ë””ì–´ ì œì•ˆ
1. **í•œêµ­ì–´ L-AVC ë°ì´í„°ì…‹ êµ¬ì¶• ë° í•œêµ­ì–´ LLM ì ìš©:** í•œêµ­ì–´ ê°ì • í‘œí˜„ì— íŠ¹í™”ëœ L-AVC ë°ì´í„°ì…‹ì„ êµ¬ì¶•í•˜ê³ , í•œêµ­ì–´ LLMì„ í™œìš©í•˜ì—¬ EPEMì„ ì ìš©í•œ ì—°êµ¬ë¥¼ ì§„í–‰í•˜ì—¬ í•œêµ­ì–´ ê°ì • ê¸°ë°˜ ì‹œê°ì  ì»¤ìŠ¤í„°ë§ˆì´ì œì´ì…˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
2. **MLLM Mergingì„ í†µí•œ ê°ì • í‘œí˜„ ë‹¤ì–‘ì„± í™•ë³´:** ë‹¤ì–‘í•œ ê°ì • í‘œí˜„ ëŠ¥ë ¥ì„ ê°€ì§„ MLLMë“¤ì„ Mergingí•˜ì—¬ ë”ìš± í’ë¶€í•˜ê³  ë¯¸ë¬˜í•œ ê°ì •ì„ í‘œí˜„í•  ìˆ˜ ìˆëŠ” MLLMì„ ê°œë°œí•˜ê³ , ì´ë¥¼ L-AVC taskì— ì ìš©í•˜ì—¬ ì„±ëŠ¥ì„ ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
3. **Vision Encoderì™€ LLM ê°„ì˜ ê°ì • ì •ë ¬ ì—°êµ¬:** Vision Encoderê°€ ì¶”ì¶œí•œ ì´ë¯¸ì§€ íŠ¹ì§•ê³¼ LLMì´ ì´í•´í•˜ëŠ” ê°ì • í‘œí˜„ ê°„ì˜ ì •ë ¬(alignment)ì„ ì—°êµ¬í•˜ì—¬, ê°ì • ê¸°ë°˜ ì‹œê°ì  ì»¤ìŠ¤í„°ë§ˆì´ì œì´ì…˜ ì„±ëŠ¥ì„ ë”ìš± í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ğŸ“š í•µì‹¬ í‚¤ì›Œë“œ
1. Affective Visual Customization
2. Multimodal Large Language Model (MLLM)
3. Emotion Manipulation
4. Vision-Language Alignment
5. Inter-emotion Semantic Conversion


---

> ğŸ¤– ì´ ê¸€ì€ AI ì—°êµ¬ ì–´ì‹œìŠ¤í„´íŠ¸ì— ì˜í•´ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.
> ë¶„ì„ ëª¨ë¸: google/gemma-3-27b-it:free
