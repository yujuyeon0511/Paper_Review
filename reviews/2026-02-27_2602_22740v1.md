---
title: "AMLRIS: Alignment-aware Masked Learning for Referring Image Segmentation"
date: 2026-02-27
arxiv: "2602.22740v1"
category: "cs.CV"
model: "google/gemma-3-4b-it:free"
---

# AMLRIS: Alignment-aware Masked Learning for Referring Image Segmentation

## ğŸ“– ë…¼ë¬¸ ì •ë³´

| í•­ëª© | ë‚´ìš© |
|------|------|
| **ì €ì** | Tongfei Chen, Shuo Yang, Yuguang Yang, Linlin Yang, Runtang Guo... |
| **ë°œí‘œì¼** | 2026-02-26 |
| **arXiv** | [2602.22740v1](https://arxiv.org/pdf/2602.22740v1) |
| **ì¹´í…Œê³ ë¦¬** | cs.CV |

---

## ğŸ“ ì´ˆë¡ (Abstract)

Referring Image Segmentation (RIS) aims to segment an object in an image identified by a natural language expression. The paper introduces Alignment-Aware Masked Learning (AML), a training strategy to enhance RIS by explicitly estimating pixel-level vision-language alignment, filtering out poorly aligned regions during optimization, and focusing on trustworthy cues. This approach results in state-of-the-art performance on RefCOCO datasets and also enhances robustness to diverse descriptions and scenarios

---

## ğŸ” AI ë¶„ì„

## ë…¼ë¬¸ ë¶„ì„: AMLRIS: Alignment-aware Masked Learning for Referring Image Segmentation

### ğŸ“„ ë…¼ë¬¸ ìš”ì•½
AMLRIS ë…¼ë¬¸ì€ Referring Image Segmentation (RIS) ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ìƒˆë¡œìš´ í•™ìŠµ ì „ëµì¸ Alignment-Aware Masked Learning (AML)ì„ ì œì‹œí•©ë‹ˆë‹¤. AMLì€ ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ê°„ì˜ pixel-level ì •ë ¬ì„ ëª…ì‹œì ìœ¼ë¡œ ì¶”ì •í•˜ì—¬, ì •ë ¬ì´ ë‚®ì€ ì˜ì—­ì„ í•„í„°ë§í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì‹œê°ì  ë‹¨ì„œë¥¼ ì§‘ì¤‘ì ìœ¼ë¡œ í™œìš©í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, RefCOCO ë°ì´í„°ì…‹ì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆìœ¼ë©°, ë‹¤ì–‘í•œ ì„¤ëª…ê³¼ ì‹œë‚˜ë¦¬ì˜¤ì— ëŒ€í•œ ê²¬ê³ ì„± í–¥ìƒë„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ì¦‰, í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ì •ë ¬ì„ ê°•í™”í•˜ì—¬ RIS ì„±ëŠ¥ì„ ê·¹ëŒ€í™”í•˜ëŠ” ë° ì´ˆì ì„ ë§ì¶˜ ì—°êµ¬ì…ë‹ˆë‹¤.

### ğŸ†• ìƒˆë¡œìš´ ì  (Novelty)
AMLRISì˜ í•µì‹¬ì ì¸ ìƒˆë¡œìš´ ì ì€ pixel-level vision-language alignmentì„ ëª…ì‹œì ìœ¼ë¡œ ì¶”ì •í•˜ê³  ì´ë¥¼ í™œìš©í•˜ì—¬ RIS í•™ìŠµì„ ê°œì„ í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ê¸°ì¡´ RIS ì—°êµ¬ë“¤ì€ ì£¼ë¡œ ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ê°„ì˜ ì „ë°˜ì ì¸ ì •ë ¬ì„ ê³ ë ¤í•˜ê±°ë‚˜, íŠ¹ì • íŠ¹ì§• ì¶”ì¶œì— ì§‘ì¤‘í•˜ëŠ” ê²½í–¥ì´ ìˆì—ˆìŠµë‹ˆë‹¤. AMLRISëŠ” pixel-level ì •ë ¬ì„ ì¶”ì •í•˜ê³ , ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµ ì˜ì—­ì„ ì„ íƒí•¨ìœ¼ë¡œì¨, ë”ìš± íš¨ê³¼ì ì¸ í•™ìŠµì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. íŠ¹íˆ, â€˜Masked Learningâ€™ ê¸°ë²•ì„ í™œìš©í•˜ì—¬ ì‹ ë¢°ë„ê°€ ë‚®ì€ ì˜ì—­ì„ ì œê±°í•˜ê³ , ì¤‘ìš”í•œ ì˜ì—­ì— ì§‘ì¤‘í•˜ëŠ” ì „ëµì€ RIS ì„±ëŠ¥ í–¥ìƒì— ê¸°ì—¬í•©ë‹ˆë‹¤.

### ğŸ’ª ê°•ì  (Strengths)
1. **Pixel-level Alignment ì¶”ì •:** ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ê°„ì˜ pixel-level ì •ë ¬ì„ ì¶”ì •í•˜ëŠ” ê²ƒì€ RIS ì„±ëŠ¥ í–¥ìƒì— ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ëª¨ë¸ì€ í…ìŠ¤íŠ¸ ì„¤ëª…ê³¼ ì´ë¯¸ì§€ì˜ ì—°ê´€ì„±ì„ ë”ìš± ì •í™•í•˜ê²Œ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
2. **Masked Learning í™œìš©:** ì‹ ë¢°ë„ê°€ ë‚®ì€ ì˜ì—­ì„ ë§ˆìŠ¤í‚¹ ì²˜ë¦¬í•˜ì—¬ í•™ìŠµ íš¨ìœ¨ì„ ë†’ì´ê³ , ëª¨ë¸ì´ ì¤‘ìš”í•œ ì˜ì—­ì— ì§‘ì¤‘í•˜ë„ë¡ ìœ ë„í•©ë‹ˆë‹¤. ì´ëŠ” í•™ìŠµ ì‹œê°„ ë‹¨ì¶• ë° ì„±ëŠ¥ í–¥ìƒì— ê¸°ì—¬í•©ë‹ˆë‹¤.
3. **RefCOCO ë°ì´í„°ì…‹ì—ì„œì˜ ìš°ìˆ˜í•œ ì„±ëŠ¥:** RefCOCO ë°ì´í„°ì…‹ì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆë‹¤ëŠ” ê²ƒì€ AMLRISì˜ íš¨ê³¼ë¥¼ ì…ì¦í•˜ëŠ” ì¤‘ìš”í•œ ì§€í‘œì…ë‹ˆë‹¤. ì´ëŠ” ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ëª¨ë¸ì˜ ì¼ë°˜í™” ëŠ¥ë ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

### âš ï¸ ì•½ì /í•œê³„ì  (Limitations)
1. **Pixel-level Alignment ì¶”ì •ì˜ ë³µì¡ì„±:** pixel-level ì •ë ¬ ì¶”ì •ì€ ê³„ì‚° ë¹„ìš©ì´ ë§ì´ ë“¤ ìˆ˜ ìˆìœ¼ë©°, ëª¨ë¸ì˜ ë³µì¡ì„±ì„ ì¦ê°€ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
2. **RefCOCO ë°ì´í„°ì…‹ ì˜ì¡´ì„±:** ì‹¤í—˜ ê²°ê³¼ê°€ RefCOCO ë°ì´í„°ì…‹ì—ë§Œ êµ­í•œë˜ì–´ ìˆì–´, ë‹¤ë¥¸ ë°ì´í„°ì…‹ì—ì„œì˜ ì„±ëŠ¥ì€ ì•„ì§ ê²€ì¦ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.
3. **í•œêµ­ì–´ ë°ì´í„°ì…‹ ì ìš© ê°€ëŠ¥ì„± ë¶ˆí™•ì‹¤:** ë…¼ë¬¸ì€ ì˜ì–´ ë°ì´í„°ì…‹ì— ëŒ€í•œ ì‹¤í—˜ ê²°ê³¼ë¥¼ ì œì‹œí•˜ê³  ìˆìœ¼ë¯€ë¡œ, í•œêµ­ì–´ ë°ì´í„°ì…‹ì— ì ìš© ê°€ëŠ¥ì„±ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ì¶”ê°€ ì—°êµ¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.

### ğŸ”— ë‚´ ì—°êµ¬ì™€ì˜ ì—°ê´€ì„±
AMLRISì˜ vision-language alignment ì—°êµ¬ëŠ” í˜„ì¬ ì €ì˜ ì—°êµ¬ ì£¼ì œì¸ MLLM ëª¨ë¸ ë¨¸ì§• ë° í•œêµ­ì–´ Multimodal LLM ê°œë°œê³¼ ë°€ì ‘í•˜ê²Œ ê´€ë ¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ, ë¬¸ì„œ/ì°¨íŠ¸/OCR/í…Œì´ë¸” ì´í•´ íŠ¹í™” MLLM ì—°êµ¬ì—ì„œ ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ê°„ì˜ ì •ë ¬ì„ ê°•í™”í•˜ëŠ” ê²ƒì€ ë§¤ìš° ì¤‘ìš”í•œ ìš”ì†Œì…ë‹ˆë‹¤. AMLRISì˜ pixel-level alignment ì¶”ì • ê¸°ë²•ì„ í™œìš©í•˜ì—¬, ë¬¸ì„œ ì´ë¯¸ì§€ì˜ íŠ¹ì • ì˜ì—­ì„ ì •í™•í•˜ê²Œ ì‹ë³„í•˜ê³ , í…ìŠ¤íŠ¸ ì„¤ëª…ê³¼ ì—°ê´€ì‹œí‚¤ëŠ” ì—°êµ¬ë¥¼ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, Vision Encoderì™€ Text LLM ê°„ì˜ ì •ë ¬ì„ ê°œì„ í•˜ëŠ” ê²ƒì€ í˜„ì¬ ì €ì˜ ì—°êµ¬ì—ì„œ í•´ê²°í•´ì•¼ í•  ê³¼ì œì´ë¯€ë¡œ, AMLRISì˜ ì•„ì´ë””ì–´ë¥¼ ì§ì ‘ì ìœ¼ë¡œ ì ìš©í•˜ì—¬ ì„±ëŠ¥ í–¥ìƒì„ ê¸°ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ğŸ’¡ ì—°êµ¬ ì•„ì´ë””ì–´ ì œì•ˆ
1. **AML ê¸°ë°˜ í•œêµ­ì–´ RIS ëª¨ë¸ ê°œë°œ:** AMLRISì˜ ê¸°ë²•ì„ í•œêµ­ì–´ ë°ì´í„°ì…‹ì— ì ìš©í•˜ì—¬ í•œêµ­ì–´ RIS ëª¨ë¸ì„ ê°œë°œí•˜ê³  ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.
2. **Multi-modal Alignment ê°•í™”:** ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¿ë§Œ ì•„ë‹ˆë¼, ì°¨íŠ¸, OCR ê²°ê³¼ ë“± ë‹¤ì–‘í•œ multimodal ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ pixel-level alignmentë¥¼ ì¶”ì •í•˜ëŠ” ë°©ë²•ì„ ì—°êµ¬í•©ë‹ˆë‹¤.
3. **Adaptive Masking ì „ëµ ê°œë°œ:** AMLì—ì„œ ì‚¬ìš©ë˜ëŠ” ë§ˆìŠ¤í‚¹ ì „ëµì„ í•™ìŠµ ë°ì´í„°ì˜ íŠ¹ì„±ì— ë”°ë¼ ë™ì ìœ¼ë¡œ ì¡°ì •í•˜ëŠ” ë°©ë²•ì„ ì—°êµ¬í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë”ìš± íš¨ê³¼ì ì¸ í•™ìŠµì´ ê°€ëŠ¥í•  ê²ƒì…ë‹ˆë‹¤.
4. **DocVQA/ChartQA/TextVQA ì—°ê³„ ì—°êµ¬:** AMLRISì˜ alignment ê¸°ë²•ì„ DocVQA, ChartQA, TextVQAì™€ ê°™ì€ multimodal VQA ë¬¸ì œì— ì ìš©í•˜ì—¬ ì„±ëŠ¥ í–¥ìƒì„ ì‹œë„í•©ë‹ˆë‹¤.
5. **Attention ë©”ì»¤ë‹ˆì¦˜ê³¼ì˜ ê²°í•©:** AMLì˜ alignment ì¶”ì • ê²°ê³¼ë¥¼ attention ë©”ì»¤ë‹ˆì¦˜ì— í™œìš©í•˜ì—¬, ëª¨ë¸ì´ ì¤‘ìš”í•œ ì˜ì—­ì— ë”ìš± ì§‘ì¤‘í•˜ë„ë¡ ìœ ë„í•©ë‹ˆë‹¤.

### ğŸ“š í•µì‹¬ í‚¤ì›Œë“œ
1. Referring Image Segmentation (RIS)
2. Alignment-Aware Masked Learning (AML)
3. Vision-Language Alignment
4. Pixel-Level Alignment
5. Multimodal Learning


---

> ğŸ¤– ì´ ê¸€ì€ AI ì—°êµ¬ ì–´ì‹œìŠ¤í„´íŠ¸ì— ì˜í•´ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.
> ë¶„ì„ ëª¨ë¸: google/gemma-3-4b-it:free
