---
title: "EmoSpace: Fine-Grained Emotion Prototype Learning for Immersive Affective Conten"
date: 2026-02-13
arxiv: "2602.11658v1"
category: "cs.CV"
model: "google/gemma-3-27b-it:free"
---

# EmoSpace: Fine-Grained Emotion Prototype Learning for Immersive Affective Content Generation

## ğŸ“– ë…¼ë¬¸ ì •ë³´

| í•­ëª© | ë‚´ìš© |
|------|------|
| **ì €ì** | Bingyuan Wang, Xingbei Chen, Zongyang Qiu, Linping Yuan, Zeyu Wang |
| **ë°œí‘œì¼** | 2026-02-12 |
| **arXiv** | [2602.11658v1](https://arxiv.org/pdf/2602.11658v1) |
| **ì¹´í…Œê³ ë¦¬** | cs.CV |

---

## ğŸ“ ì´ˆë¡ (Abstract)

Emotion is important for creating compelling virtual reality (VR) content. Although some generative methods have been applied to lower the barrier to creating emotionally rich content, they fail to capture the nuanced emotional semantics and the fine-grained control essential for immersive experiences. To address these limitations, we introduce EmoSpace, a novel framework for emotion-aware content generation that learns dynamic, interpretable emotion prototypes through vision-language alignment. We employ a hierarchical emotion representation with rich learnable prototypes that evolve during training, enabling fine-grained emotional control without requiring explicit emotion labels. We develop a controllable generation pipeline featuring multi-prototype guidance, temporal blending, and attention reweighting that supports diverse applications, including emotional image outpainting, stylized generation, and emotional panorama generation for VR environments. Our experiments demonstrate the superior performance of EmoSpace over existing methods in both qualitative and quantitative evaluations. Additionally, we present a comprehensive user study investigating how VR environments affect emotional perception compared to desktop settings. Our work facilitates immersive visual content generation with fine-grained emotion control and supports applications like therapy, education, storytelling, artistic creation, and cultural preservation. Code and models will be made publicly available.

---

## ğŸ” AI ë¶„ì„

## ğŸ“„ ë…¼ë¬¸ ìš”ì•½
EmoSpaceëŠ” VR ì½˜í…ì¸  ì œì‘ì— ì¤‘ìš”í•œ ê°ì • í‘œí˜„ì˜ ë¯¸ë¬˜í•œ ì˜ë¯¸ì™€ ì„¸ë°€í•œ ì œì–´ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. Vision-Language Alignmentë¥¼ í†µí•´ ë™ì ì´ê³  í•´ì„ ê°€ëŠ¥í•œ ê°ì • í”„ë¡œí† íƒ€ì…ì„ í•™ìŠµí•˜ë©°, ëª…ì‹œì ì¸ ê°ì • ë ˆì´ë¸” ì—†ì´ë„ ë¯¸ì„¸í•œ ê°ì • ì œì–´ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. Multi-prototype guidance, temporal blending, attention reweightingì„ íŠ¹ì§•ìœ¼ë¡œ í•˜ëŠ” ì œì–´ ê°€ëŠ¥í•œ ìƒì„± íŒŒì´í”„ë¼ì¸ì„ í†µí•´ ë‹¤ì–‘í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì§€ì›í•˜ë©°, ì‚¬ìš©ì ì—°êµ¬ë¥¼ í†µí•´ VR í™˜ê²½ì´ ê°ì • ì¸ì‹ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ë„ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.

### ğŸ†• ìƒˆë¡œìš´ ì  (Novelty)
EmoSpaceëŠ” ê¸°ì¡´ ê°ì • ê¸°ë°˜ ì½˜í…ì¸  ìƒì„± ë°©ë²•ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³ , ë‹¤ìŒê³¼ ê°™ì€ ìƒˆë¡œìš´ ì ì„ ì œì‹œí•©ë‹ˆë‹¤.

* **ë¯¸ì„¸í•œ ê°ì • ì œì–´:** ê¸°ì¡´ ì—°êµ¬ë“¤ì€ ê°ì •ì˜ ë‰˜ì•™ìŠ¤ë¥¼ ì œëŒ€ë¡œ í¬ì°©í•˜ì§€ ëª»í–ˆì§€ë§Œ, EmoSpaceëŠ” í•™ìŠµ ê°€ëŠ¥í•œ ê°ì • í”„ë¡œí† íƒ€ì…ì„ í†µí•´ ì„¸ë°€í•œ ê°ì • ì œì–´ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.
* **ëª…ì‹œì  ë ˆì´ë¸” ì—†ì´ ê°ì • í•™ìŠµ:** ëª…ì‹œì ì¸ ê°ì • ë ˆì´ë¸” ì—†ì´ë„ vision-language alignmentë¥¼ í†µí•´ ê°ì • í”„ë¡œí† íƒ€ì…ì„ í•™ìŠµí•˜ì—¬ ë°ì´í„° ìˆ˜ì§‘ ë° ë ˆì´ë¸”ë§ ë¹„ìš©ì„ ì ˆê°í•©ë‹ˆë‹¤.
* **VR í™˜ê²½ì—ì„œì˜ ê°ì • ì¸ì‹ ì—°êµ¬:** VR í™˜ê²½ì´ ê°ì • ì¸ì‹ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì‚¬ìš©ì ì—°êµ¬ë¥¼ í†µí•´ ë¶„ì„í•˜ì—¬ VR ì½˜í…ì¸  ì œì‘ì— ëŒ€í•œ ì´í•´ë„ë¥¼ ë†’ì˜€ìŠµë‹ˆë‹¤.

### ğŸ’ª ê°•ì  (Strengths)
1. **Vision-Language Alignment ê¸°ë°˜ì˜ ê°ì • í•™ìŠµ:** ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ê°„ì˜ ì—°ê´€ì„±ì„ í™œìš©í•˜ì—¬ ê°ì • í”„ë¡œí† íƒ€ì…ì„ í•™ìŠµí•˜ëŠ” ë°©ì‹ì€ ê°ì • í‘œí˜„ì˜ í’ë¶€í•¨ê³¼ ì •í™•ì„±ì„ ë†’ì…ë‹ˆë‹¤. ì´ëŠ” ì‚¬ìš©ìì˜ ì—°êµ¬ ë¶„ì•¼ì¸ Vision-Text Alignmentì™€ ì§ì ‘ì ì¸ ê´€ë ¨ì´ ìˆìŠµë‹ˆë‹¤.
2. **ì œì–´ ê°€ëŠ¥í•œ ìƒì„± íŒŒì´í”„ë¼ì¸:** Multi-prototype guidance, temporal blending, attention reweighting ë“±ì˜ ê¸°ìˆ ì„ í†µí•´ ìƒì„±ë˜ëŠ” ì½˜í…ì¸ ì˜ ê°ì •ì„ ì„¸ë°€í•˜ê²Œ ì œì–´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
3. **VR í™˜ê²½ì— íŠ¹í™”ëœ ì—°êµ¬:** VR í™˜ê²½ì—ì„œì˜ ê°ì • ì¸ì‹ì— ëŒ€í•œ ì‚¬ìš©ì ì—°êµ¬ëŠ” VR ì½˜í…ì¸  ì œì‘ì— ëŒ€í•œ ì‹¤ì§ˆì ì¸ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•˜ë©°, ëª°ì…í˜• ê²½í—˜ ë””ìì¸ì— ê¸°ì—¬í•©ë‹ˆë‹¤.

### âš ï¸ ì•½ì /í•œê³„ì  (Limitations)
1. **ê°ì • í”„ë¡œí† íƒ€ì…ì˜ í•´ì„ ê°€ëŠ¥ì„±:** í•™ìŠµëœ ê°ì • í”„ë¡œí† íƒ€ì…ì´ ì‹¤ì œë¡œ ì–´ë–¤ ì‹œê°ì  íŠ¹ì§•ê³¼ ì—°ê²°ë˜ëŠ”ì§€ ëª…í™•í•˜ê²Œ ì„¤ëª…í•˜ê¸° ì–´ë ¤ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•´ì„ ê°€ëŠ¥ì„±ì„ ë†’ì´ê¸° ìœ„í•œ ì¶”ê°€ì ì¸ ì—°êµ¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.
2. **ë°ì´í„°ì…‹ ì˜ì¡´ì„±:** Vision-Language Alignment í•™ìŠµì€ ì‚¬ìš©ëœ ë°ì´í„°ì…‹ì˜ í’ˆì§ˆê³¼ ë‹¤ì–‘ì„±ì— í¬ê²Œ ì˜ì¡´í•©ë‹ˆë‹¤. íŠ¹ì • ë°ì´í„°ì…‹ì— í¸í–¥ëœ ê°ì • í”„ë¡œí† íƒ€ì…ì´ í•™ìŠµë  ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.
3. **í•œêµ­ì–´ ì§€ì›:** ë…¼ë¬¸ì—ì„œ í•œêµ­ì–´ ë°ì´í„°ì…‹ì´ë‚˜ í•œêµ­ì–´ ëª¨ë¸ì— ëŒ€í•œ ì–¸ê¸‰ì´ ì—†ì–´, í•œêµ­ì–´ í™˜ê²½ì—ì„œì˜ ì ìš© ê°€ëŠ¥ì„±ì— ëŒ€í•œ ê²€ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤.

### ğŸ”— ë‚´ ì—°êµ¬ì™€ì˜ ì—°ê´€ì„±
ë³¸ ë…¼ë¬¸ì€ ì‚¬ìš©ìì˜ ì—°êµ¬ì™€ ë‹¤ìŒê³¼ ê°™ì€ ì¸¡ë©´ì—ì„œ ì—°ê´€ì„±ì´ ë†’ìŠµë‹ˆë‹¤.

* **Vision-Text Alignment:** EmoSpaceì˜ í•µì‹¬ ê¸°ìˆ ì¸ Vision-Text AlignmentëŠ” ì‚¬ìš©ìì˜ ì£¼ìš” ì—°êµ¬ ì£¼ì œì™€ ì¼ì¹˜í•©ë‹ˆë‹¤.
* **MLLM í™œìš©:** EmoSpaceëŠ” vision encoderì™€ language modelì„ ê²°í•©í•˜ì—¬ ê°ì • ê¸°ë°˜ ì½˜í…ì¸ ë¥¼ ìƒì„±í•˜ë¯€ë¡œ, MLLM ì—°êµ¬ì— ì ìš© ê°€ëŠ¥í•œ ì•„ì´ë””ì–´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
* **Document/Chart/OCR/Table VQA:** ê°ì • ë¶„ì„ ê¸°ìˆ ì€ ë¬¸ì„œ, ì°¨íŠ¸, í…Œì´ë¸” ë“± ë‹¤ì–‘í•œ ì‹œê°ì  ì •ë³´ì—ì„œ ê°ì •ì ì¸ ë§¥ë½ì„ íŒŒì•…í•˜ëŠ” ë° í™œìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì°¨íŠ¸ì˜ ìƒ‰ìƒì´ë‚˜ ë””ìì¸ì´ ì „ë‹¬í•˜ëŠ” ê°ì •ì„ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ë” íš¨ê³¼ì ì¸ ì‹œê°í™” ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ğŸ’¡ ì—°êµ¬ ì•„ì´ë””ì–´ ì œì•ˆ
1. **í•œêµ­ì–´ MLLM ê¸°ë°˜ EmoSpace êµ¬í˜„:** í•œêµ­ì–´ ë°ì´í„°ì…‹ê³¼ í•œêµ­ì–´ LLMì„ í™œìš©í•˜ì—¬ EmoSpaceë¥¼ êµ¬í˜„í•˜ê³ , í•œêµ­ì–´ ê°ì • í‘œí˜„ì— ëŒ€í•œ ì´í•´ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.
2. **ê°ì • í”„ë¡œí† íƒ€ì… ì‹œê°í™”:** í•™ìŠµëœ ê°ì • í”„ë¡œí† íƒ€ì…ì„ ì‹œê°ì ìœ¼ë¡œ í‘œí˜„í•˜ëŠ” ë°©ë²•ì„ ì—°êµ¬í•˜ì—¬ í•´ì„ ê°€ëŠ¥ì„±ì„ ë†’ì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, attention mapì„ í™œìš©í•˜ì—¬ ì–´ë–¤ ì‹œê°ì  íŠ¹ì§•ì´ íŠ¹ì • ê°ì • í”„ë¡œí† íƒ€ì…ê³¼ ê´€ë ¨ë˜ëŠ”ì§€ ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
3. **DocVQA/ChartQAì— ê°ì • ë¶„ì„ í†µí•©:** ë¬¸ì„œ ë˜ëŠ” ì°¨íŠ¸ VQA ì‹œìŠ¤í…œì— ê°ì • ë¶„ì„ ê¸°ëŠ¥ì„ í†µí•©í•˜ì—¬ ì‚¬ìš©ìì˜ ê°ì •ì ì¸ ì˜ë„ë¥¼ íŒŒì•…í•˜ê³ , ë” ì ì ˆí•œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, "ì´ ì°¨íŠ¸ì—ì„œ ê°€ì¥ ìš°ë ¤ë˜ëŠ” ë¶€ë¶„ì€ ë¬´ì—‡ì¸ê°€?"ë¼ëŠ” ì§ˆë¬¸ì— ëŒ€í•´ ì°¨íŠ¸ì˜ íŠ¹ì • ë¶€ë¶„ì„ ê°•ì¡°í•˜ê³ , í•´ë‹¹ ë¶€ë¶„ì— ëŒ€í•œ ê°ì •ì ì¸ ë¶„ì„ ê²°ê³¼ë¥¼ í•¨ê»˜ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
4. **MLLM Mergingì„ í†µí•œ ê°ì • í‘œí˜„ ì„±ëŠ¥ í–¥ìƒ:** ë‹¤ì–‘í•œ MLLM ëª¨ë¸ì„ ë¨¸ì§•í•˜ì—¬ ê°ì • í‘œí˜„ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ì—°êµ¬ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.

### ğŸ“š í•µì‹¬ í‚¤ì›Œë“œ
1. Vision-Language Alignment
2. Emotion Prototype
3. Affective Content Generation
4. Virtual Reality (VR)
5. Controllable Generation


---

> ğŸ¤– ì´ ê¸€ì€ AI ì—°êµ¬ ì–´ì‹œìŠ¤í„´íŠ¸ì— ì˜í•´ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.
> ë¶„ì„ ëª¨ë¸: google/gemma-3-27b-it:free
