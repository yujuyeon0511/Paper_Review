---
title: "Towards LLM-centric Affective Visual Customization via Efficient and Precise Emo"
date: 2026-02-25
arxiv: "2602.18016v1"
category: "cs.CV"
model: "google/gemma-3-27b-it:free"
---

# Towards LLM-centric Affective Visual Customization via Efficient and Precise Emotion Manipulating

## ğŸ“– ë…¼ë¬¸ ì •ë³´

| í•­ëª© | ë‚´ìš© |
|------|------|
| **ì €ì** | Jiamin Luo, Xuqian Gu, Jingjing Wang, Jiahong Lu |
| **ë°œí‘œì¼** | 2026-02-20 |
| **arXiv** | [2602.18016v1](https://arxiv.org/pdf/2602.18016v1) |
| **ì¹´í…Œê³ ë¦¬** | cs.CV |

---

## ğŸ“ ì´ˆë¡ (Abstract)

Previous studies on visual customization primarily rely on the objective alignment between various control signals (e.g., language, layout and canny) and the edited images, which largely ignore the subjective emotional contents, and more importantly lack general-purpose foundation models for affective visual customization. With this in mind, this paper proposes an LLM-centric Affective Visual Customization (L-AVC) task, which focuses on generating images within modifying their subjective emotions via Multimodal LLM. Further, this paper contends that how to make the model efficiently align emotion conversion in semantics (named inter-emotion semantic conversion) and how to precisely retain emotion-agnostic contents (named exter-emotion semantic retaining) are rather important and challenging in this L-AVC task. To this end, this paper proposes an Efficient and Precise Emotion Manipulating approach for editing subjective emotions in images. Specifically, an Efficient Inter-emotion Converting (EIC) module is tailored to make the LLM efficiently align emotion conversion in semantics before and after editing, followed by a Precise Exter-emotion Retaining (PER) module to precisely retain the emotion-agnostic contents. Comprehensive experimental evaluations on our constructed L-AVC dataset demonstrate the great advantage of the proposed EPEM approach to the L-AVC task over several state-of-the-art baselines. This justifies the importance of emotion information for L-AVC and the effectiveness of EPEM in efficiently and precisely manipulating such information.

---

## ğŸ” AI ë¶„ì„

## ğŸ“„ ë…¼ë¬¸ ìš”ì•½
ë³¸ ë…¼ë¬¸ì€ ê¸°ì¡´ì˜ ì‹œê°ì  ì»¤ìŠ¤í„°ë§ˆì´ì œì´ì…˜ ì—°êµ¬ê°€ ê°ê´€ì ì¸ ì‹ í˜¸ ì •ë ¬ì— ì§‘ì¤‘í•˜ë©° ì£¼ê´€ì ì¸ ê°ì • ë‚´ìš©ê³¼ ë²”ìš©ì ì¸ ê¸°ë°˜ ëª¨ë¸ ë¶€ì¡± ë¬¸ì œë¥¼ ì§€ì í•˜ê³ , Multimodal LLMì„ í™œìš©í•˜ì—¬ ì´ë¯¸ì§€ì˜ ê°ì •ì„ ì¡°ì‘í•˜ëŠ” LLM-centric Affective Visual Customization (L-AVC) íƒœìŠ¤í¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. íš¨ìœ¨ì ì¸ ê°ì • ë³€í™˜(inter-emotion semantic conversion)ê³¼ ê°ì • ë¬´ê´€ ë‚´ìš© ìœ ì§€(exter-emotion semantic retaining)ì˜ ì¤‘ìš”ì„±ì„ ê°•ì¡°í•˜ë©°, ì´ë¥¼ ìœ„í•œ Efficient and Precise Emotion Manipulating (EPEM) ì ‘ê·¼ ë°©ì‹ì„ ì œì‹œí•©ë‹ˆë‹¤. ì œì•ˆí•˜ëŠ” EPEMì€ EIC ëª¨ë“ˆê³¼ PER ëª¨ë“ˆì„ í†µí•´ ê°ì • ì¡°ì‘ì˜ íš¨ìœ¨ì„±ê³¼ ì •í™•ì„±ì„ ë†’ì´ë©°, ì‹¤í—˜ ê²°ê³¼ ê¸°ì¡´ ë°©ë²• ëŒ€ë¹„ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.

### ğŸ†• ìƒˆë¡œìš´ ì  (Novelty)
* **LLM-centric Affective Visual Customization (L-AVC) íƒœìŠ¤í¬ ì •ì˜:** ê¸°ì¡´ ì—°êµ¬ê°€ ë‹¤ë£¨ì§€ ì•Šì•˜ë˜ ì´ë¯¸ì§€ì˜ ì£¼ê´€ì ì¸ ê°ì • ì¡°ì‘ì„ ìœ„í•œ ìƒˆë¡œìš´ íƒœìŠ¤í¬ë¥¼ ì •ì˜í•˜ê³ , ì´ë¥¼ Multimodal LLM ê¸°ë°˜ìœ¼ë¡œ ì ‘ê·¼í•©ë‹ˆë‹¤.
* **Inter-emotion Semantic Conversion & Exter-emotion Semantic Retaining ê°œë… ì œì‹œ:** ê°ì • ì¡°ì‘ ê³¼ì •ì—ì„œ í•µì‹¬ì ì¸ ë‘ ê°€ì§€ ê³¼ì œì¸ ê°ì • ë³€í™˜ì˜ ì˜ë¯¸ë¡ ì  ì •ë ¬ê³¼ ê°ì • ë¬´ê´€ ë‚´ìš© ìœ ì§€ë¥¼ ëª…í™•íˆ ì •ì˜í•˜ê³ , ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ëª¨ë“ˆì„ ì„¤ê³„í•©ë‹ˆë‹¤.
* **EPEM (Efficient and Precise Emotion Manipulating) ì ‘ê·¼ ë°©ì‹:** EICì™€ PER ëª¨ë“ˆì„ ê²°í•©í•˜ì—¬ ê°ì • ì¡°ì‘ì˜ íš¨ìœ¨ì„±ê³¼ ì •í™•ì„±ì„ ë™ì‹œì— ë†’ì´ëŠ” ìƒˆë¡œìš´ ì ‘ê·¼ ë°©ì‹ì„ ì œì‹œí•©ë‹ˆë‹¤.

### ğŸ’ª ê°•ì  (Strengths)
1. **ìƒˆë¡œìš´ ì—°êµ¬ ë°©í–¥ ì œì‹œ:** ì´ë¯¸ì§€ í¸ì§‘ ë¶„ì•¼ì—ì„œ ê°ì •ì´ë¼ëŠ” ì£¼ê´€ì ì¸ ìš”ì†Œë¥¼ ê³ ë ¤í•œ ìƒˆë¡œìš´ ì—°êµ¬ ë°©í–¥ì„ ì œì‹œí•˜ë©°, Multimodal LLMì˜ í™œìš© ê°€ëŠ¥ì„±ì„ ë„“í˜”ìŠµë‹ˆë‹¤.
2. **ëª…í™•í•œ ë¬¸ì œ ì •ì˜ ë° í•´ê²°:** ê°ì • ì¡°ì‘ ê³¼ì •ì—ì„œ ë°œìƒí•˜ëŠ” í•µì‹¬ì ì¸ ë¬¸ì œë“¤ì„ ëª…í™•í•˜ê²Œ ì •ì˜í•˜ê³ , ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ êµ¬ì²´ì ì¸ ëª¨ë“ˆì„ ì„¤ê³„í•˜ì—¬ ì‹¤ì§ˆì ì¸ í•´ê²°ì±…ì„ ì œì‹œí•©ë‹ˆë‹¤.
3. **ì‹¤í—˜ì  ê²€ì¦:** L-AVC ë°ì´í„°ì…‹ì„ êµ¬ì¶•í•˜ê³ , ë‹¤ì–‘í•œ baseline ëª¨ë¸ê³¼ ë¹„êµí•˜ì—¬ ì œì•ˆí•˜ëŠ” EPEMì˜ ìš°ìˆ˜ì„±ì„ ì‹¤í—˜ì ìœ¼ë¡œ ì…ì¦í–ˆìŠµë‹ˆë‹¤.

### âš ï¸ ì•½ì /í•œê³„ì  (Limitations)
1. **ë°ì´í„°ì…‹ êµ¬ì¶•ì˜ ì–´ë ¤ì›€:** ê°ì • ë ˆì´ë¸”ë§ì€ ì£¼ê´€ì ì´ê³  ì–´ë ¤ìš¸ ìˆ˜ ìˆìœ¼ë©°, êµ¬ì¶•ëœ L-AVC ë°ì´í„°ì…‹ì˜ í’ˆì§ˆê³¼ ë‹¤ì–‘ì„±ì´ ê²°ê³¼ì— ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
2. **ê°ì • í‘œí˜„ì˜ ë³µì¡ì„±:** ì¸ê°„ì˜ ê°ì •ì€ ë§¤ìš° ë³µì¡í•˜ê³  ë¯¸ë¬˜í•˜ë©°, ì´ë¥¼ ì´ë¯¸ì§€ì— ì •í™•í•˜ê²Œ ë°˜ì˜í•˜ëŠ” ê²ƒì€ ì–´ë ¤ìš´ ê³¼ì œì…ë‹ˆë‹¤. ë…¼ë¬¸ì—ì„œ ë‹¤ë£¨ëŠ” ê°ì •ì˜ ë²”ìœ„ê°€ ì œí•œì ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
3. **Multimodal LLM ì˜ì¡´ì„±:** ì œì•ˆí•˜ëŠ” ë°©ë²•ì€ Multimodal LLMì˜ ì„±ëŠ¥ì— í¬ê²Œ ì˜ì¡´í•˜ë©°, LLMì˜ í•œê³„ (ì˜ˆ: í™˜ê°, í¸í–¥)ê°€ ê²°ê³¼ì— ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ğŸ”— ë‚´ ì—°êµ¬ì™€ì˜ ì—°ê´€ì„±
ë³¸ ë…¼ë¬¸ì€ ì €ì˜ ì—°êµ¬ ë¶„ì•¼ì¸ Vision-Text Alignment, Document/Chart VQAì™€ ê°„ì ‘ì ìœ¼ë¡œ ì—°ê´€ë©ë‹ˆë‹¤. íŠ¹íˆ, ë¬¸ì„œë‚˜ ì°¨íŠ¸ ë‚´ì˜ ì‹œê°ì  ìš”ì†Œì™€ í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ê²°í•©í•˜ì—¬ ê°ì •ì ì¸ ë§¥ë½ì„ ì´í•´í•˜ëŠ” ì—°êµ¬ì— í™œìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì°¨íŠ¸ì˜ ìƒ‰ìƒì´ë‚˜ ë””ìì¸ì´ íŠ¹ì • ê°ì •ì„ ìœ ë°œí•˜ëŠ”ì§€, ë¬¸ì„œì˜ ë‚´ìš©ì´ ë…ìì—ê²Œ ì–´ë–¤ ê°ì •ì„ ì „ë‹¬í•˜ëŠ”ì§€ ë“±ì„ ë¶„ì„í•˜ëŠ” ë° ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, MLLM Mergingì„ í†µí•´ ê°ì • ì¸ì‹ ë° ì¡°ì‘ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ì—°êµ¬ë„ ê°€ëŠ¥í•  ê²ƒì…ë‹ˆë‹¤.

### ğŸ’¡ ì—°êµ¬ ì•„ì´ë””ì–´ ì œì•ˆ
1. **í•œêµ­ì–´ ê°ì • ê¸°ë°˜ ì‹œê°ì  ì»¤ìŠ¤í„°ë§ˆì´ì œì´ì…˜:** í•œêµ­ì–´ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ì— ëŒ€í•œ ê°ì • ë¶„ì„ì„ ê¸°ë°˜ìœ¼ë¡œ ì‹œê°ì  ì»¤ìŠ¤í„°ë§ˆì´ì œì´ì…˜ì„ ìˆ˜í–‰í•˜ëŠ” ì—°êµ¬ë¥¼ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•œêµ­ì–´ íŠ¹ìœ ì˜ ê°ì • í‘œí˜„ ë°©ì‹ê³¼ ë¬¸í™”ì  ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ ë”ìš± ìì—°ìŠ¤ëŸ¬ìš´ ê²°ê³¼ë¬¼ì„ ì–»ì„ ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤.
2. **Document VQAì—ì„œì˜ ê°ì • ë¶„ì„ í™œìš©:** ë¬¸ì„œ VQA íƒœìŠ¤í¬ì—ì„œ ë¬¸ì„œ ë‚´ìš©ì— ëŒ€í•œ ê°ì • ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì—°êµ¬ë¥¼ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, "ì´ ë³´ê³ ì„œëŠ” ì–´ë–¤ ë¶„ìœ„ê¸°ë¥¼ ê°€ì§€ê³  ìˆë‚˜ìš”?"ì™€ ê°™ì€ ì§ˆë¬¸ì— ë‹µë³€í•  ìˆ˜ ìˆë„ë¡ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
3. **MLLM Mergingì„ í†µí•œ ê°ì • ì¡°ì‘ ì„±ëŠ¥ í–¥ìƒ:** ë‹¤ì–‘í•œ MLLM ëª¨ë¸ì„ ë¨¸ì§•í•˜ì—¬ ê°ì • ì¸ì‹ ë° ì¡°ì‘ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ì—°êµ¬ë¥¼ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ, ê°ì • ë¶„ì„ì— íŠ¹í™”ëœ ëª¨ë¸ê³¼ ì‹œê°ì  ì´í•´ ëŠ¥ë ¥ì´ ë›°ì–´ë‚œ ëª¨ë¸ì„ ê²°í•©í•˜ì—¬ ë”ìš± ê°•ë ¥í•œ ì„±ëŠ¥ì„ ì–»ì„ ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤.

### ğŸ“š í•µì‹¬ í‚¤ì›Œë“œ
1. Affective Visual Customization
2. Multimodal Large Language Model (MLLM)
3. Emotion Manipulation
4. Vision-Language Alignment
5. Inter-emotion Semantic Conversion


---

> ğŸ¤– ì´ ê¸€ì€ AI ì—°êµ¬ ì–´ì‹œìŠ¤í„´íŠ¸ì— ì˜í•´ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.
> ë¶„ì„ ëª¨ë¸: google/gemma-3-27b-it:free
