---
title: "ScalSelect: Scalable Training-Free Multimodal Data Selection for Efficient Visua"
date: 2026-02-14
arxiv: "2602.11636v1"
category: "cs.CV"
model: "google/gemma-3-27b-it:free"
---

# ScalSelect: Scalable Training-Free Multimodal Data Selection for Efficient Visual Instruction Tuning

## ğŸ“– ë…¼ë¬¸ ì •ë³´

| í•­ëª© | ë‚´ìš© |
|------|------|
| **ì €ì** | Changti Wu, Jiahuai Mao, Yuzhuo Miao, Shijie Lian, Bin Yu... |
| **ë°œí‘œì¼** | 2026-02-12 |
| **arXiv** | [2602.11636v1](https://arxiv.org/pdf/2602.11636v1) |
| **ì¹´í…Œê³ ë¦¬** | cs.CV |

---

## ğŸ“ ì´ˆë¡ (Abstract)

Large-scale Visual Instruction Tuning (VIT) has become a key paradigm for advancing the performance of vision-language models (VLMs) across various multimodal tasks. However, training on the large-scale datasets is computationally expensive and inefficient due to redundancy in the data, which motivates the need for multimodal data selection to improve training efficiency. Existing data selection methods for VIT either require costly training or gradient computation. Training-free alternatives often depend on proxy models or datasets, instruction-agnostic representations, and pairwise similarity with quadratic complexity, limiting scalability and representation fidelity. In this work, we propose ScalSelect, a scalable training-free multimodal data selection method with linear-time complexity with respect to the number of samples, eliminating the need for external models or auxiliary datasets. ScalSelect first constructs sample representations by extracting visual features most attended by instruction tokens in the target VLM, capturing instruction-relevant information. It then identifies samples whose representations best approximate the dominant subspace of the full dataset representations, enabling scalable importance scoring without pairwise comparisons. Extensive experiments across multiple VLMs, datasets, and selection budgets demonstrate that ScalSelect achieves over 97.5% of the performance of training on the full dataset using only 16% of the data, and even outperforms full-data training in some settings. The code is available at \href{https://github.com/ChangtiWu/ScalSelect}{ScalSelect}.

---

## ğŸ” AI ë¶„ì„

## ScalSelect ë…¼ë¬¸ ë¶„ì„ ê²°ê³¼

### ğŸ“„ ë…¼ë¬¸ ìš”ì•½
ë³¸ ë…¼ë¬¸ì€ ëŒ€ê·œëª¨ ì‹œê°ì  ëª…ë ¹ì–´ íŠœë‹(VIT)ì˜ íš¨ìœ¨ì„±ì„ ë†’ì´ê¸° ìœ„í•œ í›ˆë ¨ ì—†ì´ ìˆ˜í–‰ ê°€ëŠ¥í•œ í™•ì¥ì„± ìˆëŠ” ë‹¤ì¤‘ ëª¨ë‹¬ ë°ì´í„° ì„ íƒ ë°©ë²•ì¸ ScalSelectë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ScalSelectëŠ” ëŒ€ìƒ VLMì˜ ëª…ë ¹ì–´ í† í°ì´ ê°€ì¥ ì§‘ì¤‘í•˜ëŠ” ì‹œê°ì  íŠ¹ì§•ì„ ì¶”ì¶œí•˜ì—¬ ëª…ë ¹ì–´ ê´€ë ¨ ì •ë³´ë¥¼ í¬ì°©í•˜ê³ , ì „ì²´ ë°ì´í„°ì…‹ í‘œí˜„ì˜ ì£¼ìš” ë¶€ë¶„ ê³µê°„ì„ ê°€ì¥ ì˜ ê·¼ì‚¬í•˜ëŠ” ìƒ˜í”Œì„ ì‹ë³„í•˜ì—¬ ì„ í˜• ì‹œê°„ ë³µì¡ë„ë¡œ ì¤‘ìš”ë„ë¥¼ í‰ê°€í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ScalSelectëŠ” ì „ì²´ ë°ì´í„°ì…‹ì˜ 16%ë§Œ ì‚¬ìš©í•˜ì—¬ ì „ì²´ ë°ì´í„°ì…‹ìœ¼ë¡œ í›ˆë ¨í•œ ì„±ëŠ¥ì˜ 97.5% ì´ìƒì„ ë‹¬ì„±í–ˆìœ¼ë©°, ì¼ë¶€ ì„¤ì •ì—ì„œëŠ” ì „ì²´ ë°ì´í„°ì…‹ í›ˆë ¨ì„ ëŠ¥ê°€í•˜ëŠ” ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

### ğŸ†• ìƒˆë¡œìš´ ì  (Novelty)
ê¸°ì¡´ì˜ VIT ë°ì´í„° ì„ íƒ ë°©ë²•ë“¤ì´ í›ˆë ¨ ë˜ëŠ” ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°ì„ í•„ìš”ë¡œ í•˜ê±°ë‚˜, í”„ë¡ì‹œ ëª¨ë¸/ë°ì´í„°ì…‹, ëª…ë ¹ì–´ì— ë¬´ê´€í•œ í‘œí˜„, ë˜ëŠ” 2ì°¨ ë³µì¡ë„ë¥¼ ê°–ëŠ” ìŒë³„ ìœ ì‚¬ë„ì— ì˜ì¡´í–ˆë˜ ê²ƒì— ë¹„í•´, ScalSelectëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì ì—ì„œ ì°¨ë³„ì„±ì„ ê°€ì§‘ë‹ˆë‹¤.

*   **í›ˆë ¨-í”„ë¦¬(Training-Free) ë°©ì‹:** ë³„ë„ì˜ í›ˆë ¨ ê³¼ì • ì—†ì´ ë°ì´í„° ì„ íƒì´ ê°€ëŠ¥í•˜ì—¬ ê³„ì‚° ë¹„ìš©ì„ í¬ê²Œ ì ˆê°í•©ë‹ˆë‹¤.
*   **ì„ í˜• ì‹œê°„ ë³µì¡ë„:** ë°ì´í„°ì…‹ í¬ê¸°ì— ë”°ë¼ ê³„ì‚° ë³µì¡ë„ê°€ ì„ í˜•ì ìœ¼ë¡œ ì¦ê°€í•˜ì—¬ ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì— ëŒ€í•œ í™•ì¥ì„±ì´ ë›°ì–´ë‚©ë‹ˆë‹¤.
*   **ëª…ë ¹ì–´ ê´€ë ¨ ì •ë³´ í™œìš©:** ëŒ€ìƒ VLMì˜ ëª…ë ¹ì–´ í† í°ì´ ì§‘ì¤‘í•˜ëŠ” ì‹œê°ì  íŠ¹ì§•ì„ í™œìš©í•˜ì—¬ ëª…ë ¹ì–´ì— ë”ìš± ì í•©í•œ ë°ì´í„° ìƒ˜í”Œì„ ì„ íƒí•©ë‹ˆë‹¤.
*   **ì£¼ìš” ë¶€ë¶„ ê³µê°„ ê·¼ì‚¬:** ì „ì²´ ë°ì´í„°ì…‹ í‘œí˜„ì˜ ì£¼ìš” ë¶€ë¶„ ê³µê°„ì„ ê·¼ì‚¬í•˜ì—¬ ë°ì´í„°ì˜ ëŒ€í‘œì„±ì„ í™•ë³´í•˜ê³ , ë¶ˆí•„ìš”í•œ ì¤‘ë³µì„ ì œê±°í•©ë‹ˆë‹¤.

### ğŸ’ª ê°•ì  (Strengths)
1.  **ë†’ì€ íš¨ìœ¨ì„±:** ì „ì²´ ë°ì´í„°ì…‹ì˜ ì‘ì€ ë¶€ë¶„ì§‘í•©ë§Œ ì‚¬ìš©í•˜ì—¬ ê±°ì˜ ë™ì¼í•œ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ì—¬ í›ˆë ¨ ë¹„ìš©ê³¼ ì‹œê°„ì„ í¬ê²Œ ì ˆê°í•©ë‹ˆë‹¤.
2.  **ë›°ì–´ë‚œ í™•ì¥ì„±:** ì„ í˜• ì‹œê°„ ë³µì¡ë„ë¥¼ í†µí•´ ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì— íš¨ê³¼ì ìœ¼ë¡œ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
3.  **ëª…ë ¹ì–´ ì´í•´ë„ í–¥ìƒ:** ëª…ë ¹ì–´ í† í°ì˜ ì‹œê°ì  íŠ¹ì§• ì§‘ì¤‘ë„ë¥¼ í™œìš©í•˜ì—¬ ëª…ë ¹ì–´ì™€ ê´€ë ¨ëœ ë°ì´í„° ìƒ˜í”Œì„ ì„ íƒí•¨ìœ¼ë¡œì¨ VLMì˜ ëª…ë ¹ì–´ ì´í•´ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

### âš ï¸ ì•½ì /í•œê³„ì  (Limitations)
1.  **VLM ì˜ì¡´ì„±:** ScalSelectëŠ” ëŒ€ìƒ VLMì˜ ì‹œê°ì  íŠ¹ì§• ì¶”ì¶œì— ì˜ì¡´í•˜ë¯€ë¡œ, VLMì˜ ì„±ëŠ¥ì— ë”°ë¼ ë°ì´í„° ì„ íƒ ê²°ê³¼ê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¦‰, VLMì˜ ì„±ëŠ¥ì´ ì¢‹ì§€ ì•Šìœ¼ë©´ ScalSelectì˜ ì„±ëŠ¥ë„ ì €í•˜ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
2.  **ë¶€ë¶„ ê³µê°„ ì„ íƒ ê¸°ì¤€:** ì£¼ìš” ë¶€ë¶„ ê³µê°„ì„ ê²°ì •í•˜ëŠ” ê¸°ì¤€ì´ ëª…í™•í•˜ê²Œ ì œì‹œë˜ì§€ ì•Šì•„, ë°ì´í„°ì…‹ì˜ íŠ¹ì„±ì— ë”°ë¼ ìµœì ì˜ ê¸°ì¤€ì´ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
3.  **í•œêµ­ì–´ ë°ì´í„°ì…‹ì— ëŒ€í•œ ê²€ì¦ ë¶€ì¬:** ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì˜ì–´ ë°ì´í„°ì…‹ì— ëŒ€í•œ ì‹¤í—˜ ê²°ê³¼ë§Œ ì œì‹œë˜ì—ˆìœ¼ë¯€ë¡œ, í•œêµ­ì–´ ë°ì´í„°ì…‹ì— ëŒ€í•œ ì„±ëŠ¥ ê²€ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤.

### ğŸ”— ë‚´ ì—°êµ¬ì™€ì˜ ì—°ê´€ì„±
ë³¸ ë…¼ë¬¸ì€ ì œ ì—°êµ¬ ë¶„ì•¼ì¸ MLLM ì„±ëŠ¥ í–¥ìƒ, íŠ¹íˆ Vision-Text Alignment ë° MLLM Mergingì— ì§ì ‘ì ì¸ ê´€ë ¨ì´ ìˆìŠµë‹ˆë‹¤.

*   **Vision-Text Alignment:** ScalSelectëŠ” ëª…ë ¹ì–´ í† í°ì´ ì§‘ì¤‘í•˜ëŠ” ì‹œê°ì  íŠ¹ì§•ì„ ì¶”ì¶œí•˜ì—¬ Vision-Text Alignmentë¥¼ ê°•í™”í•˜ëŠ” ë° ê¸°ì—¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ì œê°€ í˜„ì¬ ì—°êµ¬í•˜ê³  ìˆëŠ” ì •ë ¬ ì—°êµ¬ì— ì¤‘ìš”í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
*   **MLLM Merging:** ScalSelectë¥¼ í™œìš©í•˜ì—¬ ê° ëª¨ë¸ì˜ ê°•ì ì„ ê°€ì§„ ë°ì´í„° ìƒ˜í”Œì„ ì„ íƒì ìœ¼ë¡œ íŠœë‹í•˜ì—¬ MLLM Mergingì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
*   **Korean MLLM:** ScalSelectë¥¼ í•œêµ­ì–´ ë°ì´í„°ì…‹ì— ì ìš©í•˜ì—¬ í•œêµ­ì–´ MLLMì˜ íš¨ìœ¨ì ì¸ íŠœë‹ì„ ê°€ëŠ¥í•˜ê²Œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ğŸ’¡ ì—°êµ¬ ì•„ì´ë””ì–´ ì œì•ˆ
1.  **í•œêµ­ì–´ ë°ì´í„°ì…‹ ì ìš©:** ScalSelectë¥¼ í•œêµ­ì–´ VQA ë°ì´í„°ì…‹(KoQA, KorVQA ë“±)ì— ì ìš©í•˜ì—¬ ì„±ëŠ¥ì„ í‰ê°€í•˜ê³ , í•œêµ­ì–´ MLLM íŠœë‹ì— ìµœì í™”ëœ ë°ì´í„° ì„ íƒ ì „ëµì„ ê°œë°œí•©ë‹ˆë‹¤.
2.  **MLLM Mergingê³¼ì˜ ê²°í•©:** ScalSelectë¥¼ í™œìš©í•˜ì—¬ ê° ëª¨ë¸ì˜ ê°•ì ì„ ê°€ì§„ ë°ì´í„° ìƒ˜í”Œì„ ì„ íƒì ìœ¼ë¡œ íŠœë‹í•˜ê³ , ì´ë¥¼ MLLM Mergingì— ì ìš©í•˜ì—¬ ì„±ëŠ¥ í–¥ìƒì„ ì‹œë„í•©ë‹ˆë‹¤.
3.  **ë¶€ë¶„ ê³µê°„ ì„ íƒ ê¸°ì¤€ ì—°êµ¬:** ë°ì´í„°ì…‹ì˜ íŠ¹ì„±ì— ë”°ë¼ ìµœì ì˜ ì£¼ìš” ë¶€ë¶„ ê³µê°„ ì„ íƒ ê¸°ì¤€ì„ ê²°ì •í•˜ëŠ” ë°©ë²•ì„ ì—°êµ¬í•˜ê³ , ì´ë¥¼ ScalSelectì— ì ìš©í•˜ì—¬ ì„±ëŠ¥ì„ ê°œì„ í•©ë‹ˆë‹¤.
4.  **VLM ì„±ëŠ¥ì— ëŒ€í•œ Robustness ê°œì„ :** VLMì˜ ì„±ëŠ¥ ë³€í™”ì— ëœ ë¯¼ê°í•˜ê²Œ ì‘ë™í•˜ë„ë¡ ScalSelectì˜ ì•Œê³ ë¦¬ì¦˜ì„ ê°œì„ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, VLMì˜ íŠ¹ì§• ì¶”ì¶œ ê²°ê³¼ì— ëŒ€í•œ ì •ê·œí™” ë˜ëŠ” ê°€ì¤‘ì¹˜ ë¶€ì—¬ ë°©ì‹ì„ ë„ì…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ğŸ“š í•µì‹¬ í‚¤ì›Œë“œ
1.  Visual Instruction Tuning (VIT)
2.  Multimodal Data Selection
3.  Training-Free
4.  Vision-Language Alignment
5.  Scalability

---

> ğŸ¤– ì´ ê¸€ì€ AI ì—°êµ¬ ì–´ì‹œìŠ¤í„´íŠ¸ì— ì˜í•´ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.
> ë¶„ì„ ëª¨ë¸: google/gemma-3-27b-it:free
